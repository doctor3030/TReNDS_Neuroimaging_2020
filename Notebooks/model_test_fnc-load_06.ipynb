{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "from IPython.display import IFrame\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "\n",
    "import scipy.stats as sts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing as prep\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn import discriminant_analysis as disan\n",
    "from sklearn import calibration as calib\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn import svm\n",
    "from sklearn import gaussian_process as gaup\n",
    "from sklearn import mixture as mix\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble as ens\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# from keras import models as kermdls\n",
    "# from keras import layers as kerlrs\n",
    "# from keras import metrics as kmetrics\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "import pickle\n",
    "\n",
    "import nilearn as nl\n",
    "from nilearn import plotting, image\n",
    "from nilearn import datasets\n",
    "import nibabel as nb\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7832955972614657442\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12538682665678164108\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6589725830\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17774684851619793817\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16511309459102941993\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnc_10 = pd.read_csv('00_Data/fnc.csv')\n",
    "# fnc_10 = fnc_10.head(5)\n",
    "# for row in fnc_10.iterrows():\n",
    "#     idx = int(row[1][0])\n",
    "#     row = row[1][1:]\n",
    "#     print(row)\n",
    "#     row.to_csv('00_Data/fnc_csv_norm/{0}.csv'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IDS = [map_id.split('.')[0] for map_id in sorted(os.listdir('00_Data/fMRI_test'))]\n",
    "TRAIN_IDS = [map_id.split('.')[0] for map_id in sorted(os.listdir('00_Data/fMRI_train'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.108977</td>\n",
       "      <td>69.993075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>21746</td>\n",
       "      <td>14.257265</td>\n",
       "      <td>21.358872</td>\n",
       "      <td>61.165998</td>\n",
       "      <td>51.778483</td>\n",
       "      <td>54.640179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>21747</td>\n",
       "      <td>55.456978</td>\n",
       "      <td>68.169675</td>\n",
       "      <td>29.907995</td>\n",
       "      <td>55.349257</td>\n",
       "      <td>54.019517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>21750</td>\n",
       "      <td>48.948756</td>\n",
       "      <td>55.114811</td>\n",
       "      <td>60.878271</td>\n",
       "      <td>38.617246</td>\n",
       "      <td>50.679885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>21752</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>59.844808</td>\n",
       "      <td>72.303110</td>\n",
       "      <td>55.458281</td>\n",
       "      <td>46.870235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>21754</td>\n",
       "      <td>68.820928</td>\n",
       "      <td>56.594193</td>\n",
       "      <td>34.605868</td>\n",
       "      <td>49.922535</td>\n",
       "      <td>50.383078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2\n",
       "0     10001  57.436077     30.571975     62.553736     53.325130     51.427998\n",
       "1     10002  59.580851     50.969456     67.470628     60.651856     58.311361\n",
       "2     10004  71.413018     53.152498     58.012103     52.418389     62.536641\n",
       "3     10005  66.532630           NaN           NaN     52.108977     69.993075\n",
       "4     10007  38.617381     49.197021     65.674285     40.151376     34.096421\n",
       "...     ...        ...           ...           ...           ...           ...\n",
       "5872  21746  14.257265     21.358872     61.165998     51.778483     54.640179\n",
       "5873  21747  55.456978     68.169675     29.907995     55.349257     54.019517\n",
       "5874  21750  48.948756     55.114811     60.878271     38.617246     50.679885\n",
       "5875  21752  66.532630     59.844808     72.303110     55.458281     46.870235\n",
       "5876  21754  68.820928     56.594193     34.605868     49.922535     50.383078\n",
       "\n",
       "[5877 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('00_Data/train_scores.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                0\n",
       "age               0\n",
       "domain1_var1    438\n",
       "domain1_var2    438\n",
       "domain2_var1     39\n",
       "domain2_var2     39\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls = data.isnull().sum()\n",
    "# l = len(data.index)\n",
    "\n",
    "# nulls['domain1_var1'] / l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length:  5434\n"
     ]
    }
   ],
   "source": [
    "print('Dataset length: ', len(data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_inputs_fnc(idx, labels):\n",
    "#     df = pd.read_csv('00_Data/fnc_csv/{0}.csv'.format(idx), index_col=0)\n",
    "#     X = np.array(df.values).reshape(-1)\n",
    "#     return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_inputs_loading(idx, labels):\n",
    "#     df = pd.read_csv('00_Data/loading_csv/{0}.csv'.format(idx), index_col=0)\n",
    "#     X = np.array(df.values).reshape(-1)\n",
    "#     return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(idx, labels):\n",
    "    df_fnc = pd.read_csv('00_Data/fnc_csv/{0}.csv'.format(idx), index_col=0)\n",
    "    X_fnc = np.array(df_fnc.values).reshape(-1)\n",
    "    \n",
    "    df_loading = pd.read_csv('00_Data/loading_csv/{0}.csv'.format(idx), index_col=0)\n",
    "    X_loading = np.array(df_loading.values).reshape(-1)\n",
    "#     print(X_fnc[0])\n",
    "#     print(X_loading[0])\n",
    "#     print(labels[0])\n",
    "#     print(X_fnc.shape)\n",
    "#     print(X_loading.shape)\n",
    "#     print(labels.shape)\n",
    "\n",
    "#     X_fnc = tf.convert_to_tensor(X_fnc, dtype=tf.float64)\n",
    "#     X_loading = tf.convert_to_tensor(X_loading, dtype=tf.float64)\n",
    "#     labels = tf.convert_to_tensor(labels, dtype=tf.float64)\n",
    "#     X = tf.tuple([X_fnc, X_loading])\n",
    "\n",
    "#     X = dict()\n",
    "#     X['input_1'] = X_fnc\n",
    "#     X['input_2'] = X_loading\n",
    "    X = (X_fnc, X_loading)\n",
    "    return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_decorator(func):\n",
    "    def wrapper(idx, labels):\n",
    "        # Use a tf.py_function to prevent auto-graph from compiling the method\n",
    "        return tf.py_function(func,\n",
    "                              inp=(idx, labels),\n",
    "                              Tout=tf.float64)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_py_function(func, inp, Tout, name=None):\n",
    "    \n",
    "    def wrapped_func(*flat_inp):\n",
    "        reconstructed_inp = tf.nest.pack_sequence_as(inp, flat_inp,\n",
    "                                                     expand_composites=True)\n",
    "        out = func(*reconstructed_inp)\n",
    "        return tf.nest.flatten(out, expand_composites=True)\n",
    "    \n",
    "    flat_Tout = tf.nest.flatten(Tout, expand_composites=True)\n",
    "    flat_out = tf.py_function(func=wrapped_func, \n",
    "                              inp=tf.nest.flatten(inp, expand_composites=True),\n",
    "                              Tout=[_tensor_spec_to_dtype(v) for v in flat_Tout],\n",
    "                              name=name)\n",
    "    spec_out = tf.nest.map_structure(_dtype_to_tensor_spec, Tout, expand_composites=True)\n",
    "    out = tf.nest.pack_sequence_as(spec_out, flat_out, expand_composites=True)\n",
    "    return out\n",
    "\n",
    "def _dtype_to_tensor_spec(v):\n",
    "    return tf.TensorSpec(None, v) if isinstance(v, tf.dtypes.DType) else v\n",
    "\n",
    "def _tensor_spec_to_dtype(v):\n",
    "    return v.dtype if isinstance(v, tf.TensorSpec) else v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dataset(data, batch_size):\n",
    "#     data = tf.data.Dataset.from_tensor_slices((data['Id'].values, \n",
    "#                                                data[['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']].values))\n",
    "#     data = data.shuffle(buffer_size=5500, seed=30, reshuffle_each_iteration=True)\n",
    "    \n",
    "#     data_fnc = data.map(map_decorator(get_inputs_fnc), \n",
    "#                      num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "#                      deterministic=True)\n",
    "#     data_loading = data.map(map_decorator(get_inputs_loading), \n",
    "#                      num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "#                      deterministic=True)\n",
    "\n",
    "#     data_fnc = data_fnc.batch(batch_size, drop_remainder=True)\n",
    "#     data_fnc = data_fnc.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "#     data_loading = data_loading.batch(batch_size, drop_remainder=True)\n",
    "#     data_loading = data_loading.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#     return (data_fnc, data_loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data, batch_size):\n",
    "    data = tf.data.Dataset.from_tensor_slices((data['Id'].values, \n",
    "                                               data[['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']].values))\n",
    "    data = data.shuffle(buffer_size=5500, seed=30, reshuffle_each_iteration=True)\n",
    "    \n",
    "    data = data.map(lambda idx, lbl:new_py_function(get_inputs, inp=(idx, lbl), Tout=((tf.float64, tf.float64), tf.float64), name=None), \n",
    "                     num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "                     deterministic=True)\n",
    "    data = data.batch(batch_size, drop_remainder=True)\n",
    "    data = data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = model_selection.train_test_split(data, test_size=0.2, shuffle=True, random_state=30)\n",
    "train, val = model_selection.train_test_split(train, test_size=0.2, shuffle=True, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 64\n",
    "\n",
    "# ds_train_fnc, ds_train_loading = get_dataset(train, batch_size)\n",
    "# ds_val_fnc, ds_val_loading = get_dataset(val, batch_size)\n",
    "# ds_test_fnc, ds_test_loading = get_dataset(test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "ds_train = get_dataset(train, batch_size)\n",
    "ds_val = get_dataset(val, batch_size)\n",
    "ds_test = get_dataset(test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.perf_counter()\n",
    "# for f in ds_train.take(1):\n",
    "#     pass\n",
    "# tf.print(\"Execution time:\", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE_fnc = (1378,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE_loading = (26,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_fnc = keras.layers.Input(shape=INPUT_SHAPE_fnc, name='inp_fnc')\n",
    "\n",
    "x = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(inputs_fnc)\n",
    "x = keras.layers.Dense(2048,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x)\n",
    "# x = keras.layers.Dropout(rate=0.2, seed=30)(x)\n",
    "\n",
    "x1 = keras.layers.Dense(512,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x1)\n",
    "x1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x1)\n",
    "\n",
    "x2 = keras.layers.Dense(512,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x2)\n",
    "x2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x2)\n",
    "\n",
    "x = keras.layers.concatenate([x1, x2])\n",
    "\n",
    "# x = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(x)\n",
    "\n",
    "x = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x)\n",
    "# x = keras.layers.Dropout(rate=0.2, seed=30)(x)\n",
    "\n",
    "# output\n",
    "x = keras.Model(inputs=inputs_fnc, outputs=x, name='model_fnc')\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_loading = keras.layers.Input(shape=INPUT_SHAPE_loading, name='inp_load')\n",
    "\n",
    "y = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(inputs_loading)\n",
    "\n",
    "y = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y)\n",
    "# y = keras.layers.Dropout(rate=0.2, seed=30)(y)\n",
    "\n",
    "y1 = keras.layers.Dense(128,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y1)\n",
    "y1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y1)\n",
    "\n",
    "y2 = keras.layers.Dense(128,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y2)\n",
    "y2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y2)\n",
    "\n",
    "y = keras.layers.concatenate([y1, y2])\n",
    "\n",
    "# y = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(y)\n",
    "\n",
    "y = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y)\n",
    "# x = keras.layers.Dropout(rate=0.2, seed=30)(x)\n",
    "\n",
    "# output\n",
    "y = keras.Model(inputs=inputs_loading, outputs=y, name='model_loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = keras.layers.concatenate([x.output, y.output])\n",
    "\n",
    "z = keras.layers.Dense(512, \n",
    "                       kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                       bias_initializer=keras.initializers.Constant(5.))(concat)\n",
    "z = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(z)\n",
    "\n",
    "# z = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(z)\n",
    "\n",
    "z = keras.layers.Dense(512, \n",
    "                       kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                       bias_initializer=keras.initializers.Constant(5.))(z)\n",
    "z = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(z)\n",
    "# z = keras.layers.Dropout(rate=0.2, seed=30)(z)\n",
    "\n",
    "outputs = keras.layers.Dense(5, activation='linear')(z)\n",
    "\n",
    "model = keras.Model(inputs=[x.input, y.input], outputs=outputs, name='model_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_combined\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inp_fnc (InputLayer)            [(None, 1378)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inp_load (InputLayer)           [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1378)         5512        inp_fnc[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 26)           104         inp_load[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         2824192     batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          6912        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu (PReLU)                 (None, 2048)         2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_4 (PReLU)               (None, 256)          256         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     p_re_lu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          1049088     p_re_lu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          32896       p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          32896       p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 512)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 512)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_5 (PReLU)               (None, 128)          128         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_6 (PReLU)               (None, 128)          128         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          2048        p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512)          2048        p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128)          512         p_re_lu_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128)          512         p_re_lu_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          262400      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          65792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_3 (PReLU)               (None, 256)          256         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_7 (PReLU)               (None, 256)          256         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           p_re_lu_3[0][0]                  \n",
      "                                                                 p_re_lu_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          262656      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_8 (PReLU)               (None, 512)          512         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          262656      p_re_lu_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_9 (PReLU)               (None, 512)          512         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 5)            2565        p_re_lu_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,866,997\n",
      "Trainable params: 5,861,629\n",
      "Non-trainable params: 5,368\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim = keras.optimizers.Adam(lr=0.000001,\n",
    "#                                  beta_1=0.99,\n",
    "#                                  beta_2=0.999,\n",
    "#                                  amsgrad=False)\n",
    "\n",
    "optim = tf.keras.optimizers.Adadelta(learning_rate=0.001, rho=0.95)\n",
    "        \n",
    "METRICS = [keras.metrics.RootMeanSquaredError(name='rmse'),\n",
    "           keras.metrics.MeanSquaredError(name='mse'),\n",
    "           keras.metrics.MeanAbsoluteError(name='mae')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def weighted_mae(y_true, y_pred):\n",
    "# #     tf.print(y_true)\n",
    "#     W = tf.constant([[0.2, 0.2, 0.2, 0.2, 0.2]])\n",
    "# #     tf.print(W / tf.math.reduce_mean(y_true, axis=0))\n",
    "#     return tf.math.reduce_mean(tf.linalg.matmul(tf.math.abs(y_pred - y_true), tf.transpose(W / tf.math.reduce_mean(y_true, axis=0))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mae', metrics=METRICS, optimizer=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint directory to store the checkpoints\n",
    "# Name of the checkpoint files\n",
    "# checkpoint_prefix = os.path.join('./99_Training_checkpoints/fnc-loading', \"ckpt_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/fnc-loading'),\n",
    "#              tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "#                                                 save_weights_only=False),\n",
    "#              tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "#                                                   factor=0.7, \n",
    "#                                                   patience=2, \n",
    "#                                                   verbose=1, \n",
    "#                                                   mode='min',\n",
    "#                                                   min_delta=0.01, \n",
    "#                                                   cooldown=5, \n",
    "#                                                   min_lr=0.00000001),\n",
    "#              tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "#                                               min_delta=0.001, \n",
    "#                                               patience=10, \n",
    "#                                               verbose=1, \n",
    "#                                               mode='min',\n",
    "#                                               baseline=None, \n",
    "#                                               restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/fnc-loading'),\n",
    "#              tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "#                                                   factor=0.7, \n",
    "#                                                   patience=2, \n",
    "#                                                   verbose=1, \n",
    "#                                                   mode='min',\n",
    "#                                                   min_delta=0.01, \n",
    "#                                                   cooldown=5, \n",
    "#                                                   min_lr=0.00000001),\n",
    "#              tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "#                                               min_delta=0.001, \n",
    "#                                               patience=10, \n",
    "#                                               verbose=1, \n",
    "#                                               mode='min',\n",
    "#                                               baseline=None, \n",
    "#                                               restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/fnc-loading'),\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              min_delta=0.001, \n",
    "                                              patience=10, \n",
    "                                              verbose=1, \n",
    "                                              mode='min',\n",
    "                                              baseline=None, \n",
    "                                              restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decay(epoch):\n",
    "#     if epoch < 2:\n",
    "#         return 0.01\n",
    "#     elif epoch >= 2 and epoch < 10:\n",
    "#         return 0.005\n",
    "#     else:\n",
    "#         return 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.LearningRateScheduler(decay)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 45.6269 - rmse: 51.9232 - mse: 2696.0208 - mae: 45.6269 - val_loss: 43.2421 - val_rmse: 47.6010 - val_mse: 2265.8538 - val_mae: 43.2421\n",
      "Epoch 2/200\n",
      "54/54 [==============================] - 14s 257ms/step - loss: 40.1601 - rmse: 46.3550 - mse: 2148.7900 - mae: 40.1601 - val_loss: 36.9911 - val_rmse: 41.2054 - val_mse: 1697.8816 - val_mae: 36.9911\n",
      "Epoch 3/200\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 34.5391 - rmse: 40.4743 - mse: 1638.1724 - mae: 34.5391 - val_loss: 30.9183 - val_rmse: 35.0022 - val_mse: 1225.1516 - val_mae: 30.9183\n",
      "Epoch 4/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 28.7877 - rmse: 34.2540 - mse: 1173.3378 - mae: 28.7877 - val_loss: 25.0261 - val_rmse: 28.8388 - val_mse: 831.6771 - val_mae: 25.0261 - mse: 1194.5645 - ma - ETA: 0s - loss: 28.7877 - rmse: 34.2540 - mse: 1173.3378 - mae: 28.78\n",
      "Epoch 5/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 23.0151 - rmse: 27.7885 - mse: 772.1988 - mae: 23.0151 - val_loss: 19.1928 - val_rmse: 22.5427 - val_mse: 508.1711 - val_mae: 19.1928\n",
      "Epoch 6/200\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 17.4938 - rmse: 21.4061 - mse: 458.2215 - mae: 17.4938 - val_loss: 14.2401 - val_rmse: 17.0493 - val_mse: 290.6800 - val_mae: 14.2401\n",
      "Epoch 7/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 12.9079 - rmse: 15.8918 - mse: 252.5479 - mae: 12.9079 - val_loss: 10.7518 - val_rmse: 13.1814 - val_mse: 173.7483 - val_mae: 10.7518\n",
      "Epoch 8/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 10.1923 - rmse: 12.6638 - mse: 160.3717 - mae: 10.1923 - val_loss: 9.5487 - val_rmse: 11.9268 - val_mse: 142.2477 - val_mae: 9.5487\n",
      "Epoch 9/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 9.3494 - rmse: 11.7249 - mse: 137.4729 - mae: 9.3494 - val_loss: 9.2542 - val_rmse: 11.6451 - val_mse: 135.6094 - val_mae: 9.2542\n",
      "Epoch 10/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 9.1469 - rmse: 11.5247 - mse: 132.8183 - mae: 9.1469 - val_loss: 9.2121 - val_rmse: 11.6406 - val_mse: 135.5029 - val_mae: 9.2121\n",
      "Epoch 11/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 9.0725 - rmse: 11.4614 - mse: 131.3627 - mae: 9.0725 - val_loss: 9.1825 - val_rmse: 11.5789 - val_mse: 134.0705 - val_mae: 9.1825\n",
      "Epoch 12/200\n",
      "54/54 [==============================] - 14s 252ms/step - loss: 9.0206 - rmse: 11.4024 - mse: 130.0141 - mae: 9.0206 - val_loss: 9.1927 - val_rmse: 11.6086 - val_mse: 134.7589 - val_mae: 9.1927\n",
      "Epoch 13/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 8.9675 - rmse: 11.3546 - mse: 128.9281 - mae: 8.9675 - val_loss: 9.1073 - val_rmse: 11.5143 - val_mse: 132.5790 - val_mae: 9.1073\n",
      "Epoch 14/200\n",
      "54/54 [==============================] - 14s 252ms/step - loss: 8.9195 - rmse: 11.3030 - mse: 127.7575 - mae: 8.9195 - val_loss: 9.0950 - val_rmse: 11.5165 - val_mse: 132.6294 - val_mae: 9.0950\n",
      "Epoch 15/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 8.8814 - rmse: 11.2591 - mse: 126.7663 - mae: 8.8814 - val_loss: 9.0333 - val_rmse: 11.4309 - val_mse: 130.6655 - val_mae: 9.0333\n",
      "Epoch 16/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.8359 - rmse: 11.2111 - mse: 125.6898 - mae: 8.8359 - val_loss: 9.0329 - val_rmse: 11.4284 - val_mse: 130.6094 - val_mae: 9.0329\n",
      "Epoch 17/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.8069 - rmse: 11.1814 - mse: 125.0243 - mae: 8.8069 - val_loss: 8.9915 - val_rmse: 11.4013 - val_mse: 129.9902 - val_mae: 8.9915\n",
      "Epoch 18/200\n",
      "54/54 [==============================] - 14s 251ms/step - loss: 8.7631 - rmse: 11.1325 - mse: 123.9325 - mae: 8.7631 - val_loss: 8.9572 - val_rmse: 11.3494 - val_mse: 128.8079 - val_mae: 8.9572\n",
      "Epoch 19/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 8.7273 - rmse: 11.0993 - mse: 123.1937 - mae: 8.7273 - val_loss: 8.9455 - val_rmse: 11.3200 - val_mse: 128.1424 - val_mae: 8.9455\n",
      "Epoch 20/200\n",
      "54/54 [==============================] - 14s 252ms/step - loss: 8.7149 - rmse: 11.0781 - mse: 122.7251 - mae: 8.7149 - val_loss: 8.9246 - val_rmse: 11.3176 - val_mse: 128.0882 - val_mae: 8.9246\n",
      "Epoch 21/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 8.6655 - rmse: 11.0241 - mse: 121.5307 - mae: 8.6655 - val_loss: 8.8960 - val_rmse: 11.2840 - val_mse: 127.3281 - val_mae: 8.8960\n",
      "Epoch 22/200\n",
      "54/54 [==============================] - 14s 251ms/step - loss: 8.6396 - rmse: 10.9944 - mse: 120.8763 - mae: 8.6396 - val_loss: 8.8802 - val_rmse: 11.3013 - val_mse: 127.7203 - val_mae: 8.8802\n",
      "Epoch 23/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 8.6157 - rmse: 10.9854 - mse: 120.6786 - mae: 8.6157 - val_loss: 8.8591 - val_rmse: 11.2343 - val_mse: 126.2090 - val_mae: 8.8591\n",
      "Epoch 24/200\n",
      "54/54 [==============================] - 14s 251ms/step - loss: 8.5969 - rmse: 10.9546 - mse: 120.0042 - mae: 8.5969 - val_loss: 8.8110 - val_rmse: 11.1867 - val_mse: 125.1421 - val_mae: 8.8110\n",
      "Epoch 25/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 8.5701 - rmse: 10.9271 - mse: 119.4009 - mae: 8.5701 - val_loss: 8.8405 - val_rmse: 11.2267 - val_mse: 126.0395 - val_mae: 8.8405\n",
      "Epoch 26/200\n",
      "54/54 [==============================] - 14s 252ms/step - loss: 8.5539 - rmse: 10.9110 - mse: 119.0494 - mae: 8.5539 - val_loss: 8.7639 - val_rmse: 11.1236 - val_mse: 123.7347 - val_mae: 8.7639\n",
      "Epoch 27/200\n",
      "54/54 [==============================] - 14s 251ms/step - loss: 8.5297 - rmse: 10.8851 - mse: 118.4855 - mae: 8.5297 - val_loss: 8.7948 - val_rmse: 11.1788 - val_mse: 124.9662 - val_mae: 8.7948\n",
      "Epoch 28/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.5038 - rmse: 10.8635 - mse: 118.0148 - mae: 8.5038 - val_loss: 8.7621 - val_rmse: 11.1299 - val_mse: 123.8754 - val_mae: 8.76215079 - rmse: 10.8691 - mse: 118.1\n",
      "Epoch 29/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.4961 - rmse: 10.8386 - mse: 117.4753 - mae: 8.4961 - val_loss: 8.7483 - val_rmse: 11.1057 - val_mse: 123.3359 - val_mae: 8.7483\n",
      "Epoch 30/200\n",
      "54/54 [==============================] - 14s 257ms/step - loss: 8.4705 - rmse: 10.8207 - mse: 117.0881 - mae: 8.4705 - val_loss: 8.7591 - val_rmse: 11.1380 - val_mse: 124.0549 - val_mae: 8.7591\n",
      "Epoch 31/200\n",
      "54/54 [==============================] - 14s 251ms/step - loss: 8.4412 - rmse: 10.7950 - mse: 116.5322 - mae: 8.4412 - val_loss: 8.7073 - val_rmse: 11.0504 - val_mse: 122.1123 - val_mae: 8.7073: 8.4525 - rmse: 10.8095 - mse: 116.8443 - mae: 8.45\n",
      "Epoch 32/200\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 8.4276 - rmse: 10.7849 - mse: 116.3151 - mae: 8.4276 - val_loss: 8.7465 - val_rmse: 11.1336 - val_mse: 123.9579 - val_mae: 8.7465\n",
      "Epoch 33/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.4082 - rmse: 10.7619 - mse: 115.8190 - mae: 8.4082 - val_loss: 8.6648 - val_rmse: 11.0260 - val_mse: 121.5719 - val_mae: 8.6648\n",
      "Epoch 34/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.3901 - rmse: 10.7360 - mse: 115.2626 - mae: 8.3901 - val_loss: 8.6767 - val_rmse: 11.0388 - val_mse: 121.8561 - val_mae: 8.6767\n",
      "Epoch 35/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 8.3594 - rmse: 10.7086 - mse: 114.6738 - mae: 8.3594 - val_loss: 8.6924 - val_rmse: 11.0571 - val_mse: 122.2590 - val_mae: 8.6924\n",
      "Epoch 36/200\n",
      "54/54 [==============================] - 14s 255ms/step - loss: 8.3580 - rmse: 10.7046 - mse: 114.5884 - mae: 8.3580 - val_loss: 8.7061 - val_rmse: 11.0624 - val_mse: 122.3777 - val_mae: 8.7061\n",
      "Epoch 37/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.3519 - rmse: 10.7006 - mse: 114.5022 - mae: 8.3519 - val_loss: 8.6665 - val_rmse: 11.0270 - val_mse: 121.5947 - val_mae: 8.6665\n",
      "Epoch 38/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.3273 - rmse: 10.6734 - mse: 113.9209 - mae: 8.3273 - val_loss: 8.6310 - val_rmse: 10.9674 - val_mse: 120.2831 - val_mae: 8.6310\n",
      "Epoch 39/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.3166 - rmse: 10.6610 - mse: 113.6560 - mae: 8.3166 - val_loss: 8.6631 - val_rmse: 11.0160 - val_mse: 121.3532 - val_mae: 8.6631\n",
      "Epoch 40/200\n",
      "54/54 [==============================] - 14s 252ms/step - loss: 8.3054 - rmse: 10.6490 - mse: 113.4019 - mae: 8.3054 - val_loss: 8.6601 - val_rmse: 10.9874 - val_mse: 120.7223 - val_mae: 8.6601\n",
      "Epoch 41/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.2915 - rmse: 10.6403 - mse: 113.2166 - mae: 8.2915 - val_loss: 8.6609 - val_rmse: 11.0057 - val_mse: 121.1246 - val_mae: 8.66099 - mse: 112.65\n",
      "Epoch 42/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.2678 - rmse: 10.6229 - mse: 112.8460 - mae: 8.2678 - val_loss: 8.6213 - val_rmse: 10.9594 - val_mse: 120.1076 - val_mae: 8.6213\n",
      "Epoch 43/200\n",
      "54/54 [==============================] - 14s 257ms/step - loss: 8.2566 - rmse: 10.6072 - mse: 112.5135 - mae: 8.2566 - val_loss: 8.6332 - val_rmse: 10.9951 - val_mse: 120.8933 - val_mae: 8.6332\n",
      "Epoch 44/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 8.2621 - rmse: 10.6127 - mse: 112.6289 - mae: 8.2621 - val_loss: 8.5946 - val_rmse: 10.9464 - val_mse: 119.8244 - val_mae: 8.5946\n",
      "Epoch 45/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.2426 - rmse: 10.5938 - mse: 112.2286 - mae: 8.2426 - val_loss: 8.6588 - val_rmse: 10.9962 - val_mse: 120.9168 - val_mae: 8.6588\n",
      "Epoch 46/200\n",
      "54/54 [==============================] - 14s 251ms/step - loss: 8.2337 - rmse: 10.5842 - mse: 112.0257 - mae: 8.2337 - val_loss: 8.6079 - val_rmse: 10.9560 - val_mse: 120.0329 - val_mae: 8.6079\n",
      "Epoch 47/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.2357 - rmse: 10.5881 - mse: 112.1071 - mae: 8.2357 - val_loss: 8.5987 - val_rmse: 10.9478 - val_mse: 119.8541 - val_mae: 8.5987se: 10.6470 -\n",
      "Epoch 48/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.2252 - rmse: 10.5676 - mse: 111.6744 - mae: 8.2252 - val_loss: 8.5642 - val_rmse: 10.8997 - val_mse: 118.8027 - val_mae: 8.5642\n",
      "Epoch 49/200\n",
      "54/54 [==============================] - 14s 255ms/step - loss: 8.2099 - rmse: 10.5540 - mse: 111.3873 - mae: 8.2099 - val_loss: 8.5716 - val_rmse: 10.9065 - val_mse: 118.9528 - val_mae: 8.5716\n",
      "Epoch 50/200\n",
      "54/54 [==============================] - 14s 252ms/step - loss: 8.2051 - rmse: 10.5539 - mse: 111.3842 - mae: 8.2051 - val_loss: 8.6078 - val_rmse: 10.9412 - val_mse: 119.7098 - val_mae: 8.6078\n",
      "Epoch 51/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.1868 - rmse: 10.5427 - mse: 111.1482 - mae: 8.1868 - val_loss: 8.5760 - val_rmse: 10.9094 - val_mse: 119.0156 - val_mae: 8.57608.2601 - rmse: 10.7118 - mse: 114.743 - ETA: 4s - loss: 8.2507 - rmse: 10.6510 - mse: \n",
      "Epoch 52/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.1715 - rmse: 10.5197 - mse: 110.6647 - mae: 8.1715 - val_loss: 8.5751 - val_rmse: 10.9128 - val_mse: 119.0882 - val_mae: 8.5751\n",
      "Epoch 53/200\n",
      "54/54 [==============================] - 14s 255ms/step - loss: 8.1784 - rmse: 10.5228 - mse: 110.7284 - mae: 8.1784 - val_loss: 8.5603 - val_rmse: 10.8901 - val_mse: 118.5938 - val_mae: 8.5603\n",
      "Epoch 54/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.1516 - rmse: 10.5063 - mse: 110.3820 - mae: 8.1516 - val_loss: 8.6210 - val_rmse: 10.9516 - val_mse: 119.9384 - val_mae: 8.6210\n",
      "Epoch 55/200\n",
      "54/54 [==============================] - 14s 251ms/step - loss: 8.1540 - rmse: 10.5080 - mse: 110.4183 - mae: 8.1540 - val_loss: 8.5819 - val_rmse: 10.9194 - val_mse: 119.2330 - val_mae: 8.5819\n",
      "Epoch 56/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.1416 - rmse: 10.4973 - mse: 110.1925 - mae: 8.1416 - val_loss: 8.6050 - val_rmse: 10.9472 - val_mse: 119.8413 - val_mae: 8.6050\n",
      "Epoch 57/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.1420 - rmse: 10.4878 - mse: 109.9941 - mae: 8.1420 - val_loss: 8.5799 - val_rmse: 10.9324 - val_mse: 119.5176 - val_mae: 8.5799\n",
      "Epoch 58/200\n",
      "54/54 [==============================] - 14s 257ms/step - loss: 8.1172 - rmse: 10.4854 - mse: 109.9435 - mae: 8.1172 - val_loss: 8.5768 - val_rmse: 10.9246 - val_mse: 119.3463 - val_mae: 8.5768\n",
      "Epoch 59/200\n",
      "54/54 [==============================] - 14s 251ms/step - loss: 8.1214 - rmse: 10.4795 - mse: 109.8205 - mae: 8.1214 - val_loss: 8.6206 - val_rmse: 10.9469 - val_mse: 119.8340 - val_mae: 8.6206\n",
      "Epoch 60/200\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 8.1199 - rmse: 10.4765 - mse: 109.7575 - mae: 8.1199 - val_loss: 8.5693 - val_rmse: 10.9143 - val_mse: 119.1222 - val_mae: 8.5693\n",
      "Epoch 61/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.1071 - rmse: 10.4619 - mse: 109.4509 - mae: 8.1071 - val_loss: 8.5345 - val_rmse: 10.8764 - val_mse: 118.2956 - val_mae: 8.5345\n",
      "Epoch 62/200\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 8.1071 - rmse: 10.4636 - mse: 109.4870 - mae: 8.1071 - val_loss: 8.5286 - val_rmse: 10.8566 - val_mse: 117.8651 - val_mae: 8.5286\n",
      "Epoch 63/200\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 8.0895 - rmse: 10.4410 - mse: 109.0139 - mae: 8.0895 - val_loss: 8.5614 - val_rmse: 10.9098 - val_mse: 119.0246 - val_mae: 8.5614\n",
      "Epoch 64/200\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 8.0822 - rmse: 10.4441 - mse: 109.0799 - mae: 8.0822 - val_loss: 8.5305 - val_rmse: 10.8540 - val_mse: 117.8098 - val_mae: 8.5305\n",
      "Epoch 65/200\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 8.0804 - rmse: 10.4370 - mse: 108.9317 - mae: 8.0804 - val_loss: 8.5698 - val_rmse: 10.9256 - val_mse: 119.3697 - val_mae: 8.5698\n",
      "Epoch 66/200\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 8.0707 - rmse: 10.4314 - mse: 108.8148 - mae: 8.0707 - val_loss: 8.5483 - val_rmse: 10.8791 - val_mse: 118.3543 - val_mae: 8.5483\n",
      "Epoch 67/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.0629 - rmse: 10.4237 - mse: 108.6529 - mae: 8.0629 - val_loss: 8.5136 - val_rmse: 10.8483 - val_mse: 117.6858 - val_mae: 8.5136\n",
      "Epoch 68/200\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 8.0601 - rmse: 10.4186 - mse: 108.5472 - mae: 8.0601 - val_loss: 8.5150 - val_rmse: 10.8365 - val_mse: 117.4302 - val_mae: 8.5150\n",
      "Epoch 69/200\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 8.0478 - rmse: 10.4070 - mse: 108.3051 - mae: 8.0478 - val_loss: 8.5453 - val_rmse: 10.8979 - val_mse: 118.7648 - val_mae: 8.5453\n",
      "Epoch 70/200\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 8.0498 - rmse: 10.4074 - mse: 108.3144 - mae: 8.0498 - val_loss: 8.5381 - val_rmse: 10.8468 - val_mse: 117.6527 - val_mae: 8.5381\n",
      "Epoch 71/200\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 8.0473 - rmse: 10.4103 - mse: 108.3747 - mae: 8.0473 - val_loss: 8.5541 - val_rmse: 10.8783 - val_mse: 118.3381 - val_mae: 8.5541\n",
      "Epoch 72/200\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 8.0246 - rmse: 10.3890 - mse: 107.9303 - mae: 8.0246 - val_loss: 8.5515 - val_rmse: 10.8995 - val_mse: 118.8000 - val_mae: 8.5515\n",
      "Epoch 73/200\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 8.0160 - rmse: 10.3798 - mse: 107.7395 - mae: 8.0160 - val_loss: 8.5672 - val_rmse: 10.9169 - val_mse: 119.1786 - val_mae: 8.5672\n",
      "Epoch 74/200\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 8.0237 - rmse: 10.3879 - mse: 107.9084 - mae: 8.0237 - val_loss: 8.5614 - val_rmse: 10.8971 - val_mse: 118.7478 - val_mae: 8.5614\n",
      "Epoch 75/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.0135 - rmse: 10.3752 - mse: 107.6458 - mae: 8.0135 - val_loss: 8.5111 - val_rmse: 10.8461 - val_mse: 117.6389 - val_mae: 8.5111\n",
      "Epoch 76/200\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 8.0220 - rmse: 10.3848 - mse: 107.8443 - mae: 8.0220 - val_loss: 8.5817 - val_rmse: 10.9146 - val_mse: 119.1275 - val_mae: 8.5817\n",
      "Epoch 77/200\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 7.9984 - rmse: 10.3712 - mse: 107.5608 - mae: 7.9984 - val_loss: 8.5301 - val_rmse: 10.8611 - val_mse: 117.9626 - val_mae: 8.5301\n",
      "Epoch 78/200\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 8.0050 - rmse: 10.3712 - mse: 107.5609 - mae: 8.0050 - val_loss: 8.5654 - val_rmse: 10.9100 - val_mse: 119.0279 - val_mae: 8.5654\n",
      "Epoch 79/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.0005 - rmse: 10.3723 - mse: 107.5849 - mae: 8.0005 - val_loss: 8.5417 - val_rmse: 10.8669 - val_mse: 118.0898 - val_mae: 8.5417\n",
      "Epoch 80/200\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 7.9940 - rmse: 10.3536 - mse: 107.1976 - mae: 7.9940 - val_loss: 8.5160 - val_rmse: 10.8462 - val_mse: 117.6410 - val_mae: 8.5160\n",
      "Epoch 81/200\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 7.9650 - rmse: 10.3332 - mse: 106.7753 - mae: 7.9650 - val_loss: 8.5410 - val_rmse: 10.8770 - val_mse: 118.3083 - val_mae: 8.5410\n",
      "Epoch 82/200\n",
      "54/54 [==============================] - 14s 255ms/step - loss: 7.9659 - rmse: 10.3376 - mse: 106.8655 - mae: 7.9659 - val_loss: 8.5264 - val_rmse: 10.8445 - val_mse: 117.6035 - val_mae: 8.5264\n",
      "Epoch 83/200\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 7.9716 - rmse: 10.3405 - mse: 106.9252 - mae: 7.9716 - val_loss: 8.5249 - val_rmse: 10.8577 - val_mse: 117.8890 - val_mae: 8.5249\n",
      "Epoch 84/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 7.9690 - rmse: 10.3414 - mse: 106.9443 - mae: 7.9690 - val_loss: 8.5468 - val_rmse: 10.8832 - val_mse: 118.4446 - val_mae: 8.5468\n",
      "Epoch 85/200\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 7.9659 - rmse: 10.3327 - mse: 106.7642 - mae: 7.9659 - val_loss: 8.5015 - val_rmse: 10.8088 - val_mse: 116.8309 - val_mae: 8.5015\n",
      "Epoch 86/200\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 7.9628 - rmse: 10.3328 - mse: 106.7661 - mae: 7.9628 - val_loss: 8.5798 - val_rmse: 10.9161 - val_mse: 119.1608 - val_mae: 8.5798\n",
      "Epoch 87/200\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 7.9497 - rmse: 10.3252 - mse: 106.6100 - mae: 7.9497 - val_loss: 8.5271 - val_rmse: 10.8594 - val_mse: 117.9267 - val_mae: 8.5271\n",
      "Epoch 88/200\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 7.9573 - rmse: 10.3266 - mse: 106.6394 - mae: 7.9573 - val_loss: 8.5131 - val_rmse: 10.8485 - val_mse: 117.6901 - val_mae: 8.5131\n",
      "Epoch 89/200\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 7.9482 - rmse: 10.3216 - mse: 106.5360 - mae: 7.9482 - val_loss: 8.5735 - val_rmse: 10.9177 - val_mse: 119.1967 - val_mae: 8.5735\n",
      "Epoch 90/200\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 7.9416 - rmse: 10.3193 - mse: 106.4882 - mae: 7.9416 - val_loss: 8.5475 - val_rmse: 10.8779 - val_mse: 118.3288 - val_mae: 8.5475\n",
      "Epoch 91/200\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 7.9440 - rmse: 10.3103 - mse: 106.3014 - mae: 7.9440 - val_loss: 8.5662 - val_rmse: 10.9059 - val_mse: 118.9379 - val_mae: 8.5662\n",
      "Epoch 92/200\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 7.9352 - rmse: 10.3104 - mse: 106.3039 - mae: 7.9352 - val_loss: 8.5303 - val_rmse: 10.8612 - val_mse: 117.9665 - val_mae: 8.5303\n",
      "Epoch 93/200\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 7.9320 - rmse: 10.3087 - mse: 106.2700 - mae: 7.9320 - val_loss: 8.4977 - val_rmse: 10.8146 - val_mse: 116.9564 - val_mae: 8.4977\n",
      "Epoch 94/200\n",
      "54/54 [==============================] - 14s 255ms/step - loss: 7.9309 - rmse: 10.3065 - mse: 106.2233 - mae: 7.9309 - val_loss: 8.5641 - val_rmse: 10.8997 - val_mse: 118.8043 - val_mae: 8.5641\n",
      "Epoch 95/200\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 7.9257 - rmse: 10.3046 - mse: 106.1848 - mae: 7.9257 - val_loss: 8.5348 - val_rmse: 10.8778 - val_mse: 118.3274 - val_mae: 8.5348\n",
      "Epoch 96/200\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 7.9014 - rmse: 10.2813 - mse: 105.7048 - mae: 7.9014 - val_loss: 8.5156 - val_rmse: 10.8234 - val_mse: 117.1459 - val_mae: 8.5156\n",
      "Epoch 97/200\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 7.8892 - rmse: 10.2674 - mse: 105.4197 - mae: 7.8892 - val_loss: 8.5567 - val_rmse: 10.8999 - val_mse: 118.8078 - val_mae: 8.5567\n",
      "Epoch 98/200\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 7.8990 - rmse: 10.2825 - mse: 105.7291 - mae: 7.8990 - val_loss: 8.5546 - val_rmse: 10.8929 - val_mse: 118.6558 - val_mae: 8.5546\n",
      "Epoch 99/200\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 7.9024 - rmse: 10.2836 - mse: 105.7530 - mae: 7.9024 - val_loss: 8.5522 - val_rmse: 10.8954 - val_mse: 118.7102 - val_mae: 8.5522\n",
      "Epoch 100/200\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 7.8975 - rmse: 10.2797 - mse: 105.6715 - mae: 7.8975 - val_loss: 8.5575 - val_rmse: 10.8804 - val_mse: 118.3824 - val_mae: 8.5575\n",
      "Epoch 101/200\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 7.8909 - rmse: 10.2727 - mse: 105.5288 - mae: 7.8909 - val_loss: 8.5615 - val_rmse: 10.8885 - val_mse: 118.5590 - val_mae: 8.5615\n",
      "Epoch 102/200\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 7.8948 - rmse: 10.2773 - mse: 105.6227 - mae: 7.8948 - val_loss: 8.5646 - val_rmse: 10.8901 - val_mse: 118.5951 - val_mae: 8.5646\n",
      "Epoch 103/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 7.8890 - rmse: 10.2672 - mse: 105.4150 - mae: 7.8890Restoring model weights from the end of the best epoch.\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 7.8890 - rmse: 10.2672 - mse: 105.4150 - mae: 7.8890 - val_loss: 8.5062 - val_rmse: 10.8391 - val_mse: 117.4866 - val_mae: 8.5062\n",
      "Epoch 00103: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    hist = model.fit(ds_train,\n",
    "                     validation_data=ds_val,\n",
    "                     callbacks=callbacks,\n",
    "                     epochs=200,\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 197ms/step - loss: 8.4362 - rmse: 10.7730 - mse: 116.0568 - mae: 8.4362\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    results = model.evaluate(ds_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Metric')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(16,16)\n",
    "\n",
    "    ax=fig.add_subplot(3,2,1)\n",
    "    ax.plot(hist.history['rmse'])\n",
    "    ax.plot(hist.history['mse'])\n",
    "    ax.legend(['Metric', 'Loss'])\n",
    "    ax.set_title('Train')\n",
    "\n",
    "    ax=fig.add_subplot(3,2,2)\n",
    "    ax.plot(hist.history['val_rmse'])\n",
    "    ax.plot(hist.history['val_mse'])\n",
    "    ax.legend(['Metric', 'Loss'])\n",
    "    ax.set_title('Test')\n",
    "\n",
    "    ax=fig.add_subplot(3,2,3)\n",
    "    ax.plot(hist.history['loss'])\n",
    "    ax.plot(hist.history['val_loss'])\n",
    "    ax.legend(['Train', 'Test'])\n",
    "    ax.set_title('Loss')\n",
    "\n",
    "    ax=fig.add_subplot(3,2,4)\n",
    "    ax.plot(hist.history['mse'])\n",
    "    ax.plot(hist.history['val_mse'])\n",
    "    ax.legend(['Train', 'Test'])\n",
    "    ax.set_title('Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = pd.read_csv('00_Data/fnc.csv')\n",
    "X1_test = X1_test[X1_test['Id'].isin(TEST_IDS)]\n",
    "X1_test = X1_test.to_numpy()\n",
    "X1_test = X1_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_test = pd.read_csv('00_Data/loading.csv')\n",
    "X2_test = X2_test[X2_test['Id'].isin(TEST_IDS)]\n",
    "X2_test = X2_test.to_numpy()\n",
    "X2_test = X2_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict([X1_test, X2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = y_preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = []\n",
    "i = 0\n",
    "for idx in TEST_IDS:\n",
    "    df_submission.append(['{0}_age'.format(idx), y_preds[i]])\n",
    "    df_submission.append(['{0}_domain1_var1'.format(idx), y_preds[i+1]])\n",
    "    df_submission.append(['{0}_domain1_var2'.format(idx), y_preds[i+2]])\n",
    "    df_submission.append(['{0}_domain2_var1'.format(idx), y_preds[i+3]])\n",
    "    df_submission.append(['{0}_domain2_var2'.format(idx), y_preds[i+4]])\n",
    "    i += 5\n",
    "\n",
    "df_submission = pd.DataFrame(df_submission, columns=['Id', 'Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('submission_fnc-load_mae_06.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.108977</td>\n",
       "      <td>69.993075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>21746</td>\n",
       "      <td>14.257265</td>\n",
       "      <td>21.358872</td>\n",
       "      <td>61.165998</td>\n",
       "      <td>51.778483</td>\n",
       "      <td>54.640179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>21747</td>\n",
       "      <td>55.456978</td>\n",
       "      <td>68.169675</td>\n",
       "      <td>29.907995</td>\n",
       "      <td>55.349257</td>\n",
       "      <td>54.019517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>21750</td>\n",
       "      <td>48.948756</td>\n",
       "      <td>55.114811</td>\n",
       "      <td>60.878271</td>\n",
       "      <td>38.617246</td>\n",
       "      <td>50.679885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>21752</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>59.844808</td>\n",
       "      <td>72.303110</td>\n",
       "      <td>55.458281</td>\n",
       "      <td>46.870235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>21754</td>\n",
       "      <td>68.820928</td>\n",
       "      <td>56.594193</td>\n",
       "      <td>34.605868</td>\n",
       "      <td>49.922535</td>\n",
       "      <td>50.383078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2\n",
       "0     10001  57.436077     30.571975     62.553736     53.325130     51.427998\n",
       "1     10002  59.580851     50.969456     67.470628     60.651856     58.311361\n",
       "2     10004  71.413018     53.152498     58.012103     52.418389     62.536641\n",
       "3     10005  66.532630           NaN           NaN     52.108977     69.993075\n",
       "4     10007  38.617381     49.197021     65.674285     40.151376     34.096421\n",
       "...     ...        ...           ...           ...           ...           ...\n",
       "5872  21746  14.257265     21.358872     61.165998     51.778483     54.640179\n",
       "5873  21747  55.456978     68.169675     29.907995     55.349257     54.019517\n",
       "5874  21750  48.948756     55.114811     60.878271     38.617246     50.679885\n",
       "5875  21752  66.532630     59.844808     72.303110     55.458281     46.870235\n",
       "5876  21754  68.820928     56.594193     34.605868     49.922535     50.383078\n",
       "\n",
       "[5877 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('00_Data/train_scores.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nulls = data[data.isnull().any(axis=1)]\n",
    "NULL_IDS = list(data_nulls['Id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
