{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "from IPython.display import IFrame\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "\n",
    "import scipy.stats as sts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing as prep\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn import discriminant_analysis as disan\n",
    "from sklearn import calibration as calib\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn import svm\n",
    "from sklearn import gaussian_process as gaup\n",
    "from sklearn import mixture as mix\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble as ens\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# from keras import models as kermdls\n",
    "# from keras import layers as kerlrs\n",
    "# from keras import metrics as kmetrics\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "import pickle\n",
    "\n",
    "import nilearn as nl\n",
    "from nilearn import plotting, image\n",
    "from nilearn import datasets\n",
    "import nibabel as nb\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13798488165748916945\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14788054892589081454\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6589725830\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13528481202688575572\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9219705741001220020\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnc_10 = pd.read_csv('00_Data/fnc.csv')\n",
    "# fnc_10 = fnc_10.head(5)\n",
    "# for row in fnc_10.iterrows():\n",
    "#     idx = int(row[1][0])\n",
    "#     row = row[1][1:]\n",
    "#     print(row)\n",
    "#     row.to_csv('00_Data/fnc_csv_norm/{0}.csv'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IDS = [map_id.split('.')[0] for map_id in sorted(os.listdir('00_Data/fMRI_test'))]\n",
    "TRAIN_IDS = [map_id.split('.')[0] for map_id in sorted(os.listdir('00_Data/fMRI_train'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.108977</td>\n",
       "      <td>69.993075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>21746</td>\n",
       "      <td>14.257265</td>\n",
       "      <td>21.358872</td>\n",
       "      <td>61.165998</td>\n",
       "      <td>51.778483</td>\n",
       "      <td>54.640179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>21747</td>\n",
       "      <td>55.456978</td>\n",
       "      <td>68.169675</td>\n",
       "      <td>29.907995</td>\n",
       "      <td>55.349257</td>\n",
       "      <td>54.019517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>21750</td>\n",
       "      <td>48.948756</td>\n",
       "      <td>55.114811</td>\n",
       "      <td>60.878271</td>\n",
       "      <td>38.617246</td>\n",
       "      <td>50.679885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>21752</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>59.844808</td>\n",
       "      <td>72.303110</td>\n",
       "      <td>55.458281</td>\n",
       "      <td>46.870235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>21754</td>\n",
       "      <td>68.820928</td>\n",
       "      <td>56.594193</td>\n",
       "      <td>34.605868</td>\n",
       "      <td>49.922535</td>\n",
       "      <td>50.383078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2\n",
       "0     10001  57.436077     30.571975     62.553736     53.325130     51.427998\n",
       "1     10002  59.580851     50.969456     67.470628     60.651856     58.311361\n",
       "2     10004  71.413018     53.152498     58.012103     52.418389     62.536641\n",
       "3     10005  66.532630           NaN           NaN     52.108977     69.993075\n",
       "4     10007  38.617381     49.197021     65.674285     40.151376     34.096421\n",
       "...     ...        ...           ...           ...           ...           ...\n",
       "5872  21746  14.257265     21.358872     61.165998     51.778483     54.640179\n",
       "5873  21747  55.456978     68.169675     29.907995     55.349257     54.019517\n",
       "5874  21750  48.948756     55.114811     60.878271     38.617246     50.679885\n",
       "5875  21752  66.532630     59.844808     72.303110     55.458281     46.870235\n",
       "5876  21754  68.820928     56.594193     34.605868     49.922535     50.383078\n",
       "\n",
       "[5877 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('00_Data/train_scores.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                0\n",
       "age               0\n",
       "domain1_var1    438\n",
       "domain1_var2    438\n",
       "domain2_var1     39\n",
       "domain2_var2     39\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls = data.isnull().sum()\n",
    "# l = len(data.index)\n",
    "\n",
    "# nulls['domain1_var1'] / l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length:  5434\n"
     ]
    }
   ],
   "source": [
    "print('Dataset length: ', len(data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_inputs_fnc(idx, labels):\n",
    "#     df = pd.read_csv('00_Data/fnc_csv/{0}.csv'.format(idx), index_col=0)\n",
    "#     X = np.array(df.values).reshape(-1)\n",
    "#     return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_inputs_loading(idx, labels):\n",
    "#     df = pd.read_csv('00_Data/loading_csv/{0}.csv'.format(idx), index_col=0)\n",
    "#     X = np.array(df.values).reshape(-1)\n",
    "#     return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(idx, labels):\n",
    "    df_fnc = pd.read_csv('00_Data/fnc_csv/{0}.csv'.format(idx), index_col=0)\n",
    "    X_fnc = np.array(df_fnc.values).reshape(-1)\n",
    "    \n",
    "    df_loading = pd.read_csv('00_Data/loading_csv/{0}.csv'.format(idx), index_col=0)\n",
    "    X_loading = np.array(df_loading.values).reshape(-1)\n",
    "#     print(X_fnc[0])\n",
    "#     print(X_loading[0])\n",
    "#     print(labels[0])\n",
    "#     print(X_fnc.shape)\n",
    "#     print(X_loading.shape)\n",
    "#     print(labels.shape)\n",
    "\n",
    "#     X_fnc = tf.convert_to_tensor(X_fnc, dtype=tf.float64)\n",
    "#     X_loading = tf.convert_to_tensor(X_loading, dtype=tf.float64)\n",
    "#     labels = tf.convert_to_tensor(labels, dtype=tf.float64)\n",
    "#     X = tf.tuple([X_fnc, X_loading])\n",
    "\n",
    "#     X = dict()\n",
    "#     X['input_1'] = X_fnc\n",
    "#     X['input_2'] = X_loading\n",
    "    X = (X_fnc, X_loading)\n",
    "    return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_decorator(func):\n",
    "    def wrapper(idx, labels):\n",
    "        # Use a tf.py_function to prevent auto-graph from compiling the method\n",
    "        return tf.py_function(func,\n",
    "                              inp=(idx, labels),\n",
    "                              Tout=tf.float64)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_py_function(func, inp, Tout, name=None):\n",
    "    \n",
    "    def wrapped_func(*flat_inp):\n",
    "        reconstructed_inp = tf.nest.pack_sequence_as(inp, flat_inp,\n",
    "                                                     expand_composites=True)\n",
    "        out = func(*reconstructed_inp)\n",
    "        return tf.nest.flatten(out, expand_composites=True)\n",
    "    \n",
    "    flat_Tout = tf.nest.flatten(Tout, expand_composites=True)\n",
    "    flat_out = tf.py_function(func=wrapped_func, \n",
    "                              inp=tf.nest.flatten(inp, expand_composites=True),\n",
    "                              Tout=[_tensor_spec_to_dtype(v) for v in flat_Tout],\n",
    "                              name=name)\n",
    "    spec_out = tf.nest.map_structure(_dtype_to_tensor_spec, Tout, expand_composites=True)\n",
    "    out = tf.nest.pack_sequence_as(spec_out, flat_out, expand_composites=True)\n",
    "    return out\n",
    "\n",
    "def _dtype_to_tensor_spec(v):\n",
    "    return tf.TensorSpec(None, v) if isinstance(v, tf.dtypes.DType) else v\n",
    "\n",
    "def _tensor_spec_to_dtype(v):\n",
    "    return v.dtype if isinstance(v, tf.TensorSpec) else v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dataset(data, batch_size):\n",
    "#     data = tf.data.Dataset.from_tensor_slices((data['Id'].values, \n",
    "#                                                data[['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']].values))\n",
    "#     data = data.shuffle(buffer_size=5500, seed=30, reshuffle_each_iteration=True)\n",
    "    \n",
    "#     data_fnc = data.map(map_decorator(get_inputs_fnc), \n",
    "#                      num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "#                      deterministic=True)\n",
    "#     data_loading = data.map(map_decorator(get_inputs_loading), \n",
    "#                      num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "#                      deterministic=True)\n",
    "\n",
    "#     data_fnc = data_fnc.batch(batch_size, drop_remainder=True)\n",
    "#     data_fnc = data_fnc.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "#     data_loading = data_loading.batch(batch_size, drop_remainder=True)\n",
    "#     data_loading = data_loading.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#     return (data_fnc, data_loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data, batch_size):\n",
    "    data = tf.data.Dataset.from_tensor_slices((data['Id'].values, \n",
    "                                               data[['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']].values))\n",
    "    data = data.shuffle(buffer_size=5500, seed=30, reshuffle_each_iteration=True)\n",
    "    \n",
    "    data = data.map(lambda idx, lbl:new_py_function(get_inputs, inp=(idx, lbl), Tout=((tf.float64, tf.float64), tf.float64), name=None), \n",
    "                     num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "                     deterministic=True)\n",
    "    data = data.batch(batch_size, drop_remainder=True)\n",
    "    data = data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = model_selection.train_test_split(data, test_size=0.2, shuffle=True, random_state=30)\n",
    "train, val = model_selection.train_test_split(train, test_size=0.2, shuffle=True, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 64\n",
    "\n",
    "# ds_train_fnc, ds_train_loading = get_dataset(train, batch_size)\n",
    "# ds_val_fnc, ds_val_loading = get_dataset(val, batch_size)\n",
    "# ds_test_fnc, ds_test_loading = get_dataset(test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "ds_train = get_dataset(train, batch_size)\n",
    "ds_val = get_dataset(val, batch_size)\n",
    "ds_test = get_dataset(test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.perf_counter()\n",
    "# for f in ds_train.take(1):\n",
    "#     pass\n",
    "# tf.print(\"Execution time:\", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE_fnc = (1378,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE_loading = (26,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_fnc = keras.layers.Input(shape=INPUT_SHAPE_fnc, name='inp_fnc')\n",
    "\n",
    "x = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(inputs_fnc)\n",
    "x = keras.layers.Dense(2048,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x)\n",
    "# x = keras.layers.Dropout(rate=0.2, seed=30)(x)\n",
    "\n",
    "x1 = keras.layers.Dense(512,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x1)\n",
    "# x1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(x1)\n",
    "\n",
    "x11 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x1)\n",
    "x11 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x11)\n",
    "x11 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x11)\n",
    "\n",
    "\n",
    "x12 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x1)\n",
    "x12 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x12)\n",
    "x12 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x12)\n",
    "\n",
    "x1 = keras.layers.concatenate([x11, x12])\n",
    "\n",
    "x1 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x1)\n",
    "x1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x1)\n",
    "x1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x1)\n",
    "\n",
    "x2 = keras.layers.Dense(512,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x2)\n",
    "# x2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(x2)\n",
    "\n",
    "x21 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x2)\n",
    "x21 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x21)\n",
    "x21 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x21)\n",
    "\n",
    "x22 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x2)\n",
    "x22 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x22)\n",
    "x22 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x22)\n",
    "\n",
    "x2 = keras.layers.concatenate([x21, x22])\n",
    "\n",
    "x2 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x2)\n",
    "x2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x2)\n",
    "x2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x2)\n",
    "\n",
    "x = keras.layers.concatenate([x1, x2])\n",
    "\n",
    "# x = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(x)\n",
    "\n",
    "x = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x)\n",
    "\n",
    "# output\n",
    "x = keras.Model(inputs=inputs_fnc, outputs=x, name='model_fnc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_loading = keras.layers.Input(shape=INPUT_SHAPE_loading, name='inp_load')\n",
    "\n",
    "y = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(inputs_loading)\n",
    "\n",
    "y = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y)\n",
    "# y = keras.layers.Dropout(rate=0.2, seed=30)(y)\n",
    "\n",
    "y1 = keras.layers.Dense(128,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y1)\n",
    "# y1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(y1)\n",
    "\n",
    "y11 = keras.layers.Dense(64,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y1)\n",
    "y11 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y11)\n",
    "y11 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y11)\n",
    "\n",
    "\n",
    "y12 = keras.layers.Dense(64,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y1)\n",
    "y12 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y12)\n",
    "y12 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y12)\n",
    "\n",
    "y1 = keras.layers.concatenate([y11, y12])\n",
    "\n",
    "y1 = keras.layers.Dense(128,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y1)\n",
    "y1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y1)\n",
    "y1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y1)\n",
    "\n",
    "y2 = keras.layers.Dense(128,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y2)\n",
    "# y2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(y2)\n",
    "\n",
    "y21 = keras.layers.Dense(64,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y2)\n",
    "y21 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y21)\n",
    "y21 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y21)\n",
    "\n",
    "y22 = keras.layers.Dense(64,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y2)\n",
    "y22 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y22)\n",
    "y22 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y22)\n",
    "\n",
    "y2 = keras.layers.concatenate([y21, y22])\n",
    "\n",
    "y2 = keras.layers.Dense(128,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y2)\n",
    "y2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y2)\n",
    "y2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y2)\n",
    "\n",
    "y = keras.layers.concatenate([y1, y2])\n",
    "\n",
    "# y = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(y)\n",
    "\n",
    "y = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y)\n",
    "# x = keras.layers.Dropout(rate=0.2, seed=30)(x)\n",
    "\n",
    "# output\n",
    "y = keras.Model(inputs=inputs_loading, outputs=y, name='model_loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = keras.layers.concatenate([x.output, y.output])\n",
    "\n",
    "z1 = keras.layers.Dense(512, \n",
    "                       kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                       bias_initializer=keras.initializers.Constant(5.))(concat)\n",
    "z1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(z1)\n",
    "z1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(z1)\n",
    "\n",
    "z2 = keras.layers.Dense(512, \n",
    "                       kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                       bias_initializer=keras.initializers.Constant(5.))(concat)\n",
    "z2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(z2)\n",
    "z2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(z2)\n",
    "\n",
    "z = keras.layers.concatenate([z1, z2])\n",
    "\n",
    "z = keras.layers.Dense(512, \n",
    "                       kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                       bias_initializer=keras.initializers.Constant(5.))(z)\n",
    "z = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(z)\n",
    "\n",
    "outputs = keras.layers.Dense(5, activation='linear')(z)\n",
    "\n",
    "model = keras.Model(inputs=[x.input, y.input], outputs=outputs, name='model_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_combined\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inp_fnc (InputLayer)            [(None, 1378)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inp_load (InputLayer)           [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1378)         5512        inp_fnc[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 26)           104         inp_load[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         2824192     batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          6912        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu (PReLU)                 (None, 2048)         2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_10 (PReLU)              (None, 256)          256         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     p_re_lu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          1049088     p_re_lu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 128)          32896       p_re_lu_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 128)          32896       p_re_lu_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 512)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_5 (PReLU)               (None, 512)          512         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_11 (PReLU)              (None, 128)          128         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_15 (PReLU)              (None, 128)          128         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          131328      p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          131328      p_re_lu_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          131328      p_re_lu_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           8256        p_re_lu_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           8256        p_re_lu_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 64)           8256        p_re_lu_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 64)           8256        p_re_lu_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 256)          256         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_3 (PReLU)               (None, 256)          256         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_6 (PReLU)               (None, 256)          256         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_7 (PReLU)               (None, 256)          256         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_12 (PReLU)              (None, 64)           64          dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_13 (PReLU)              (None, 64)           64          dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_16 (PReLU)              (None, 64)           64          dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_17 (PReLU)              (None, 64)           64          dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        p_re_lu_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256)          1024        p_re_lu_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256)          1024        p_re_lu_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64)           256         p_re_lu_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64)           256         p_re_lu_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64)           256         p_re_lu_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64)           256         p_re_lu_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128)          0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128)          0           batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          131328      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          131328      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 128)          16512       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 128)          16512       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_4 (PReLU)               (None, 256)          256         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_8 (PReLU)               (None, 256)          256         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_14 (PReLU)              (None, 128)          128         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_18 (PReLU)              (None, 128)          128         dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256)          1024        p_re_lu_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128)          512         p_re_lu_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128)          512         p_re_lu_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 256)          0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          131328      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 256)          65792       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_9 (PReLU)               (None, 256)          256         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_19 (PReLU)              (None, 256)          256         dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 512)          0           p_re_lu_9[0][0]                  \n",
      "                                                                 p_re_lu_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 512)          262656      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 512)          262656      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_20 (PReLU)              (None, 512)          512         dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_21 (PReLU)              (None, 512)          512         dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 512)          2048        p_re_lu_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 512)          2048        p_re_lu_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1024)         0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 512)          524800      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_22 (PReLU)              (None, 512)          512         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 5)            2565        p_re_lu_22[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 7,124,469\n",
      "Trainable params: 7,115,517\n",
      "Non-trainable params: 8,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim = keras.optimizers.Adam(lr=0.000001,\n",
    "#                                  beta_1=0.99,\n",
    "#                                  beta_2=0.999,\n",
    "#                                  amsgrad=False)\n",
    "\n",
    "optim = tf.keras.optimizers.Adadelta(learning_rate=0.001, rho=0.95)\n",
    "        \n",
    "METRICS = [keras.metrics.RootMeanSquaredError(name='rmse'),\n",
    "           keras.metrics.MeanSquaredError(name='mse'),\n",
    "           keras.metrics.MeanAbsoluteError(name='mae')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def weighted_mae(y_true, y_pred):\n",
    "# #     tf.print(y_true)\n",
    "#     W = tf.constant([[0.2, 0.2, 0.2, 0.2, 0.2]])\n",
    "# #     tf.print(W / tf.math.reduce_mean(y_true, axis=0))\n",
    "#     return tf.math.reduce_mean(tf.linalg.matmul(tf.math.abs(y_pred - y_true), tf.transpose(W / tf.math.reduce_mean(y_true, axis=0))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mae', metrics=METRICS, optimizer=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint directory to store the checkpoints\n",
    "# Name of the checkpoint files\n",
    "# checkpoint_prefix = os.path.join('./99_Training_checkpoints/fnc-loading', \"ckpt_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/fnc-loading'),\n",
    "#              tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "#                                                 save_weights_only=False),\n",
    "#              tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "#                                                   factor=0.7, \n",
    "#                                                   patience=2, \n",
    "#                                                   verbose=1, \n",
    "#                                                   mode='min',\n",
    "#                                                   min_delta=0.01, \n",
    "#                                                   cooldown=5, \n",
    "#                                                   min_lr=0.00000001),\n",
    "#              tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "#                                               min_delta=0.001, \n",
    "#                                               patience=10, \n",
    "#                                               verbose=1, \n",
    "#                                               mode='min',\n",
    "#                                               baseline=None, \n",
    "#                                               restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/fnc-loading'),\n",
    "#              tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "#                                                   factor=0.7, \n",
    "#                                                   patience=2, \n",
    "#                                                   verbose=1, \n",
    "#                                                   mode='min',\n",
    "#                                                   min_delta=0.01, \n",
    "#                                                   cooldown=5, \n",
    "#                                                   min_lr=0.00000001),\n",
    "#              tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "#                                               min_delta=0.001, \n",
    "#                                               patience=10, \n",
    "#                                               verbose=1, \n",
    "#                                               mode='min',\n",
    "#                                               baseline=None, \n",
    "#                                               restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/fnc-loading'),\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              min_delta=0.001, \n",
    "                                              patience=10, \n",
    "                                              verbose=1, \n",
    "                                              mode='min',\n",
    "                                              baseline=None, \n",
    "                                              restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decay(epoch):\n",
    "#     if epoch < 2:\n",
    "#         return 0.01\n",
    "#     elif epoch >= 2 and epoch < 10:\n",
    "#         return 0.005\n",
    "#     else:\n",
    "#         return 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.LearningRateScheduler(decay)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 54.1484 - rmse: 55.9612 - mse: 3131.6584 - mae: 54.1484 - val_loss: 65.5667 - val_rmse: 69.6381 - val_mse: 4849.4707 - val_mae: 65.5667\n",
      "Epoch 2/400\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 53.9240 - rmse: 55.7458 - mse: 3107.5972 - mae: 53.9240 - val_loss: 59.9129 - val_rmse: 62.8782 - val_mse: 3953.6628 - val_mae: 59.9129\n",
      "Epoch 3/400\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 53.6984 - rmse: 55.5242 - mse: 3082.9407 - mae: 53.6984 - val_loss: 57.4710 - val_rmse: 60.0745 - val_mse: 3608.9492 - val_mae: 57.4710\n",
      "Epoch 4/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 53.4435 - rmse: 55.2788 - mse: 3055.7505 - mae: 53.4435 - val_loss: 55.7235 - val_rmse: 58.0898 - val_mse: 3374.4268 - val_mae: 55.7235\n",
      "Epoch 5/400\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 53.1904 - rmse: 55.0348 - mse: 3028.8247 - mae: 53.1904 - val_loss: 54.4173 - val_rmse: 56.6289 - val_mse: 3206.8284 - val_mae: 54.4173\n",
      "Epoch 6/400\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 52.9212 - rmse: 54.7766 - mse: 3000.4756 - mae: 52.9212 - val_loss: 53.3643 - val_rmse: 55.4712 - val_mse: 3077.0530 - val_mae: 53.3643\n",
      "Epoch 7/400\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 52.6514 - rmse: 54.5170 - mse: 2972.0981 - mae: 52.6514 - val_loss: 52.6492 - val_rmse: 54.6951 - val_mse: 2991.5544 - val_mae: 52.6492\n",
      "Epoch 8/400\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 52.3649 - rmse: 54.2399 - mse: 2941.9651 - mae: 52.3649 - val_loss: 52.2415 - val_rmse: 54.2475 - val_mse: 2942.7866 - val_mae: 52.2415\n",
      "Epoch 9/400\n",
      "54/54 [==============================] - 15s 279ms/step - loss: 52.0782 - rmse: 53.9625 - mse: 2911.9548 - mae: 52.0782 - val_loss: 51.8482 - val_rmse: 53.8085 - val_mse: 2895.3518 - val_mae: 51.8482\n",
      "Epoch 10/400\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 51.7618 - rmse: 53.6571 - mse: 2879.0872 - mae: 51.7618 - val_loss: 51.4921 - val_rmse: 53.4725 - val_mse: 2859.3030 - val_mae: 51.4921\n",
      "Epoch 11/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 51.4625 - rmse: 53.3685 - mse: 2848.1973 - mae: 51.4625 - val_loss: 51.1579 - val_rmse: 53.1242 - val_mse: 2822.1821 - val_mae: 51.1579\n",
      "Epoch 12/400\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 51.1419 - rmse: 53.0593 - mse: 2815.2913 - mae: 51.1419 - val_loss: 50.8215 - val_rmse: 52.8097 - val_mse: 2788.8667 - val_mae: 50.8215\n",
      "Epoch 13/400\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 50.8098 - rmse: 52.7432 - mse: 2781.8486 - mae: 50.8098 - val_loss: 50.5208 - val_rmse: 52.5098 - val_mse: 2757.2808 - val_mae: 50.5208\n",
      "Epoch 14/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 50.4740 - rmse: 52.4167 - mse: 2747.5146 - mae: 50.4740 - val_loss: 50.0923 - val_rmse: 52.0989 - val_mse: 2714.2996 - val_mae: 50.0923\n",
      "Epoch 15/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 50.1296 - rmse: 52.0849 - mse: 2712.8311 - mae: 50.1296 - val_loss: 49.8354 - val_rmse: 51.8381 - val_mse: 2687.1902 - val_mae: 49.8354\n",
      "Epoch 16/400\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 49.7850 - rmse: 51.7542 - mse: 2678.4934 - mae: 49.7850 - val_loss: 49.5093 - val_rmse: 51.5362 - val_mse: 2655.9783 - val_mae: 49.5093\n",
      "Epoch 17/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 49.4314 - rmse: 51.4144 - mse: 2643.4387 - mae: 49.4314 - val_loss: 49.0905 - val_rmse: 51.1230 - val_mse: 2613.5654 - val_mae: 49.0905\n",
      "Epoch 18/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 49.0521 - rmse: 51.0477 - mse: 2605.8672 - mae: 49.0521 - val_loss: 48.6229 - val_rmse: 50.6802 - val_mse: 2568.4780 - val_mae: 48.6229\n",
      "Epoch 19/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 48.6931 - rmse: 50.7048 - mse: 2570.9792 - mae: 48.6931 - val_loss: 48.3167 - val_rmse: 50.3934 - val_mse: 2539.4917 - val_mae: 48.3167\n",
      "Epoch 20/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 48.2949 - rmse: 50.3229 - mse: 2532.3965 - mae: 48.2949 - val_loss: 47.9532 - val_rmse: 50.0416 - val_mse: 2504.1636 - val_mae: 47.9532\n",
      "Epoch 21/400\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 47.9250 - rmse: 49.9635 - mse: 2496.3513 - mae: 47.9250 - val_loss: 47.5866 - val_rmse: 49.6917 - val_mse: 2469.2639 - val_mae: 47.5866\n",
      "Epoch 22/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 47.5250 - rmse: 49.5834 - mse: 2458.5171 - mae: 47.5250 - val_loss: 47.2198 - val_rmse: 49.3448 - val_mse: 2434.9084 - val_mae: 47.2198\n",
      "Epoch 23/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 47.1248 - rmse: 49.2009 - mse: 2420.7319 - mae: 47.1248 - val_loss: 46.7308 - val_rmse: 48.8558 - val_mse: 2386.8896 - val_mae: 46.7308\n",
      "Epoch 24/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 46.7010 - rmse: 48.7955 - mse: 2381.0007 - mae: 46.7010 - val_loss: 46.2629 - val_rmse: 48.4157 - val_mse: 2344.0830 - val_mae: 46.2629\n",
      "Epoch 25/400\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 46.2998 - rmse: 48.4099 - mse: 2343.5208 - mae: 46.2998 - val_loss: 45.9407 - val_rmse: 48.1277 - val_mse: 2316.2705 - val_mae: 45.9407\n",
      "Epoch 26/400\n",
      "54/54 [==============================] - 15s 276ms/step - loss: 45.8747 - rmse: 48.0046 - mse: 2304.4419 - mae: 45.8747 - val_loss: 45.4922 - val_rmse: 47.6993 - val_mse: 2275.2222 - val_mae: 45.4922\n",
      "Epoch 27/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 45.4643 - rmse: 47.6098 - mse: 2266.6919 - mae: 45.4643 - val_loss: 45.0460 - val_rmse: 47.2628 - val_mse: 2233.7751 - val_mae: 45.0460\n",
      "Epoch 28/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 45.0276 - rmse: 47.1930 - mse: 2227.1785 - mae: 45.0276 - val_loss: 44.6959 - val_rmse: 46.9324 - val_mse: 2202.6543 - val_mae: 44.6959\n",
      "Epoch 29/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 44.5963 - rmse: 46.7812 - mse: 2188.4814 - mae: 44.5963 - val_loss: 44.2081 - val_rmse: 46.4707 - val_mse: 2159.5291 - val_mae: 44.2081\n",
      "Epoch 30/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 44.1498 - rmse: 46.3609 - mse: 2149.3308 - mae: 44.1498 - val_loss: 43.7691 - val_rmse: 46.0651 - val_mse: 2121.9922 - val_mae: 43.7691\n",
      "Epoch 31/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 43.6988 - rmse: 45.9258 - mse: 2109.1743 - mae: 43.6988 - val_loss: 43.3105 - val_rmse: 45.6053 - val_mse: 2079.8416 - val_mae: 43.3105\n",
      "Epoch 32/400\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 43.2453 - rmse: 45.4980 - mse: 2070.0630 - mae: 43.2453 - val_loss: 42.8310 - val_rmse: 45.1670 - val_mse: 2040.0581 - val_mae: 42.8310\n",
      "Epoch 33/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 42.7644 - rmse: 45.0401 - mse: 2028.6084 - mae: 42.7644 - val_loss: 42.4668 - val_rmse: 44.7982 - val_mse: 2006.8829 - val_mae: 42.4668\n",
      "Epoch 34/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 42.3089 - rmse: 44.6054 - mse: 1989.6377 - mae: 42.3089 - val_loss: 41.8968 - val_rmse: 44.2682 - val_mse: 1959.6746 - val_mae: 41.8968\n",
      "Epoch 35/400\n",
      "54/54 [==============================] - 15s 279ms/step - loss: 41.8430 - rmse: 44.1587 - mse: 1949.9921 - mae: 41.8430 - val_loss: 41.4509 - val_rmse: 43.8523 - val_mse: 1923.0208 - val_mae: 41.4509\n",
      "Epoch 36/400\n",
      "54/54 [==============================] - 15s 276ms/step - loss: 41.3467 - rmse: 43.6886 - mse: 1908.6906 - mae: 41.3467 - val_loss: 40.8944 - val_rmse: 43.3116 - val_mse: 1875.8911 - val_mae: 40.8944\n",
      "Epoch 37/400\n",
      "54/54 [==============================] - 15s 280ms/step - loss: 40.8682 - rmse: 43.2393 - mse: 1869.6381 - mae: 40.8682 - val_loss: 40.6137 - val_rmse: 43.0402 - val_mse: 1852.4615 - val_mae: 40.6137\n",
      "Epoch 38/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 40.3837 - rmse: 42.7803 - mse: 1830.1530 - mae: 40.3837 - val_loss: 39.9827 - val_rmse: 42.4504 - val_mse: 1802.0326 - val_mae: 39.9827\n",
      "Epoch 39/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 39.8785 - rmse: 42.3048 - mse: 1789.6995 - mae: 39.8785 - val_loss: 39.5287 - val_rmse: 42.0384 - val_mse: 1767.2245 - val_mae: 39.5287\n",
      "Epoch 40/400\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 39.3892 - rmse: 41.8411 - mse: 1750.6749 - mae: 39.3892 - val_loss: 39.0532 - val_rmse: 41.5689 - val_mse: 1727.9705 - val_mae: 39.0532\n",
      "Epoch 41/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 38.8672 - rmse: 41.3475 - mse: 1709.6194 - mae: 38.8672 - val_loss: 38.5193 - val_rmse: 41.0798 - val_mse: 1687.5508 - val_mae: 38.5193\n",
      "Epoch 42/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 38.3776 - rmse: 40.8829 - mse: 1671.4155 - mae: 38.3776 - val_loss: 37.9706 - val_rmse: 40.5564 - val_mse: 1644.8248 - val_mae: 37.9706\n",
      "Epoch 43/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 37.8668 - rmse: 40.4020 - mse: 1632.3181 - mae: 37.8668 - val_loss: 37.4323 - val_rmse: 40.0466 - val_mse: 1603.7283 - val_mae: 37.4323\n",
      "Epoch 44/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 37.3460 - rmse: 39.9137 - mse: 1593.1017 - mae: 37.3460 - val_loss: 36.9428 - val_rmse: 39.5899 - val_mse: 1567.3579 - val_mae: 36.9428\n",
      "Epoch 45/400\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 36.8119 - rmse: 39.4143 - mse: 1553.4873 - mae: 36.8119 - val_loss: 36.4141 - val_rmse: 39.0963 - val_mse: 1528.5173 - val_mae: 36.4141\n",
      "Epoch 46/400\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 36.2887 - rmse: 38.9195 - mse: 1514.7271 - mae: 36.2887 - val_loss: 35.9048 - val_rmse: 38.5993 - val_mse: 1489.9095 - val_mae: 35.9048\n",
      "Epoch 47/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 35.7387 - rmse: 38.4099 - mse: 1475.3214 - mae: 35.7387 - val_loss: 35.3260 - val_rmse: 38.0763 - val_mse: 1449.8032 - val_mae: 35.3260\n",
      "Epoch 48/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 35.2109 - rmse: 37.9069 - mse: 1436.9331 - mae: 35.2109 - val_loss: 34.8213 - val_rmse: 37.5871 - val_mse: 1412.7874 - val_mae: 34.8213\n",
      "Epoch 49/400\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 34.6856 - rmse: 37.4206 - mse: 1400.3044 - mae: 34.6856 - val_loss: 34.2968 - val_rmse: 37.1096 - val_mse: 1377.1217 - val_mae: 34.2968\n",
      "Epoch 50/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 34.1337 - rmse: 36.9053 - mse: 1361.9991 - mae: 34.1337 - val_loss: 33.7298 - val_rmse: 36.5892 - val_mse: 1338.7704 - val_mae: 33.7298\n",
      "Epoch 51/400\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 33.5853 - rmse: 36.3943 - mse: 1324.5483 - mae: 33.5853 - val_loss: 33.2580 - val_rmse: 36.1339 - val_mse: 1305.6576 - val_mae: 33.2580\n",
      "Epoch 52/400\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 33.0266 - rmse: 35.8690 - mse: 1286.5823 - mae: 33.0266 - val_loss: 32.6536 - val_rmse: 35.5474 - val_mse: 1263.6202 - val_mae: 32.6536\n",
      "Epoch 53/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 32.4742 - rmse: 35.3541 - mse: 1249.9115 - mae: 32.4742 - val_loss: 32.1363 - val_rmse: 35.0642 - val_mse: 1229.5009 - val_mae: 32.1363\n",
      "Epoch 54/400\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 31.9184 - rmse: 34.8332 - mse: 1213.3552 - mae: 31.9184 - val_loss: 31.5769 - val_rmse: 34.5799 - val_mse: 1195.7711 - val_mae: 31.5769\n",
      "Epoch 55/400\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 31.3533 - rmse: 34.3073 - mse: 1176.9924 - mae: 31.3533 - val_loss: 30.9453 - val_rmse: 33.9668 - val_mse: 1153.7439 - val_mae: 30.9453\n",
      "Epoch 56/400\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 30.7813 - rmse: 33.7714 - mse: 1140.5085 - mae: 30.7813 - val_loss: 30.4980 - val_rmse: 33.5462 - val_mse: 1125.3496 - val_mae: 30.4980\n",
      "Epoch 57/400\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 30.2248 - rmse: 33.2544 - mse: 1105.8575 - mae: 30.2248 - val_loss: 29.8248 - val_rmse: 32.9047 - val_mse: 1082.7188 - val_mae: 29.8248\n",
      "Epoch 58/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 29.6513 - rmse: 32.7167 - mse: 1070.3845 - mae: 29.6513 - val_loss: 29.2799 - val_rmse: 32.3991 - val_mse: 1049.6985 - val_mae: 29.2799\n",
      "Epoch 59/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 29.0767 - rmse: 32.1814 - mse: 1035.6396 - mae: 29.0767 - val_loss: 28.7773 - val_rmse: 31.9181 - val_mse: 1018.7632 - val_mae: 28.7773\n",
      "Epoch 60/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 28.5210 - rmse: 31.6614 - mse: 1002.4434 - mae: 28.5210 - val_loss: 28.1725 - val_rmse: 31.3260 - val_mse: 981.3190 - val_mae: 28.1725\n",
      "Epoch 61/400\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 27.9509 - rmse: 31.1270 - mse: 968.8903 - mae: 27.9509 - val_loss: 27.6626 - val_rmse: 30.8592 - val_mse: 952.2916 - val_mae: 27.6626\n",
      "Epoch 62/400\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 27.3656 - rmse: 30.5783 - mse: 935.0296 - mae: 27.3656 - val_loss: 27.0765 - val_rmse: 30.3228 - val_mse: 919.4750 - val_mae: 27.0765\n",
      "Epoch 63/400\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 26.8082 - rmse: 30.0491 - mse: 902.9460 - mae: 26.8082 - val_loss: 26.5678 - val_rmse: 29.8399 - val_mse: 890.4222 - val_mae: 26.5678\n",
      "Epoch 64/400\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 26.2500 - rmse: 29.5270 - mse: 871.8431 - mae: 26.2500 - val_loss: 25.9752 - val_rmse: 29.2511 - val_mse: 855.6240 - val_mae: 25.9752\n",
      "Epoch 65/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 25.6678 - rmse: 28.9717 - mse: 839.3593 - mae: 25.6678 - val_loss: 25.3712 - val_rmse: 28.7004 - val_mse: 823.7119 - val_mae: 25.3712\n",
      "Epoch 66/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 25.1133 - rmse: 28.4457 - mse: 809.1596 - mae: 25.1133 - val_loss: 24.8725 - val_rmse: 28.2344 - val_mse: 797.1837 - val_mae: 24.8725\n",
      "Epoch 67/400\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 24.5628 - rmse: 27.9223 - mse: 779.6555 - mae: 24.5628 - val_loss: 24.3148 - val_rmse: 27.6724 - val_mse: 765.7606 - val_mae: 24.3148\n",
      "Epoch 68/400\n",
      "54/54 [==============================] - 15s 276ms/step - loss: 23.9908 - rmse: 27.3784 - mse: 749.5785 - mae: 23.9908 - val_loss: 23.7867 - val_rmse: 27.1873 - val_mse: 739.1494 - val_mae: 23.7867\n",
      "Epoch 69/400\n",
      "54/54 [==============================] - 15s 276ms/step - loss: 23.4152 - rmse: 26.8357 - mse: 720.1523 - mae: 23.4152 - val_loss: 23.2637 - val_rmse: 26.7098 - val_mse: 713.4157 - val_mae: 23.2637\n",
      "Epoch 70/400\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 22.8716 - rmse: 26.3104 - mse: 692.2386 - mae: 22.8716 - val_loss: 22.7633 - val_rmse: 26.2070 - val_mse: 686.8091 - val_mae: 22.7633\n",
      "Epoch 71/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 22.3354 - rmse: 25.7963 - mse: 665.4485 - mae: 22.3354 - val_loss: 22.2343 - val_rmse: 25.6919 - val_mse: 660.0754 - val_mae: 22.2343\n",
      "Epoch 72/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 21.7942 - rmse: 25.2666 - mse: 638.3986 - mae: 21.7942 - val_loss: 21.7354 - val_rmse: 25.1892 - val_mse: 634.4973 - val_mae: 21.7354\n",
      "Epoch 73/400\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 21.2611 - rmse: 24.7535 - mse: 612.7349 - mae: 21.2611 - val_loss: 21.2608 - val_rmse: 24.7295 - val_mse: 611.5496 - val_mae: 21.2608\n",
      "Epoch 74/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 20.7186 - rmse: 24.2217 - mse: 586.6891 - mae: 20.7186 - val_loss: 20.6294 - val_rmse: 24.1092 - val_mse: 581.2511 - val_mae: 20.6294\n",
      "Epoch 75/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 20.2087 - rmse: 23.7249 - mse: 562.8697 - mae: 20.2087 - val_loss: 20.1009 - val_rmse: 23.5867 - val_mse: 556.3326 - val_mae: 20.1009\n",
      "Epoch 76/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 19.6854 - rmse: 23.2085 - mse: 538.6329 - mae: 19.6854 - val_loss: 19.7148 - val_rmse: 23.1787 - val_mse: 537.2513 - val_mae: 19.7148\n",
      "Epoch 77/400\n",
      "54/54 [==============================] - 15s 273ms/step - loss: 19.1785 - rmse: 22.7077 - mse: 515.6398 - mae: 19.1785 - val_loss: 19.2427 - val_rmse: 22.7092 - val_mse: 515.7083 - val_mae: 19.2427\n",
      "Epoch 78/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 18.6753 - rmse: 22.2052 - mse: 493.0723 - mae: 18.6753 - val_loss: 18.6749 - val_rmse: 22.1515 - val_mse: 490.6873 - val_mae: 18.6749\n",
      "Epoch 79/400\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 18.2068 - rmse: 21.7263 - mse: 472.0309 - mae: 18.2068 - val_loss: 18.1759 - val_rmse: 21.6702 - val_mse: 469.5972 - val_mae: 18.1759\n",
      "Epoch 80/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 17.7264 - rmse: 21.2371 - mse: 451.0149 - mae: 17.7264 - val_loss: 17.6569 - val_rmse: 21.1289 - val_mse: 446.4324 - val_mae: 17.6569\n",
      "Epoch 81/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 17.2667 - rmse: 20.7574 - mse: 430.8690 - mae: 17.2667 - val_loss: 17.2511 - val_rmse: 20.7104 - val_mse: 428.9206 - val_mae: 17.2511\n",
      "Epoch 82/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 16.8115 - rmse: 20.2953 - mse: 411.8978 - mae: 16.8115 - val_loss: 16.8549 - val_rmse: 20.2907 - val_mse: 411.7105 - val_mae: 16.8549\n",
      "Epoch 83/400\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 16.3794 - rmse: 19.8381 - mse: 393.5493 - mae: 16.3794 - val_loss: 16.3182 - val_rmse: 19.7417 - val_mse: 389.7362 - val_mae: 16.3182\n",
      "Epoch 84/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 15.9460 - rmse: 19.3733 - mse: 375.3246 - mae: 15.9460 - val_loss: 16.0071 - val_rmse: 19.3830 - val_mse: 375.7025 - val_mae: 16.0071\n",
      "Epoch 85/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 15.5318 - rmse: 18.9376 - mse: 358.6321 - mae: 15.5318 - val_loss: 15.5364 - val_rmse: 18.8962 - val_mse: 357.0650 - val_mae: 15.5364\n",
      "Epoch 86/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 15.1390 - rmse: 18.5110 - mse: 342.6588 - mae: 15.1390 - val_loss: 15.2015 - val_rmse: 18.5236 - val_mse: 343.1242 - val_mae: 15.2015\n",
      "Epoch 87/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 14.7439 - rmse: 18.0840 - mse: 327.0310 - mae: 14.7439 - val_loss: 14.7958 - val_rmse: 18.0769 - val_mse: 326.7742 - val_mae: 14.7958\n",
      "Epoch 88/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 14.3849 - rmse: 17.6854 - mse: 312.7722 - mae: 14.3849 - val_loss: 14.4903 - val_rmse: 17.7209 - val_mse: 314.0303 - val_mae: 14.4903\n",
      "Epoch 89/400\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 14.0057 - rmse: 17.2739 - mse: 298.3875 - mae: 14.0057 - val_loss: 14.0913 - val_rmse: 17.3256 - val_mse: 300.1758 - val_mae: 14.0913\n",
      "Epoch 90/400\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 13.6538 - rmse: 16.8775 - mse: 284.8501 - mae: 13.6538 - val_loss: 13.7318 - val_rmse: 16.9160 - val_mse: 286.1515 - val_mae: 13.7318\n",
      "Epoch 91/400\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 13.3154 - rmse: 16.4941 - mse: 272.0556 - mae: 13.3154 - val_loss: 13.4209 - val_rmse: 16.5441 - val_mse: 273.7061 - val_mae: 13.4209\n",
      "Epoch 92/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 12.9955 - rmse: 16.1334 - mse: 260.2869 - mae: 12.9955 - val_loss: 13.1113 - val_rmse: 16.1861 - val_mse: 261.9914 - val_mae: 13.1113\n",
      "Epoch 93/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 12.6886 - rmse: 15.7777 - mse: 248.9349 - mae: 12.6886 - val_loss: 12.7951 - val_rmse: 15.8079 - val_mse: 249.8886 - val_mae: 12.7951\n",
      "Epoch 94/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 12.3921 - rmse: 15.4352 - mse: 238.2441 - mae: 12.3921 - val_loss: 12.4809 - val_rmse: 15.4733 - val_mse: 239.4217 - val_mae: 12.4809\n",
      "Epoch 95/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 12.1042 - rmse: 15.1036 - mse: 228.1201 - mae: 12.1042 - val_loss: 12.2272 - val_rmse: 15.1718 - val_mse: 230.1823 - val_mae: 12.2272\n",
      "Epoch 96/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 11.8292 - rmse: 14.7737 - mse: 218.2633 - mae: 11.8292 - val_loss: 12.0024 - val_rmse: 14.9032 - val_mse: 222.1063 - val_mae: 12.0024\n",
      "Epoch 97/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 11.5684 - rmse: 14.4686 - mse: 209.3405 - mae: 11.5684 - val_loss: 11.7323 - val_rmse: 14.5743 - val_mse: 212.4116 - val_mae: 11.7323\n",
      "Epoch 98/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 11.3377 - rmse: 14.1891 - mse: 201.3297 - mae: 11.3377 - val_loss: 11.5185 - val_rmse: 14.3376 - val_mse: 205.5675 - val_mae: 11.5185\n",
      "Epoch 99/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 11.0970 - rmse: 13.9038 - mse: 193.3148 - mae: 11.0970 - val_loss: 11.2986 - val_rmse: 14.0819 - val_mse: 198.2993 - val_mae: 11.2986\n",
      "Epoch 100/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 10.8775 - rmse: 13.6376 - mse: 185.9833 - mae: 10.8775 - val_loss: 11.0628 - val_rmse: 13.7721 - val_mse: 189.6702 - val_mae: 11.0628\n",
      "Epoch 101/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 10.6647 - rmse: 13.3876 - mse: 179.2287 - mae: 10.6647 - val_loss: 10.8661 - val_rmse: 13.5560 - val_mse: 183.7645 - val_mae: 10.8661\n",
      "Epoch 102/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 10.4703 - rmse: 13.1532 - mse: 173.0064 - mae: 10.4703 - val_loss: 10.6681 - val_rmse: 13.2980 - val_mse: 176.8359 - val_mae: 10.6681\n",
      "Epoch 103/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 10.2939 - rmse: 12.9339 - mse: 167.2848 - mae: 10.2939 - val_loss: 10.4198 - val_rmse: 13.0301 - val_mse: 169.7838 - val_mae: 10.4198\n",
      "Epoch 104/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 10.1185 - rmse: 12.7286 - mse: 162.0160 - mae: 10.1185 - val_loss: 10.3115 - val_rmse: 12.8945 - val_mse: 166.2674 - val_mae: 10.3115\n",
      "Epoch 105/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 9.9570 - rmse: 12.5217 - mse: 156.7935 - mae: 9.9570 - val_loss: 10.1554 - val_rmse: 12.6849 - val_mse: 160.9061 - val_mae: 10.1554\n",
      "Epoch 106/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 9.8007 - rmse: 12.3372 - mse: 152.2056 - mae: 9.8007 - val_loss: 9.9956 - val_rmse: 12.5087 - val_mse: 156.4670 - val_mae: 9.9956\n",
      "Epoch 107/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 9.6654 - rmse: 12.1645 - mse: 147.9744 - mae: 9.6654 - val_loss: 9.8905 - val_rmse: 12.3908 - val_mse: 153.5311 - val_mae: 9.8905\n",
      "Epoch 108/400\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 9.5284 - rmse: 11.9938 - mse: 143.8523 - mae: 9.5284 - val_loss: 9.7094 - val_rmse: 12.1876 - val_mse: 148.5366 - val_mae: 9.7094\n",
      "Epoch 109/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 9.4086 - rmse: 11.8556 - mse: 140.5560 - mae: 9.4086 - val_loss: 9.5946 - val_rmse: 12.0388 - val_mse: 144.9327 - val_mae: 9.5946\n",
      "Epoch 110/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 9.2937 - rmse: 11.7125 - mse: 137.1821 - mae: 9.2937 - val_loss: 9.5598 - val_rmse: 11.9925 - val_mse: 143.8211 - val_mae: 9.5598 mae: \n",
      "Epoch 111/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 9.1778 - rmse: 11.5775 - mse: 134.0377 - mae: 9.1778 - val_loss: 9.4927 - val_rmse: 11.9010 - val_mse: 141.6329 - val_mae: 9.4927\n",
      "Epoch 112/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 9.0989 - rmse: 11.4742 - mse: 131.6580 - mae: 9.0989 - val_loss: 9.3480 - val_rmse: 11.7452 - val_mse: 137.9493 - val_mae: 9.3480\n",
      "Epoch 113/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 9.0054 - rmse: 11.3635 - mse: 129.1299 - mae: 9.0054 - val_loss: 9.3056 - val_rmse: 11.6745 - val_mse: 136.2938 - val_mae: 9.3056\n",
      "Epoch 114/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 8.9175 - rmse: 11.2595 - mse: 126.7773 - mae: 8.9175 - val_loss: 9.2089 - val_rmse: 11.5557 - val_mse: 133.5331 - val_mae: 9.2089\n",
      "Epoch 115/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.8375 - rmse: 11.1678 - mse: 124.7187 - mae: 8.8375 - val_loss: 9.1424 - val_rmse: 11.4809 - val_mse: 131.8100 - val_mae: 9.1424\n",
      "Epoch 116/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 8.7709 - rmse: 11.0867 - mse: 122.9140 - mae: 8.7709 - val_loss: 9.0731 - val_rmse: 11.4228 - val_mse: 130.4806 - val_mae: 9.0731\n",
      "Epoch 117/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.7210 - rmse: 11.0207 - mse: 121.4556 - mae: 8.7210 - val_loss: 9.0024 - val_rmse: 11.3280 - val_mse: 128.3243 - val_mae: 9.0024\n",
      "Epoch 118/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.6544 - rmse: 10.9490 - mse: 119.8803 - mae: 8.6544 - val_loss: 8.9787 - val_rmse: 11.3049 - val_mse: 127.8003 - val_mae: 8.9787\n",
      "Epoch 119/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.6077 - rmse: 10.8893 - mse: 118.5774 - mae: 8.6077 - val_loss: 8.9275 - val_rmse: 11.2539 - val_mse: 126.6501 - val_mae: 8.9275\n",
      "Epoch 120/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.5406 - rmse: 10.8196 - mse: 117.0639 - mae: 8.5406 - val_loss: 8.8808 - val_rmse: 11.1700 - val_mse: 124.7682 - val_mae: 8.8808\n",
      "Epoch 121/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 8.5015 - rmse: 10.7742 - mse: 116.0825 - mae: 8.5015 - val_loss: 8.8403 - val_rmse: 11.1483 - val_mse: 124.2840 - val_mae: 8.8403\n",
      "Epoch 122/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.4474 - rmse: 10.7066 - mse: 114.6317 - mae: 8.4474 - val_loss: 8.7867 - val_rmse: 11.0839 - val_mse: 122.8522 - val_mae: 8.7867\n",
      "Epoch 123/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 8.4335 - rmse: 10.6945 - mse: 114.3718 - mae: 8.4335 - val_loss: 8.7636 - val_rmse: 11.0759 - val_mse: 122.6747 - val_mae: 8.7636\n",
      "Epoch 124/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.3879 - rmse: 10.6427 - mse: 113.2661 - mae: 8.3879 - val_loss: 8.7257 - val_rmse: 11.0159 - val_mse: 121.3498 - val_mae: 8.7257se: 10.7495 \n",
      "Epoch 125/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 8.3596 - rmse: 10.6097 - mse: 112.5665 - mae: 8.3596 - val_loss: 8.7636 - val_rmse: 11.0622 - val_mse: 122.3719 - val_mae: 8.7636\n",
      "Epoch 126/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.3333 - rmse: 10.5871 - mse: 112.0859 - mae: 8.3333 - val_loss: 8.7155 - val_rmse: 11.0091 - val_mse: 121.1997 - val_mae: 8.7155\n",
      "Epoch 127/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 8.3008 - rmse: 10.5443 - mse: 111.1831 - mae: 8.3008 - val_loss: 8.7302 - val_rmse: 11.0083 - val_mse: 121.1829 - val_mae: 8.7302\n",
      "Epoch 128/400\n",
      "54/54 [==============================] - 15s 280ms/step - loss: 8.2691 - rmse: 10.5207 - mse: 110.6860 - mae: 8.2691 - val_loss: 8.6760 - val_rmse: 10.9709 - val_mse: 120.3598 - val_mae: 8.6760\n",
      "Epoch 129/400\n",
      "54/54 [==============================] - 15s 276ms/step - loss: 8.2617 - rmse: 10.5112 - mse: 110.4847 - mae: 8.2617 - val_loss: 8.6231 - val_rmse: 10.9148 - val_mse: 119.1324 - val_mae: 8.6231\n",
      "Epoch 130/400\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 8.2288 - rmse: 10.4772 - mse: 109.7719 - mae: 8.2288 - val_loss: 8.6684 - val_rmse: 10.9638 - val_mse: 120.2058 - val_mae: 8.6684\n",
      "Epoch 131/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 8.2156 - rmse: 10.4720 - mse: 109.6637 - mae: 8.2156 - val_loss: 8.6582 - val_rmse: 10.9499 - val_mse: 119.8998 - val_mae: 8.6582\n",
      "Epoch 132/400\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 8.1847 - rmse: 10.4374 - mse: 108.9398 - mae: 8.1847 - val_loss: 8.6134 - val_rmse: 10.8922 - val_mse: 118.6409 - val_mae: 8.6134\n",
      "Epoch 133/400\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 8.1824 - rmse: 10.4336 - mse: 108.8592 - mae: 8.1824 - val_loss: 8.5936 - val_rmse: 10.8735 - val_mse: 118.2335 - val_mae: 8.5936\n",
      "Epoch 134/400\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 8.1803 - rmse: 10.4333 - mse: 108.8540 - mae: 8.1803 - val_loss: 8.6141 - val_rmse: 10.9090 - val_mse: 119.0072 - val_mae: 8.6141\n",
      "Epoch 135/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 8.1453 - rmse: 10.4017 - mse: 108.1962 - mae: 8.1453 - val_loss: 8.6019 - val_rmse: 10.8909 - val_mse: 118.6106 - val_mae: 8.6019\n",
      "Epoch 136/400\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 8.1459 - rmse: 10.3993 - mse: 108.1454 - mae: 8.1459 - val_loss: 8.5723 - val_rmse: 10.8660 - val_mse: 118.0708 - val_mae: 8.5723\n",
      "Epoch 137/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 8.1165 - rmse: 10.3806 - mse: 107.7567 - mae: 8.1165 - val_loss: 8.6231 - val_rmse: 10.9237 - val_mse: 119.3265 - val_mae: 8.6231\n",
      "Epoch 138/400\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 8.1011 - rmse: 10.3639 - mse: 107.4111 - mae: 8.1011 - val_loss: 8.5769 - val_rmse: 10.8657 - val_mse: 118.0627 - val_mae: 8.5769\n",
      "Epoch 139/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 8.1013 - rmse: 10.3631 - mse: 107.3932 - mae: 8.1013 - val_loss: 8.5590 - val_rmse: 10.8504 - val_mse: 117.7309 - val_mae: 8.5590\n",
      "Epoch 140/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.0864 - rmse: 10.3503 - mse: 107.1288 - mae: 8.0864 - val_loss: 8.6062 - val_rmse: 10.9189 - val_mse: 119.2225 - val_mae: 8.6062\n",
      "Epoch 141/400\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 8.0917 - rmse: 10.3581 - mse: 107.2909 - mae: 8.0917 - val_loss: 8.5951 - val_rmse: 10.9012 - val_mse: 118.8368 - val_mae: 8.5951\n",
      "Epoch 142/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 8.0763 - rmse: 10.3365 - mse: 106.8438 - mae: 8.0763 - val_loss: 8.6094 - val_rmse: 10.9238 - val_mse: 119.3283 - val_mae: 8.6094\n",
      "Epoch 143/400\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 8.0598 - rmse: 10.3213 - mse: 106.5287 - mae: 8.0598 - val_loss: 8.5811 - val_rmse: 10.8699 - val_mse: 118.1544 - val_mae: 8.5811\n",
      "Epoch 144/400\n",
      "54/54 [==============================] - 15s 281ms/step - loss: 8.0631 - rmse: 10.3297 - mse: 106.7035 - mae: 8.0631 - val_loss: 8.5811 - val_rmse: 10.8873 - val_mse: 118.5339 - val_mae: 8.5811\n",
      "Epoch 145/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 8.0610 - rmse: 10.3291 - mse: 106.6902 - mae: 8.0610 - val_loss: 8.5231 - val_rmse: 10.8298 - val_mse: 117.2835 - val_mae: 8.5231\n",
      "Epoch 146/400\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 8.0463 - rmse: 10.3271 - mse: 106.6496 - mae: 8.0463 - val_loss: 8.5722 - val_rmse: 10.8797 - val_mse: 118.3682 - val_mae: 8.5722\n",
      "Epoch 147/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 8.0162 - rmse: 10.2937 - mse: 105.9607 - mae: 8.0162 - val_loss: 8.5823 - val_rmse: 10.8976 - val_mse: 118.7578 - val_mae: 8.5823\n",
      "Epoch 148/400\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 8.0138 - rmse: 10.2851 - mse: 105.7838 - mae: 8.0138 - val_loss: 8.5395 - val_rmse: 10.8470 - val_mse: 117.6566 - val_mae: 8.5395\n",
      "Epoch 149/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 8.0227 - rmse: 10.3043 - mse: 106.1792 - mae: 8.0227 - val_loss: 8.5722 - val_rmse: 10.8654 - val_mse: 118.0566 - val_mae: 8.5722\n",
      "Epoch 150/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 8.0056 - rmse: 10.2906 - mse: 105.8973 - mae: 8.0056 - val_loss: 8.5789 - val_rmse: 10.8862 - val_mse: 118.5093 - val_mae: 8.5789\n",
      "Epoch 151/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 7.9920 - rmse: 10.2711 - mse: 105.4953 - mae: 7.9920 - val_loss: 8.5395 - val_rmse: 10.8463 - val_mse: 117.6433 - val_mae: 8.5395\n",
      "Epoch 152/400\n",
      "54/54 [==============================] - 15s 273ms/step - loss: 7.9930 - rmse: 10.2781 - mse: 105.6395 - mae: 7.9930 - val_loss: 8.5684 - val_rmse: 10.8704 - val_mse: 118.1658 - val_mae: 8.5684\n",
      "Epoch 153/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 7.9879 - rmse: 10.2795 - mse: 105.6684 - mae: 7.9879 - val_loss: 8.5258 - val_rmse: 10.8203 - val_mse: 117.0783 - val_mae: 8.5258\n",
      "Epoch 154/400\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 7.9721 - rmse: 10.2591 - mse: 105.2497 - mae: 7.9721 - val_loss: 8.5676 - val_rmse: 10.8778 - val_mse: 118.3274 - val_mae: 8.5676\n",
      "Epoch 155/400\n",
      "54/54 [==============================] - ETA: 0s - loss: 7.9756 - rmse: 10.2743 - mse: 105.5609 - mae: 7.9756Restoring model weights from the end of the best epoch.\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 7.9756 - rmse: 10.2743 - mse: 105.5609 - mae: 7.9756 - val_loss: 8.5704 - val_rmse: 10.8755 - val_mse: 118.2758 - val_mae: 8.5704\n",
      "Epoch 00155: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    hist = model.fit(ds_train,\n",
    "                     validation_data=ds_val,\n",
    "                     callbacks=callbacks,\n",
    "                     epochs=400,\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 199ms/step - loss: 8.4537 - rmse: 10.7647 - mse: 115.8786 - mae: 8.4537\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    results = model.evaluate(ds_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Metric')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(16,16)\n",
    "\n",
    "    ax=fig.add_subplot(3,2,1)\n",
    "    ax.plot(hist.history['rmse'])\n",
    "    ax.plot(hist.history['mse'])\n",
    "    ax.legend(['Metric', 'Loss'])\n",
    "    ax.set_title('Train')\n",
    "\n",
    "    ax=fig.add_subplot(3,2,2)\n",
    "    ax.plot(hist.history['val_rmse'])\n",
    "    ax.plot(hist.history['val_mse'])\n",
    "    ax.legend(['Metric', 'Loss'])\n",
    "    ax.set_title('Test')\n",
    "\n",
    "    ax=fig.add_subplot(3,2,3)\n",
    "    ax.plot(hist.history['loss'])\n",
    "    ax.plot(hist.history['val_loss'])\n",
    "    ax.legend(['Train', 'Test'])\n",
    "    ax.set_title('Loss')\n",
    "\n",
    "    ax=fig.add_subplot(3,2,4)\n",
    "    ax.plot(hist.history['mse'])\n",
    "    ax.plot(hist.history['val_mse'])\n",
    "    ax.legend(['Train', 'Test'])\n",
    "    ax.set_title('Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = pd.read_csv('00_Data/fnc.csv')\n",
    "X1_test = X1_test[X1_test['Id'].isin(TEST_IDS)]\n",
    "X1_test = X1_test.to_numpy()\n",
    "X1_test = X1_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_test = pd.read_csv('00_Data/loading.csv')\n",
    "X2_test = X2_test[X2_test['Id'].isin(TEST_IDS)]\n",
    "X2_test = X2_test.to_numpy()\n",
    "X2_test = X2_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict([X1_test, X2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = y_preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = []\n",
    "i = 0\n",
    "for idx in TEST_IDS:\n",
    "    df_submission.append(['{0}_age'.format(idx), y_preds[i]])\n",
    "    df_submission.append(['{0}_domain1_var1'.format(idx), y_preds[i+1]])\n",
    "    df_submission.append(['{0}_domain1_var2'.format(idx), y_preds[i+2]])\n",
    "    df_submission.append(['{0}_domain2_var1'.format(idx), y_preds[i+3]])\n",
    "    df_submission.append(['{0}_domain2_var2'.format(idx), y_preds[i+4]])\n",
    "    i += 5\n",
    "\n",
    "df_submission = pd.DataFrame(df_submission, columns=['Id', 'Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('submission_fnc-load_mae_07.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.108977</td>\n",
       "      <td>69.993075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>21746</td>\n",
       "      <td>14.257265</td>\n",
       "      <td>21.358872</td>\n",
       "      <td>61.165998</td>\n",
       "      <td>51.778483</td>\n",
       "      <td>54.640179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>21747</td>\n",
       "      <td>55.456978</td>\n",
       "      <td>68.169675</td>\n",
       "      <td>29.907995</td>\n",
       "      <td>55.349257</td>\n",
       "      <td>54.019517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>21750</td>\n",
       "      <td>48.948756</td>\n",
       "      <td>55.114811</td>\n",
       "      <td>60.878271</td>\n",
       "      <td>38.617246</td>\n",
       "      <td>50.679885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>21752</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>59.844808</td>\n",
       "      <td>72.303110</td>\n",
       "      <td>55.458281</td>\n",
       "      <td>46.870235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>21754</td>\n",
       "      <td>68.820928</td>\n",
       "      <td>56.594193</td>\n",
       "      <td>34.605868</td>\n",
       "      <td>49.922535</td>\n",
       "      <td>50.383078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2\n",
       "0     10001  57.436077     30.571975     62.553736     53.325130     51.427998\n",
       "1     10002  59.580851     50.969456     67.470628     60.651856     58.311361\n",
       "2     10004  71.413018     53.152498     58.012103     52.418389     62.536641\n",
       "3     10005  66.532630           NaN           NaN     52.108977     69.993075\n",
       "4     10007  38.617381     49.197021     65.674285     40.151376     34.096421\n",
       "...     ...        ...           ...           ...           ...           ...\n",
       "5872  21746  14.257265     21.358872     61.165998     51.778483     54.640179\n",
       "5873  21747  55.456978     68.169675     29.907995     55.349257     54.019517\n",
       "5874  21750  48.948756     55.114811     60.878271     38.617246     50.679885\n",
       "5875  21752  66.532630     59.844808     72.303110     55.458281     46.870235\n",
       "5876  21754  68.820928     56.594193     34.605868     49.922535     50.383078\n",
       "\n",
       "[5877 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('00_Data/train_scores.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nulls = data[data.isnull().any(axis=1)]\n",
    "NULL_IDS = list(data_nulls['Id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
