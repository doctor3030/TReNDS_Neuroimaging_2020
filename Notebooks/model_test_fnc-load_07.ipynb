{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "from IPython.display import IFrame\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "\n",
    "import scipy.stats as sts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing as prep\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn import discriminant_analysis as disan\n",
    "from sklearn import calibration as calib\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn import svm\n",
    "from sklearn import gaussian_process as gaup\n",
    "from sklearn import mixture as mix\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble as ens\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# from keras import models as kermdls\n",
    "# from keras import layers as kerlrs\n",
    "# from keras import metrics as kmetrics\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "import pickle\n",
    "\n",
    "import nilearn as nl\n",
    "from nilearn import plotting, image\n",
    "from nilearn import datasets\n",
    "import nibabel as nb\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11080951934576161006\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15303545776932650476\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6589725830\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15125955397867295524\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8851075402230654249\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnc_10 = pd.read_csv('00_Data/fnc.csv')\n",
    "# fnc_10 = fnc_10.head(5)\n",
    "# for row in fnc_10.iterrows():\n",
    "#     idx = int(row[1][0])\n",
    "#     row = row[1][1:]\n",
    "#     print(row)\n",
    "#     row.to_csv('00_Data/fnc_csv_norm/{0}.csv'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IDS = [map_id.split('.')[0] for map_id in sorted(os.listdir('00_Data/fMRI_test'))]\n",
    "TRAIN_IDS = [map_id.split('.')[0] for map_id in sorted(os.listdir('00_Data/fMRI_train'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.108977</td>\n",
       "      <td>69.993075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>21746</td>\n",
       "      <td>14.257265</td>\n",
       "      <td>21.358872</td>\n",
       "      <td>61.165998</td>\n",
       "      <td>51.778483</td>\n",
       "      <td>54.640179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>21747</td>\n",
       "      <td>55.456978</td>\n",
       "      <td>68.169675</td>\n",
       "      <td>29.907995</td>\n",
       "      <td>55.349257</td>\n",
       "      <td>54.019517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>21750</td>\n",
       "      <td>48.948756</td>\n",
       "      <td>55.114811</td>\n",
       "      <td>60.878271</td>\n",
       "      <td>38.617246</td>\n",
       "      <td>50.679885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>21752</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>59.844808</td>\n",
       "      <td>72.303110</td>\n",
       "      <td>55.458281</td>\n",
       "      <td>46.870235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>21754</td>\n",
       "      <td>68.820928</td>\n",
       "      <td>56.594193</td>\n",
       "      <td>34.605868</td>\n",
       "      <td>49.922535</td>\n",
       "      <td>50.383078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2\n",
       "0     10001  57.436077     30.571975     62.553736     53.325130     51.427998\n",
       "1     10002  59.580851     50.969456     67.470628     60.651856     58.311361\n",
       "2     10004  71.413018     53.152498     58.012103     52.418389     62.536641\n",
       "3     10005  66.532630           NaN           NaN     52.108977     69.993075\n",
       "4     10007  38.617381     49.197021     65.674285     40.151376     34.096421\n",
       "...     ...        ...           ...           ...           ...           ...\n",
       "5872  21746  14.257265     21.358872     61.165998     51.778483     54.640179\n",
       "5873  21747  55.456978     68.169675     29.907995     55.349257     54.019517\n",
       "5874  21750  48.948756     55.114811     60.878271     38.617246     50.679885\n",
       "5875  21752  66.532630     59.844808     72.303110     55.458281     46.870235\n",
       "5876  21754  68.820928     56.594193     34.605868     49.922535     50.383078\n",
       "\n",
       "[5877 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('00_Data/train_scores.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                0\n",
       "age               0\n",
       "domain1_var1    438\n",
       "domain1_var2    438\n",
       "domain2_var1     39\n",
       "domain2_var2     39\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls = data.isnull().sum()\n",
    "# l = len(data.index)\n",
    "\n",
    "# nulls['domain1_var1'] / l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length:  5434\n"
     ]
    }
   ],
   "source": [
    "print('Dataset length: ', len(data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_inputs_fnc(idx, labels):\n",
    "#     df = pd.read_csv('00_Data/fnc_csv/{0}.csv'.format(idx), index_col=0)\n",
    "#     X = np.array(df.values).reshape(-1)\n",
    "#     return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_inputs_loading(idx, labels):\n",
    "#     df = pd.read_csv('00_Data/loading_csv/{0}.csv'.format(idx), index_col=0)\n",
    "#     X = np.array(df.values).reshape(-1)\n",
    "#     return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(idx, labels):\n",
    "    df_fnc = pd.read_csv('00_Data/fnc_csv/{0}.csv'.format(idx), index_col=0)\n",
    "    X_fnc = np.array(df_fnc.values).reshape(-1)\n",
    "    \n",
    "    df_loading = pd.read_csv('00_Data/loading_csv/{0}.csv'.format(idx), index_col=0)\n",
    "    X_loading = np.array(df_loading.values).reshape(-1)\n",
    "#     print(X_fnc[0])\n",
    "#     print(X_loading[0])\n",
    "#     print(labels[0])\n",
    "#     print(X_fnc.shape)\n",
    "#     print(X_loading.shape)\n",
    "#     print(labels.shape)\n",
    "\n",
    "#     X_fnc = tf.convert_to_tensor(X_fnc, dtype=tf.float64)\n",
    "#     X_loading = tf.convert_to_tensor(X_loading, dtype=tf.float64)\n",
    "#     labels = tf.convert_to_tensor(labels, dtype=tf.float64)\n",
    "#     X = tf.tuple([X_fnc, X_loading])\n",
    "\n",
    "#     X = dict()\n",
    "#     X['input_1'] = X_fnc\n",
    "#     X['input_2'] = X_loading\n",
    "    X = (X_fnc, X_loading)\n",
    "    return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_decorator(func):\n",
    "    def wrapper(idx, labels):\n",
    "        # Use a tf.py_function to prevent auto-graph from compiling the method\n",
    "        return tf.py_function(func,\n",
    "                              inp=(idx, labels),\n",
    "                              Tout=tf.float64)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_py_function(func, inp, Tout, name=None):\n",
    "    \n",
    "    def wrapped_func(*flat_inp):\n",
    "        reconstructed_inp = tf.nest.pack_sequence_as(inp, flat_inp,\n",
    "                                                     expand_composites=True)\n",
    "        out = func(*reconstructed_inp)\n",
    "        return tf.nest.flatten(out, expand_composites=True)\n",
    "    \n",
    "    flat_Tout = tf.nest.flatten(Tout, expand_composites=True)\n",
    "    flat_out = tf.py_function(func=wrapped_func, \n",
    "                              inp=tf.nest.flatten(inp, expand_composites=True),\n",
    "                              Tout=[_tensor_spec_to_dtype(v) for v in flat_Tout],\n",
    "                              name=name)\n",
    "    spec_out = tf.nest.map_structure(_dtype_to_tensor_spec, Tout, expand_composites=True)\n",
    "    out = tf.nest.pack_sequence_as(spec_out, flat_out, expand_composites=True)\n",
    "    return out\n",
    "\n",
    "def _dtype_to_tensor_spec(v):\n",
    "    return tf.TensorSpec(None, v) if isinstance(v, tf.dtypes.DType) else v\n",
    "\n",
    "def _tensor_spec_to_dtype(v):\n",
    "    return v.dtype if isinstance(v, tf.TensorSpec) else v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dataset(data, batch_size):\n",
    "#     data = tf.data.Dataset.from_tensor_slices((data['Id'].values, \n",
    "#                                                data[['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']].values))\n",
    "#     data = data.shuffle(buffer_size=5500, seed=30, reshuffle_each_iteration=True)\n",
    "    \n",
    "#     data_fnc = data.map(map_decorator(get_inputs_fnc), \n",
    "#                      num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "#                      deterministic=True)\n",
    "#     data_loading = data.map(map_decorator(get_inputs_loading), \n",
    "#                      num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "#                      deterministic=True)\n",
    "\n",
    "#     data_fnc = data_fnc.batch(batch_size, drop_remainder=True)\n",
    "#     data_fnc = data_fnc.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "#     data_loading = data_loading.batch(batch_size, drop_remainder=True)\n",
    "#     data_loading = data_loading.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#     return (data_fnc, data_loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data, batch_size):\n",
    "    data = tf.data.Dataset.from_tensor_slices((data['Id'].values, \n",
    "                                               data[['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']].values))\n",
    "    data = data.shuffle(buffer_size=5500, seed=30, reshuffle_each_iteration=True)\n",
    "    \n",
    "    data = data.map(lambda idx, lbl:new_py_function(get_inputs, inp=(idx, lbl), Tout=((tf.float64, tf.float64), tf.float64), name=None), \n",
    "                     num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "                     deterministic=True)\n",
    "    data = data.batch(batch_size, drop_remainder=True)\n",
    "    data = data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = model_selection.train_test_split(data, test_size=0.2, shuffle=True, random_state=30)\n",
    "train, val = model_selection.train_test_split(train, test_size=0.2, shuffle=True, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 64\n",
    "\n",
    "# ds_train_fnc, ds_train_loading = get_dataset(train, batch_size)\n",
    "# ds_val_fnc, ds_val_loading = get_dataset(val, batch_size)\n",
    "# ds_test_fnc, ds_test_loading = get_dataset(test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "ds_train = get_dataset(train, batch_size)\n",
    "ds_val = get_dataset(val, batch_size)\n",
    "ds_test = get_dataset(test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.perf_counter()\n",
    "# for f in ds_train.take(1):\n",
    "#     pass\n",
    "# tf.print(\"Execution time:\", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE_fnc = (1378,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE_loading = (26,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_fnc = keras.layers.Input(shape=INPUT_SHAPE_fnc, name='inp_fnc')\n",
    "\n",
    "x = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(inputs_fnc)\n",
    "x = keras.layers.Dense(2048,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x)\n",
    "# x = keras.layers.Dropout(rate=0.2, seed=30)(x)\n",
    "\n",
    "x1 = keras.layers.Dense(512,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x1)\n",
    "x1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x1)\n",
    "\n",
    "x2 = keras.layers.Dense(512,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x2)\n",
    "x2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x2)\n",
    "\n",
    "x = keras.layers.concatenate([x1, x2])\n",
    "\n",
    "# x = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(x)\n",
    "\n",
    "x = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x)\n",
    "# x = keras.layers.Dropout(rate=0.2, seed=30)(x)\n",
    "\n",
    "# output\n",
    "x = keras.Model(inputs=inputs_fnc, outputs=x, name='model_fnc')\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_loading = keras.layers.Input(shape=INPUT_SHAPE_loading, name='inp_load')\n",
    "\n",
    "y = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(inputs_loading)\n",
    "\n",
    "y = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y)\n",
    "# y = keras.layers.Dropout(rate=0.2, seed=30)(y)\n",
    "\n",
    "y1 = keras.layers.Dense(128,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y1)\n",
    "y1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y1)\n",
    "\n",
    "y2 = keras.layers.Dense(128,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y2)\n",
    "y2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y2)\n",
    "\n",
    "y = keras.layers.concatenate([y1, y2])\n",
    "\n",
    "# y = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(y)\n",
    "\n",
    "y = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y)\n",
    "# x = keras.layers.Dropout(rate=0.2, seed=30)(x)\n",
    "\n",
    "# output\n",
    "y = keras.Model(inputs=inputs_loading, outputs=y, name='model_loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = keras.layers.concatenate([x.output, y.output])\n",
    "\n",
    "z1 = keras.layers.Dense(512, \n",
    "                       kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                       bias_initializer=keras.initializers.Constant(5.))(concat)\n",
    "z1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(z1)\n",
    "z1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(z1)\n",
    "\n",
    "z2 = keras.layers.Dense(512, \n",
    "                       kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                       bias_initializer=keras.initializers.Constant(5.))(concat)\n",
    "z2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(z2)\n",
    "z1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(z2)\n",
    "\n",
    "z = keras.layers.concatenate([z1, z2])\n",
    "\n",
    "z = keras.layers.Dense(512, \n",
    "                       kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                       bias_initializer=keras.initializers.Constant(5.))(concat)\n",
    "z = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(z)\n",
    "\n",
    "outputs = keras.layers.Dense(5, activation='linear')(z)\n",
    "\n",
    "model = keras.Model(inputs=[x.input, y.input], outputs=outputs, name='model_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_combined\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inp_fnc (InputLayer)            [(None, 1378)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inp_load (InputLayer)           [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1378)         5512        inp_fnc[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 26)           104         inp_load[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         2824192     batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          6912        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu (PReLU)                 (None, 2048)         2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_4 (PReLU)               (None, 256)          256         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     p_re_lu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          1049088     p_re_lu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          32896       p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          32896       p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 512)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 512)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_5 (PReLU)               (None, 128)          128         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_6 (PReLU)               (None, 128)          128         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          2048        p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512)          2048        p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128)          512         p_re_lu_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128)          512         p_re_lu_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          262400      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          65792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_3 (PReLU)               (None, 256)          256         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_7 (PReLU)               (None, 256)          256         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           p_re_lu_3[0][0]                  \n",
      "                                                                 p_re_lu_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 512)          262656      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_10 (PReLU)              (None, 512)          512         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 5)            2565        p_re_lu_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 5,603,829\n",
      "Trainable params: 5,598,461\n",
      "Non-trainable params: 5,368\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim = keras.optimizers.Adam(lr=0.000001,\n",
    "#                                  beta_1=0.99,\n",
    "#                                  beta_2=0.999,\n",
    "#                                  amsgrad=False)\n",
    "\n",
    "optim = tf.keras.optimizers.Adadelta(learning_rate=0.001, rho=0.95)\n",
    "        \n",
    "METRICS = [keras.metrics.RootMeanSquaredError(name='rmse'),\n",
    "           keras.metrics.MeanSquaredError(name='mse'),\n",
    "           keras.metrics.MeanAbsoluteError(name='mae')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def weighted_mae(y_true, y_pred):\n",
    "# #     tf.print(y_true)\n",
    "#     W = tf.constant([[0.2, 0.2, 0.2, 0.2, 0.2]])\n",
    "# #     tf.print(W / tf.math.reduce_mean(y_true, axis=0))\n",
    "#     return tf.math.reduce_mean(tf.linalg.matmul(tf.math.abs(y_pred - y_true), tf.transpose(W / tf.math.reduce_mean(y_true, axis=0))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mae', metrics=METRICS, optimizer=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint directory to store the checkpoints\n",
    "# Name of the checkpoint files\n",
    "# checkpoint_prefix = os.path.join('./99_Training_checkpoints/fnc-loading', \"ckpt_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/fnc-loading'),\n",
    "#              tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "#                                                 save_weights_only=False),\n",
    "#              tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "#                                                   factor=0.7, \n",
    "#                                                   patience=2, \n",
    "#                                                   verbose=1, \n",
    "#                                                   mode='min',\n",
    "#                                                   min_delta=0.01, \n",
    "#                                                   cooldown=5, \n",
    "#                                                   min_lr=0.00000001),\n",
    "#              tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "#                                               min_delta=0.001, \n",
    "#                                               patience=10, \n",
    "#                                               verbose=1, \n",
    "#                                               mode='min',\n",
    "#                                               baseline=None, \n",
    "#                                               restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/fnc-loading'),\n",
    "#              tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "#                                                   factor=0.7, \n",
    "#                                                   patience=2, \n",
    "#                                                   verbose=1, \n",
    "#                                                   mode='min',\n",
    "#                                                   min_delta=0.01, \n",
    "#                                                   cooldown=5, \n",
    "#                                                   min_lr=0.00000001),\n",
    "#              tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "#                                               min_delta=0.001, \n",
    "#                                               patience=10, \n",
    "#                                               verbose=1, \n",
    "#                                               mode='min',\n",
    "#                                               baseline=None, \n",
    "#                                               restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/fnc-loading'),\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              min_delta=0.001, \n",
    "                                              patience=10, \n",
    "                                              verbose=1, \n",
    "                                              mode='min',\n",
    "                                              baseline=None, \n",
    "                                              restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decay(epoch):\n",
    "#     if epoch < 2:\n",
    "#         return 0.01\n",
    "#     elif epoch >= 2 and epoch < 10:\n",
    "#         return 0.005\n",
    "#     else:\n",
    "#         return 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.LearningRateScheduler(decay)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 43.8283 - rmse: 46.3944 - mse: 2152.4385 - mae: 43.8283 - val_loss: 48.2755 - val_rmse: 52.2577 - val_mse: 2730.8628 - val_mae: 48.2755\n",
      "Epoch 2/200\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 41.3679 - rmse: 44.0651 - mse: 1941.7310 - mae: 41.3679 - val_loss: 43.8794 - val_rmse: 47.6703 - val_mse: 2272.4536 - val_mae: 43.8794\n",
      "Epoch 3/200\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 38.7958 - rmse: 41.6186 - mse: 1732.1053 - mae: 38.7958 - val_loss: 40.0863 - val_rmse: 43.7256 - val_mse: 1911.9246 - val_mae: 40.0863\n",
      "Epoch 4/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 36.0965 - rmse: 39.0612 - mse: 1525.7749 - mae: 36.0965 - val_loss: 36.4446 - val_rmse: 39.9822 - val_mse: 1598.5767 - val_mae: 36.4446\n",
      "Epoch 5/200\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 33.3142 - rmse: 36.3972 - mse: 1324.7567 - mae: 33.3142 - val_loss: 32.9627 - val_rmse: 36.4110 - val_mse: 1325.7578 - val_mae: 32.9627\n",
      "Epoch 6/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 30.4635 - rmse: 33.6503 - mse: 1132.3446 - mae: 30.4635 - val_loss: 29.7056 - val_rmse: 33.0850 - val_mse: 1094.6190 - val_mae: 29.7056\n",
      "Epoch 7/200\n",
      "54/54 [==============================] - 14s 255ms/step - loss: 27.5675 - rmse: 30.8104 - mse: 949.2784 - mae: 27.5675 - val_loss: 26.4519 - val_rmse: 29.7707 - val_mse: 886.2969 - val_mae: 26.4519\n",
      "Epoch 8/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 24.6543 - rmse: 27.9028 - mse: 778.5668 - mae: 24.6543 - val_loss: 23.4369 - val_rmse: 26.6391 - val_mse: 709.6392 - val_mae: 23.4369\n",
      "Epoch 9/200\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 21.7762 - rmse: 24.9690 - mse: 623.4499 - mae: 21.7762 - val_loss: 20.4881 - val_rmse: 23.5788 - val_mse: 555.9575 - val_mae: 20.4881\n",
      "Epoch 10/200\n",
      "54/54 [==============================] - 14s 255ms/step - loss: 18.9570 - rmse: 22.0616 - mse: 486.7158 - mae: 18.9570 - val_loss: 17.7201 - val_rmse: 20.7097 - val_mse: 428.8933 - val_mae: 17.7201\n",
      "Epoch 11/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 16.3483 - rmse: 19.3318 - mse: 373.7180 - mae: 16.3483 - val_loss: 15.1925 - val_rmse: 18.0758 - val_mse: 326.7335 - val_mae: 15.1925\n",
      "Epoch 12/200\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 14.0438 - rmse: 16.8749 - mse: 284.7628 - mae: 14.0438 - val_loss: 13.1587 - val_rmse: 15.9136 - val_mse: 253.2428 - val_mae: 13.1587\n",
      "Epoch 13/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 12.2063 - rmse: 14.8848 - mse: 221.5585 - mae: 12.2063 - val_loss: 11.6287 - val_rmse: 14.2755 - val_mse: 203.7892 - val_mae: 11.6287\n",
      "Epoch 14/200\n",
      "54/54 [==============================] - 14s 255ms/step - loss: 10.8950 - rmse: 13.4405 - mse: 180.6473 - mae: 10.8950 - val_loss: 10.5596 - val_rmse: 13.1044 - val_mse: 171.7259 - val_mae: 10.5596\n",
      "Epoch 15/200\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 10.0732 - rmse: 12.5161 - mse: 156.6523 - mae: 10.0732 - val_loss: 9.9200 - val_rmse: 12.4005 - val_mse: 153.7733 - val_mae: 9.92001 - rmse: 12.5284 - mse: 156.9607 \n",
      "Epoch 16/200\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 9.5924 - rmse: 11.9736 - mse: 143.3667 - mae: 9.5924 - val_loss: 9.6056 - val_rmse: 12.0434 - val_mse: 145.0430 - val_mae: 9.6056\n",
      "Epoch 17/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 9.3283 - rmse: 11.6846 - mse: 136.5305 - mae: 9.3283 - val_loss: 9.3358 - val_rmse: 11.7791 - val_mse: 138.7483 - val_mae: 9.3358\n",
      "Epoch 18/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 9.1686 - rmse: 11.5260 - mse: 132.8486 - mae: 9.1686 - val_loss: 9.2248 - val_rmse: 11.6460 - val_mse: 135.6296 - val_mae: 9.2248\n",
      "Epoch 19/200\n",
      "54/54 [==============================] - 14s 255ms/step - loss: 9.0781 - rmse: 11.4438 - mse: 130.9594 - mae: 9.0781 - val_loss: 9.1919 - val_rmse: 11.5923 - val_mse: 134.3814 - val_mae: 9.1919\n",
      "Epoch 20/200\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 9.0293 - rmse: 11.3925 - mse: 129.7898 - mae: 9.0293 - val_loss: 9.1372 - val_rmse: 11.5448 - val_mse: 133.2817 - val_mae: 9.1372\n",
      "Epoch 21/200\n",
      "54/54 [==============================] - 14s 254ms/step - loss: 8.9773 - rmse: 11.3395 - mse: 128.5845 - mae: 8.9773 - val_loss: 9.0951 - val_rmse: 11.5190 - val_mse: 132.6873 - val_mae: 9.0951\n",
      "Epoch 22/200\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 8.9422 - rmse: 11.3019 - mse: 127.7332 - mae: 8.9422 - val_loss: 9.0855 - val_rmse: 11.5104 - val_mse: 132.4901 - val_mae: 9.0855\n",
      "Epoch 23/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.9128 - rmse: 11.2788 - mse: 127.2115 - mae: 8.9128 - val_loss: 9.0404 - val_rmse: 11.4358 - val_mse: 130.7766 - val_mae: 9.0404\n",
      "Epoch 24/200\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 8.8754 - rmse: 11.2397 - mse: 126.3302 - mae: 8.8754 - val_loss: 9.0065 - val_rmse: 11.4003 - val_mse: 129.9664 - val_mae: 9.0065\n",
      "Epoch 25/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.8466 - rmse: 11.2076 - mse: 125.6111 - mae: 8.8466 - val_loss: 9.0387 - val_rmse: 11.4285 - val_mse: 130.6096 - val_mae: 9.0387\n",
      "Epoch 26/200\n",
      "54/54 [==============================] - 14s 255ms/step - loss: 8.8244 - rmse: 11.1867 - mse: 125.1433 - mae: 8.8244 - val_loss: 8.9564 - val_rmse: 11.3426 - val_mse: 128.6551 - val_mae: 8.9564\n",
      "Epoch 27/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.7953 - rmse: 11.1538 - mse: 124.4071 - mae: 8.7953 - val_loss: 8.9545 - val_rmse: 11.3541 - val_mse: 128.9158 - val_mae: 8.9545\n",
      "Epoch 28/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.7717 - rmse: 11.1223 - mse: 123.7061 - mae: 8.7717 - val_loss: 8.9421 - val_rmse: 11.3279 - val_mse: 128.3208 - val_mae: 8.9421\n",
      "Epoch 29/200\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 8.7404 - rmse: 11.0910 - mse: 123.0108 - mae: 8.7404 - val_loss: 8.9026 - val_rmse: 11.2834 - val_mse: 127.3140 - val_mae: 8.9026\n",
      "Epoch 30/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.7236 - rmse: 11.0741 - mse: 122.6355 - mae: 8.7236 - val_loss: 8.8960 - val_rmse: 11.2863 - val_mse: 127.3800 - val_mae: 8.8960\n",
      "Epoch 31/200\n",
      "54/54 [==============================] - 14s 255ms/step - loss: 8.6943 - rmse: 11.0450 - mse: 121.9913 - mae: 8.6943 - val_loss: 8.8661 - val_rmse: 11.2265 - val_mse: 126.0348 - val_mae: 8.8661\n",
      "Epoch 32/200\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 8.6706 - rmse: 11.0204 - mse: 121.4493 - mae: 8.6706 - val_loss: 8.9009 - val_rmse: 11.2844 - val_mse: 127.3371 - val_mae: 8.9009\n",
      "Epoch 33/200\n",
      "54/54 [==============================] - 14s 255ms/step - loss: 8.6518 - rmse: 11.0040 - mse: 121.0873 - mae: 8.6518 - val_loss: 8.8290 - val_rmse: 11.1858 - val_mse: 125.1220 - val_mae: 8.8290\n",
      "Epoch 34/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.6334 - rmse: 10.9784 - mse: 120.5244 - mae: 8.6334 - val_loss: 8.7985 - val_rmse: 11.1694 - val_mse: 124.7552 - val_mae: 8.7985\n",
      "Epoch 35/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.5934 - rmse: 10.9382 - mse: 119.6431 - mae: 8.5934 - val_loss: 8.8174 - val_rmse: 11.1918 - val_mse: 125.2558 - val_mae: 8.8174\n",
      "Epoch 36/200\n",
      "54/54 [==============================] - 14s 256ms/step - loss: 8.5857 - rmse: 10.9269 - mse: 119.3982 - mae: 8.5857 - val_loss: 8.8442 - val_rmse: 11.1968 - val_mse: 125.3683 - val_mae: 8.8442\n",
      "Epoch 37/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.5805 - rmse: 10.9276 - mse: 119.4122 - mae: 8.5805 - val_loss: 8.7931 - val_rmse: 11.1578 - val_mse: 124.4966 - val_mae: 8.7931\n",
      "Epoch 38/200\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 8.5522 - rmse: 10.8955 - mse: 118.7122 - mae: 8.5522 - val_loss: 8.7641 - val_rmse: 11.1111 - val_mse: 123.4568 - val_mae: 8.7641\n",
      "Epoch 39/200\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 8.5467 - rmse: 10.8860 - mse: 118.5049 - mae: 8.5467 - val_loss: 8.7995 - val_rmse: 11.1522 - val_mse: 124.3723 - val_mae: 8.7995\n",
      "Epoch 40/200\n",
      "54/54 [==============================] - 14s 257ms/step - loss: 8.5234 - rmse: 10.8619 - mse: 117.9815 - mae: 8.5234 - val_loss: 8.7902 - val_rmse: 11.1179 - val_mse: 123.6066 - val_mae: 8.7902\n",
      "Epoch 41/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.5085 - rmse: 10.8554 - mse: 117.8402 - mae: 8.5085 - val_loss: 8.7847 - val_rmse: 11.1337 - val_mse: 123.9586 - val_mae: 8.7847\n",
      "Epoch 42/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.4847 - rmse: 10.8281 - mse: 117.2478 - mae: 8.4847 - val_loss: 8.7494 - val_rmse: 11.0850 - val_mse: 122.8765 - val_mae: 8.7494\n",
      "Epoch 43/200\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 8.4686 - rmse: 10.8116 - mse: 116.8914 - mae: 8.4686 - val_loss: 8.7634 - val_rmse: 11.1074 - val_mse: 123.3742 - val_mae: 8.7634\n",
      "Epoch 44/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.4725 - rmse: 10.8137 - mse: 116.9363 - mae: 8.4725 - val_loss: 8.7011 - val_rmse: 11.0441 - val_mse: 121.9731 - val_mae: 8.7011 8.4687 - rmse: 10.8183 - mse: 117.0363 - ma\n",
      "Epoch 45/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.4415 - rmse: 10.7830 - mse: 116.2741 - mae: 8.4415 - val_loss: 8.7579 - val_rmse: 11.0970 - val_mse: 123.1427 - val_mae: 8.7579\n",
      "Epoch 46/200\n",
      "54/54 [==============================] - 14s 257ms/step - loss: 8.4322 - rmse: 10.7697 - mse: 115.9875 - mae: 8.4322 - val_loss: 8.7232 - val_rmse: 11.0603 - val_mse: 122.3313 - val_mae: 8.7232\n",
      "Epoch 47/200\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 8.4386 - rmse: 10.7762 - mse: 116.1264 - mae: 8.4386 - val_loss: 8.7072 - val_rmse: 11.0528 - val_mse: 122.1637 - val_mae: 8.7072\n",
      "Epoch 48/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.4147 - rmse: 10.7501 - mse: 115.5641 - mae: 8.4147 - val_loss: 8.6540 - val_rmse: 10.9894 - val_mse: 120.7658 - val_mae: 8.6540\n",
      "Epoch 49/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.3993 - rmse: 10.7379 - mse: 115.3030 - mae: 8.3993 - val_loss: 8.6772 - val_rmse: 11.0085 - val_mse: 121.1877 - val_mae: 8.6772\n",
      "Epoch 50/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.4005 - rmse: 10.7368 - mse: 115.2783 - mae: 8.4005 - val_loss: 8.7068 - val_rmse: 11.0391 - val_mse: 121.8620 - val_mae: 8.7068\n",
      "Epoch 51/200\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 8.3753 - rmse: 10.7201 - mse: 114.9215 - mae: 8.3753 - val_loss: 8.6727 - val_rmse: 10.9991 - val_mse: 120.9796 - val_mae: 8.6727\n",
      "Epoch 52/200\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 8.3578 - rmse: 10.6949 - mse: 114.3804 - mae: 8.3578 - val_loss: 8.6480 - val_rmse: 10.9703 - val_mse: 120.3480 - val_mae: 8.6480\n",
      "Epoch 53/200\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 8.3569 - rmse: 10.6965 - mse: 114.4148 - mae: 8.3569 - val_loss: 8.6382 - val_rmse: 10.9642 - val_mse: 120.2138 - val_mae: 8.6382\n",
      "Epoch 54/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.3409 - rmse: 10.6803 - mse: 114.0693 - mae: 8.3409 - val_loss: 8.7097 - val_rmse: 11.0484 - val_mse: 122.0661 - val_mae: 8.7097\n",
      "Epoch 55/200\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 8.3312 - rmse: 10.6758 - mse: 113.9734 - mae: 8.3312 - val_loss: 8.6762 - val_rmse: 11.0069 - val_mse: 121.1524 - val_mae: 8.6762\n",
      "Epoch 56/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.3184 - rmse: 10.6572 - mse: 113.5763 - mae: 8.3184 - val_loss: 8.6930 - val_rmse: 11.0269 - val_mse: 121.5932 - val_mae: 8.6930\n",
      "Epoch 57/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.3117 - rmse: 10.6455 - mse: 113.3275 - mae: 8.3117 - val_loss: 8.6556 - val_rmse: 10.9895 - val_mse: 120.7701 - val_mae: 8.6556\n",
      "Epoch 58/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.3002 - rmse: 10.6461 - mse: 113.3392 - mae: 8.3002 - val_loss: 8.6504 - val_rmse: 10.9776 - val_mse: 120.5067 - val_mae: 8.6504\n",
      "Epoch 59/200\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 8.2989 - rmse: 10.6384 - mse: 113.1762 - mae: 8.2989 - val_loss: 8.6775 - val_rmse: 11.0117 - val_mse: 121.2574 - val_mae: 8.6775\n",
      "Epoch 60/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.2970 - rmse: 10.6381 - mse: 113.1691 - mae: 8.2970 - val_loss: 8.6326 - val_rmse: 10.9757 - val_mse: 120.4650 - val_mae: 8.6326\n",
      "Epoch 61/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.2859 - rmse: 10.6287 - mse: 112.9690 - mae: 8.2859 - val_loss: 8.5934 - val_rmse: 10.9248 - val_mse: 119.3518 - val_mae: 8.5934\n",
      "Epoch 62/200\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 8.2731 - rmse: 10.6159 - mse: 112.6981 - mae: 8.2731 - val_loss: 8.5917 - val_rmse: 10.9160 - val_mse: 119.1591 - val_mae: 8.5917\n",
      "Epoch 63/200\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 8.2626 - rmse: 10.5984 - mse: 112.3270 - mae: 8.2626 - val_loss: 8.6262 - val_rmse: 10.9716 - val_mse: 120.3754 - val_mae: 8.6262\n",
      "Epoch 64/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.2443 - rmse: 10.5895 - mse: 112.1369 - mae: 8.2443 - val_loss: 8.5802 - val_rmse: 10.9024 - val_mse: 118.8620 - val_mae: 8.5802\n",
      "Epoch 65/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.2493 - rmse: 10.5883 - mse: 112.1131 - mae: 8.2493 - val_loss: 8.6294 - val_rmse: 10.9732 - val_mse: 120.4108 - val_mae: 8.6294\n",
      "Epoch 66/200\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 8.2343 - rmse: 10.5739 - mse: 111.8076 - mae: 8.2343 - val_loss: 8.6027 - val_rmse: 10.9286 - val_mse: 119.4332 - val_mae: 8.6027\n",
      "Epoch 67/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.2290 - rmse: 10.5726 - mse: 111.7806 - mae: 8.2290 - val_loss: 8.5705 - val_rmse: 10.8943 - val_mse: 118.6852 - val_mae: 8.5705\n",
      "Epoch 68/200\n",
      "54/54 [==============================] - 14s 257ms/step - loss: 8.2283 - rmse: 10.5691 - mse: 111.7061 - mae: 8.2283 - val_loss: 8.5815 - val_rmse: 10.9060 - val_mse: 118.9399 - val_mae: 8.5815\n",
      "Epoch 69/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.2145 - rmse: 10.5536 - mse: 111.3783 - mae: 8.2145 - val_loss: 8.6043 - val_rmse: 10.9460 - val_mse: 119.8160 - val_mae: 8.6043\n",
      "Epoch 70/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.1999 - rmse: 10.5477 - mse: 111.2540 - mae: 8.1999 - val_loss: 8.5750 - val_rmse: 10.8830 - val_mse: 118.4390 - val_mae: 8.5750\n",
      "Epoch 71/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.2118 - rmse: 10.5566 - mse: 111.4419 - mae: 8.2118 - val_loss: 8.6027 - val_rmse: 10.9302 - val_mse: 119.4696 - val_mae: 8.6027\n",
      "Epoch 72/200\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 8.1889 - rmse: 10.5345 - mse: 110.9756 - mae: 8.1889 - val_loss: 8.6047 - val_rmse: 10.9432 - val_mse: 119.7537 - val_mae: 8.6047\n",
      "Epoch 73/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.1717 - rmse: 10.5133 - mse: 110.5301 - mae: 8.1717 - val_loss: 8.6155 - val_rmse: 10.9537 - val_mse: 119.9842 - val_mae: 8.6155\n",
      "Epoch 74/200\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 8.1813 - rmse: 10.5301 - mse: 110.8827 - mae: 8.1813 - val_loss: 8.5928 - val_rmse: 10.9265 - val_mse: 119.3889 - val_mae: 8.5928\n",
      "Epoch 75/200\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 8.1813 - rmse: 10.5267 - mse: 110.8115 - mae: 8.1813 - val_loss: 8.5550 - val_rmse: 10.8902 - val_mse: 118.5965 - val_mae: 8.5550\n",
      "Epoch 76/200\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 8.1683 - rmse: 10.5195 - mse: 110.6606 - mae: 8.1683 - val_loss: 8.6223 - val_rmse: 10.9499 - val_mse: 119.9002 - val_mae: 8.6223\n",
      "Epoch 77/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.1579 - rmse: 10.5029 - mse: 110.3119 - mae: 8.1579 - val_loss: 8.5597 - val_rmse: 10.8970 - val_mse: 118.7439 - val_mae: 8.5597\n",
      "Epoch 78/200\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 8.1564 - rmse: 10.5020 - mse: 110.2914 - mae: 8.1564 - val_loss: 8.5939 - val_rmse: 10.9274 - val_mse: 119.4071 - val_mae: 8.5939\n",
      "Epoch 79/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.1581 - rmse: 10.5098 - mse: 110.4552 - mae: 8.1581 - val_loss: 8.5824 - val_rmse: 10.9015 - val_mse: 118.8424 - val_mae: 8.5824\n",
      "Epoch 80/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.1527 - rmse: 10.4927 - mse: 110.0961 - mae: 8.1527 - val_loss: 8.5442 - val_rmse: 10.8656 - val_mse: 118.0616 - val_mae: 8.5442\n",
      "Epoch 81/200\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 8.1212 - rmse: 10.4720 - mse: 109.6630 - mae: 8.1212 - val_loss: 8.5765 - val_rmse: 10.9104 - val_mse: 119.0366 - val_mae: 8.5765\n",
      "Epoch 82/200\n",
      "54/54 [==============================] - 14s 257ms/step - loss: 8.1174 - rmse: 10.4653 - mse: 109.5228 - mae: 8.1174 - val_loss: 8.5589 - val_rmse: 10.8765 - val_mse: 118.2990 - val_mae: 8.5589\n",
      "Epoch 83/200\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 8.1184 - rmse: 10.4660 - mse: 109.5368 - mae: 8.1184 - val_loss: 8.5633 - val_rmse: 10.8833 - val_mse: 118.4470 - val_mae: 8.5633\n",
      "Epoch 84/200\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 8.1213 - rmse: 10.4724 - mse: 109.6707 - mae: 8.1213 - val_loss: 8.5763 - val_rmse: 10.9158 - val_mse: 119.1540 - val_mae: 8.5763\n",
      "Epoch 85/200\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 8.1114 - rmse: 10.4659 - mse: 109.5357 - mae: 8.1114 - val_loss: 8.5300 - val_rmse: 10.8352 - val_mse: 117.4014 - val_mae: 8.5300\n",
      "Epoch 86/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.1092 - rmse: 10.4586 - mse: 109.3820 - mae: 8.1092 - val_loss: 8.6044 - val_rmse: 10.9333 - val_mse: 119.5367 - val_mae: 8.6044\n",
      "Epoch 87/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.0967 - rmse: 10.4502 - mse: 109.2059 - mae: 8.0967 - val_loss: 8.5615 - val_rmse: 10.8911 - val_mse: 118.6159 - val_mae: 8.5615\n",
      "Epoch 88/200\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 8.1003 - rmse: 10.4518 - mse: 109.2397 - mae: 8.1003 - val_loss: 8.5404 - val_rmse: 10.8694 - val_mse: 118.1442 - val_mae: 8.5404\n",
      "Epoch 89/200\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 8.0923 - rmse: 10.4469 - mse: 109.1376 - mae: 8.0923 - val_loss: 8.5940 - val_rmse: 10.9300 - val_mse: 119.4643 - val_mae: 8.5940\n",
      "Epoch 90/200\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 8.0880 - rmse: 10.4449 - mse: 109.0962 - mae: 8.0880 - val_loss: 8.5550 - val_rmse: 10.8852 - val_mse: 118.4869 - val_mae: 8.5550\n",
      "Epoch 91/200\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 8.0889 - rmse: 10.4354 - mse: 108.8969 - mae: 8.0889 - val_loss: 8.5888 - val_rmse: 10.9089 - val_mse: 119.0031 - val_mae: 8.5888\n",
      "Epoch 92/200\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 8.0837 - rmse: 10.4381 - mse: 108.9537 - mae: 8.0837 - val_loss: 8.5390 - val_rmse: 10.8635 - val_mse: 118.0153 - val_mae: 8.5390\n",
      "Epoch 93/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.0776 - rmse: 10.4359 - mse: 108.9073 - mae: 8.0776 - val_loss: 8.5275 - val_rmse: 10.8399 - val_mse: 117.5028 - val_mae: 8.5275\n",
      "Epoch 94/200\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 8.0729 - rmse: 10.4258 - mse: 108.6977 - mae: 8.0729 - val_loss: 8.5714 - val_rmse: 10.9053 - val_mse: 118.9260 - val_mae: 8.5714\n",
      "Epoch 95/200\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 8.0642 - rmse: 10.4278 - mse: 108.7395 - mae: 8.0642 - val_loss: 8.5478 - val_rmse: 10.8805 - val_mse: 118.3861 - val_mae: 8.5478\n",
      "Epoch 96/200\n",
      "54/54 [==============================] - 14s 255ms/step - loss: 8.0555 - rmse: 10.4087 - mse: 108.3408 - mae: 8.0555 - val_loss: 8.5416 - val_rmse: 10.8475 - val_mse: 117.6678 - val_mae: 8.5416\n",
      "Epoch 97/200\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 8.0371 - rmse: 10.3955 - mse: 108.0673 - mae: 8.0371 - val_loss: 8.5822 - val_rmse: 10.9255 - val_mse: 119.3662 - val_mae: 8.5822\n",
      "Epoch 98/200\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 8.0398 - rmse: 10.4018 - mse: 108.1966 - mae: 8.0398 - val_loss: 8.5708 - val_rmse: 10.9013 - val_mse: 118.8381 - val_mae: 8.5708\n",
      "Epoch 99/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.0442 - rmse: 10.4017 - mse: 108.1957 - mae: 8.0442 - val_loss: 8.5746 - val_rmse: 10.9114 - val_mse: 119.0590 - val_mae: 8.5746\n",
      "Epoch 100/200\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 8.0423 - rmse: 10.4002 - mse: 108.1640 - mae: 8.0423 - val_loss: 8.5561 - val_rmse: 10.8709 - val_mse: 118.1761 - val_mae: 8.5561\n",
      "Epoch 101/200\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.0320 - rmse: 10.3938 - mse: 108.0308 - mae: 8.0320 - val_loss: 8.5660 - val_rmse: 10.8904 - val_mse: 118.6009 - val_mae: 8.5660\n",
      "Epoch 102/200\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 8.0447 - rmse: 10.3983 - mse: 108.1244 - mae: 8.0447 - val_loss: 8.5770 - val_rmse: 10.9052 - val_mse: 118.9241 - val_mae: 8.5770\n",
      "Epoch 103/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 8.0309 - rmse: 10.3901 - mse: 107.9550 - mae: 8.0309- ETA: 3s - loss: 7.9814 - rmse: 10.3404 - mse: 106.Restoring model weights from the end of the best epoch.\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 8.0309 - rmse: 10.3901 - mse: 107.9550 - mae: 8.0309 - val_loss: 8.5406 - val_rmse: 10.8652 - val_mse: 118.0535 - val_mae: 8.5406\n",
      "Epoch 00103: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    hist = model.fit(ds_train,\n",
    "                     validation_data=ds_val,\n",
    "                     callbacks=callbacks,\n",
    "                     epochs=200,\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 197ms/step - loss: 8.4599 - rmse: 10.8038 - mse: 116.7224 - mae: 8.4599 1s - loss: 8.4899 - rmse: 10.8039 - mse: 116.7237\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    results = model.evaluate(ds_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Metric')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(16,16)\n",
    "\n",
    "    ax=fig.add_subplot(3,2,1)\n",
    "    ax.plot(hist.history['rmse'])\n",
    "    ax.plot(hist.history['mse'])\n",
    "    ax.legend(['Metric', 'Loss'])\n",
    "    ax.set_title('Train')\n",
    "\n",
    "    ax=fig.add_subplot(3,2,2)\n",
    "    ax.plot(hist.history['val_rmse'])\n",
    "    ax.plot(hist.history['val_mse'])\n",
    "    ax.legend(['Metric', 'Loss'])\n",
    "    ax.set_title('Test')\n",
    "\n",
    "    ax=fig.add_subplot(3,2,3)\n",
    "    ax.plot(hist.history['loss'])\n",
    "    ax.plot(hist.history['val_loss'])\n",
    "    ax.legend(['Train', 'Test'])\n",
    "    ax.set_title('Loss')\n",
    "\n",
    "    ax=fig.add_subplot(3,2,4)\n",
    "    ax.plot(hist.history['mse'])\n",
    "    ax.plot(hist.history['val_mse'])\n",
    "    ax.legend(['Train', 'Test'])\n",
    "    ax.set_title('Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = pd.read_csv('00_Data/fnc.csv')\n",
    "X1_test = X1_test[X1_test['Id'].isin(TEST_IDS)]\n",
    "X1_test = X1_test.to_numpy()\n",
    "X1_test = X1_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_test = pd.read_csv('00_Data/loading.csv')\n",
    "X2_test = X2_test[X2_test['Id'].isin(TEST_IDS)]\n",
    "X2_test = X2_test.to_numpy()\n",
    "X2_test = X2_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict([X1_test, X2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = y_preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = []\n",
    "i = 0\n",
    "for idx in TEST_IDS:\n",
    "    df_submission.append(['{0}_age'.format(idx), y_preds[i]])\n",
    "    df_submission.append(['{0}_domain1_var1'.format(idx), y_preds[i+1]])\n",
    "    df_submission.append(['{0}_domain1_var2'.format(idx), y_preds[i+2]])\n",
    "    df_submission.append(['{0}_domain2_var1'.format(idx), y_preds[i+3]])\n",
    "    df_submission.append(['{0}_domain2_var2'.format(idx), y_preds[i+4]])\n",
    "    i += 5\n",
    "\n",
    "df_submission = pd.DataFrame(df_submission, columns=['Id', 'Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('submission_fnc-load_mae_07.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.108977</td>\n",
       "      <td>69.993075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>21746</td>\n",
       "      <td>14.257265</td>\n",
       "      <td>21.358872</td>\n",
       "      <td>61.165998</td>\n",
       "      <td>51.778483</td>\n",
       "      <td>54.640179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>21747</td>\n",
       "      <td>55.456978</td>\n",
       "      <td>68.169675</td>\n",
       "      <td>29.907995</td>\n",
       "      <td>55.349257</td>\n",
       "      <td>54.019517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>21750</td>\n",
       "      <td>48.948756</td>\n",
       "      <td>55.114811</td>\n",
       "      <td>60.878271</td>\n",
       "      <td>38.617246</td>\n",
       "      <td>50.679885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>21752</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>59.844808</td>\n",
       "      <td>72.303110</td>\n",
       "      <td>55.458281</td>\n",
       "      <td>46.870235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>21754</td>\n",
       "      <td>68.820928</td>\n",
       "      <td>56.594193</td>\n",
       "      <td>34.605868</td>\n",
       "      <td>49.922535</td>\n",
       "      <td>50.383078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2\n",
       "0     10001  57.436077     30.571975     62.553736     53.325130     51.427998\n",
       "1     10002  59.580851     50.969456     67.470628     60.651856     58.311361\n",
       "2     10004  71.413018     53.152498     58.012103     52.418389     62.536641\n",
       "3     10005  66.532630           NaN           NaN     52.108977     69.993075\n",
       "4     10007  38.617381     49.197021     65.674285     40.151376     34.096421\n",
       "...     ...        ...           ...           ...           ...           ...\n",
       "5872  21746  14.257265     21.358872     61.165998     51.778483     54.640179\n",
       "5873  21747  55.456978     68.169675     29.907995     55.349257     54.019517\n",
       "5874  21750  48.948756     55.114811     60.878271     38.617246     50.679885\n",
       "5875  21752  66.532630     59.844808     72.303110     55.458281     46.870235\n",
       "5876  21754  68.820928     56.594193     34.605868     49.922535     50.383078\n",
       "\n",
       "[5877 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('00_Data/train_scores.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nulls = data[data.isnull().any(axis=1)]\n",
    "NULL_IDS = list(data_nulls['Id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
