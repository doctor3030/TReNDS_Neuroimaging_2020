{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "from IPython.display import IFrame\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing as prep\n",
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IDS = [map_id.split('.')[0] for map_id in sorted(os.listdir('00_Data/fMRI_test'))]\n",
    "TRAIN_IDS = [map_id.split('.')[0] for map_id in sorted(os.listdir('00_Data/fMRI_train'))]\n",
    "ALL_IDS = TRAIN_IDS + TEST_IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10008</td>\n",
       "      <td>35.326582</td>\n",
       "      <td>15.769168</td>\n",
       "      <td>65.782269</td>\n",
       "      <td>44.643805</td>\n",
       "      <td>50.448485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>21654</td>\n",
       "      <td>53.103634</td>\n",
       "      <td>50.951656</td>\n",
       "      <td>62.168022</td>\n",
       "      <td>49.389400</td>\n",
       "      <td>53.020847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>21665</td>\n",
       "      <td>38.246437</td>\n",
       "      <td>48.018227</td>\n",
       "      <td>59.522285</td>\n",
       "      <td>45.697098</td>\n",
       "      <td>53.208160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>21674</td>\n",
       "      <td>69.414169</td>\n",
       "      <td>58.593918</td>\n",
       "      <td>60.298779</td>\n",
       "      <td>49.865669</td>\n",
       "      <td>47.863167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>21693</td>\n",
       "      <td>62.009209</td>\n",
       "      <td>54.272484</td>\n",
       "      <td>60.474388</td>\n",
       "      <td>52.325031</td>\n",
       "      <td>52.989803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>21734</td>\n",
       "      <td>36.072495</td>\n",
       "      <td>46.474880</td>\n",
       "      <td>61.304012</td>\n",
       "      <td>42.742592</td>\n",
       "      <td>53.425110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2\n",
       "0     10001  57.436077     30.571975     62.553736     53.325130     51.427998\n",
       "1     10002  59.580851     50.969456     67.470628     60.651856     58.311361\n",
       "2     10004  71.413018     53.152498     58.012103     52.418389     62.536641\n",
       "3     10007  38.617381     49.197021     65.674285     40.151376     34.096421\n",
       "4     10008  35.326582     15.769168     65.782269     44.643805     50.448485\n",
       "...     ...        ...           ...           ...           ...           ...\n",
       "5872  21654  53.103634     50.951656     62.168022     49.389400     53.020847\n",
       "5873  21665  38.246437     48.018227     59.522285     45.697098     53.208160\n",
       "5874  21674  69.414169     58.593918     60.298779     49.865669     47.863167\n",
       "5875  21693  62.009209     54.272484     60.474388     52.325031     52.989803\n",
       "5876  21734  36.072495     46.474880     61.304012     42.742592     53.425110\n",
       "\n",
       "[5877 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('00_Data/train_scores_full.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(idx):\n",
    "    #MRI inputs\n",
    "    patient_SM = h5py.File('00_Data/fMRI_all/{0}.mat'.format(idx), mode='r')\n",
    "    patient_SM = np.array(patient_SM.get('SM_feature'))\n",
    "#     print(patient_SM.shape)\n",
    "    k = 1\n",
    "    ki_padding = 3\n",
    "    \n",
    "    arr_regions = []\n",
    "    for i in range(patient_SM.shape[0]):\n",
    "        sample_map = patient_SM[i,:,:,:]\n",
    "        if k > 1:\n",
    "            map_shape = sample_map.shape\n",
    "            shape_pad = ((map_shape[0]//k + 1)*k - map_shape[0],\n",
    "                         (map_shape[1]//k + 1)*k - map_shape[1],\n",
    "                         (map_shape[2]//k + 1)*k - map_shape[2])\n",
    "\n",
    "            npad = (((0 if shape_pad[0]%2==0 else shape_pad[0]//2), (shape_pad[0]//2 if shape_pad[0]%2==0 else shape_pad[0]//2+1)),    \n",
    "                    ((0 if shape_pad[1]%2==0 else shape_pad[0]//2), (shape_pad[1]//2 if shape_pad[1]%2==0 else shape_pad[1]//2+1)),    \n",
    "                    ((0 if shape_pad[2]%2==0 else shape_pad[0]//2), (shape_pad[2]//2 if shape_pad[2]%2==0 else shape_pad[2]//2+1)))\n",
    "\n",
    "            sample_map_padded = np.pad(sample_map, pad_width=npad, mode='constant', constant_values=0)\n",
    "\n",
    "            sx = sample_map_padded.shape[0] / k\n",
    "            sy = sample_map_padded.shape[1] / k\n",
    "            sz = sample_map_padded.shape[2] / k\n",
    "            for kz in range(k):\n",
    "                for ky in range(k):\n",
    "                    for kx in range(k):\n",
    "                        ki_region = sample_map_padded[int(kx*sx): int(kx*sx + sx - 1), \n",
    "                                                     int(ky*sy): int(ky*sy + sy - 1), \n",
    "                                                     int(kz*sz): int(kz*sz + sz - 1)]\n",
    "                        #padding i-th region by 3 pixels\n",
    "                        ki_region_padded = np.pad(ki_region, pad_width=ki_padding, mode='constant', constant_values=0)\n",
    "                        arr_regions.append(ki_region_padded)\n",
    "        else:\n",
    "            map_shape = sample_map.shape\n",
    "            shape_pad = ((map_shape[0]//2 + 1)*2 - map_shape[0],\n",
    "                         (map_shape[1]//2 + 1)*2 - map_shape[1],\n",
    "                         (map_shape[2]//2 + 1)*2 - map_shape[2])\n",
    "\n",
    "            npad = (((0 if shape_pad[0]%2==0 else shape_pad[0]//2+1), (0 if shape_pad[0]%2==0 else shape_pad[0]//2+1)),    \n",
    "                    ((0 if shape_pad[1]%2==0 else shape_pad[0]//2+1), (0 if shape_pad[1]%2==0 else shape_pad[1]//2+1)),    \n",
    "                    ((0 if shape_pad[2]%2==0 else shape_pad[0]//2+1), (0 if shape_pad[2]%2==0 else shape_pad[2]//2+1)))\n",
    "\n",
    "            sample_map_padded = np.pad(sample_map, pad_width=npad, mode='constant', constant_values=0)\n",
    "            \n",
    "#             sample_map_padded = np.pad(sample_map, pad_width=ki_padding, mode='constant', constant_values=0)\n",
    "            arr_regions.append(sample_map_padded)\n",
    "            \n",
    "    X_mri = np.stack(arr_regions, axis=3)\n",
    "#     print(X_mri.shape)\n",
    "    return X_mri, X_mri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_inputs('10002')[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_py_function(func, inp, Tout, name=None):\n",
    "    \n",
    "    def wrapped_func(*flat_inp):\n",
    "        reconstructed_inp = tf.nest.pack_sequence_as(inp, flat_inp,\n",
    "                                                     expand_composites=True)\n",
    "        out = func(*reconstructed_inp)\n",
    "        return tf.nest.flatten(out, expand_composites=True)\n",
    "    \n",
    "    flat_Tout = tf.nest.flatten(Tout, expand_composites=True)\n",
    "    flat_out = tf.py_function(func=wrapped_func, \n",
    "                              inp=tf.nest.flatten(inp, expand_composites=True),\n",
    "                              Tout=[_tensor_spec_to_dtype(v) for v in flat_Tout],\n",
    "                              name=name)\n",
    "    spec_out = tf.nest.map_structure(_dtype_to_tensor_spec, Tout, expand_composites=True)\n",
    "    out = tf.nest.pack_sequence_as(spec_out, flat_out, expand_composites=True)\n",
    "    return out\n",
    "\n",
    "def _dtype_to_tensor_spec(v):\n",
    "    return tf.TensorSpec(None, v) if isinstance(v, tf.dtypes.DType) else v\n",
    "\n",
    "def _tensor_spec_to_dtype(v):\n",
    "    return v.dtype if isinstance(v, tf.TensorSpec) else v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data, batch_size):\n",
    "    data = np.array([int(i) for i in data])\n",
    "    data = tf.data.Dataset.from_tensor_slices(data)\n",
    "    data = data.shuffle(buffer_size=4000, seed=30, reshuffle_each_iteration=True)\n",
    "    \n",
    "    data = data.map(lambda idx: new_py_function(get_inputs, inp=[idx], \n",
    "                                                    Tout=(tf.TensorSpec(shape=(None, 52, 66, 56, 53), dtype=tf.dtypes.float64),\n",
    "                                                          tf.TensorSpec(shape=(None, 52, 66, 56, 53), dtype=tf.dtypes.float64)), name=None), \n",
    "                     num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "                     deterministic=False)\n",
    "#     data = data.map(lambda idx: tf.py_function(get_inputs, inp=[idx], \n",
    "#                                                     Tout=tf.float64, name=None), \n",
    "#                      num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "#                      deterministic=False)\n",
    "    data = data.batch(batch_size, drop_remainder=False)\n",
    "    data = data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(ALL_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['Id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array([int(i) for i in ALL_IDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = model_selection.train_test_split(data, test_size=0.2, shuffle=True, random_state=30)\n",
    "# train, val = model_selection.train_test_split(train, test_size=0.2, shuffle=True, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "ds_train = get_dataset(ALL_IDS, batch_size)\n",
    "# ds_val = get_dataset(val, batch_size)\n",
    "# ds_test = get_dataset(test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in ds_train.take(1):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE_mri = (52, 66, 56, 53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ClusteringLayer(keras.layers.Layer):\n",
    "#     \"\"\"\n",
    "#     Clustering layer converts input sample (feature) to soft label.\n",
    "\n",
    "#     # Example\n",
    "#     ```\n",
    "#         model.add(ClusteringLayer(n_clusters=10))\n",
    "#     ```\n",
    "#     # Arguments\n",
    "#         n_clusters: number of clusters.\n",
    "#         weights: list of Numpy array with shape `(n_clusters, n_features)` witch represents the initial cluster centers.\n",
    "#         alpha: degrees of freedom parameter in Student's t-distribution. Default to 1.0.\n",
    "#     # Input shape\n",
    "#         2D tensor with shape: `(n_samples, n_features)`.\n",
    "#     # Output shape\n",
    "#         2D tensor with shape: `(n_samples, n_clusters)`.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "#         if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "#             kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "#         super(ClusteringLayer, self).__init__(**kwargs)\n",
    "#         self.n_clusters = n_clusters\n",
    "#         self.alpha = alpha\n",
    "#         self.initial_weights = weights\n",
    "#         self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         assert len(input_shape) == 2\n",
    "#         input_dim = input_shape[1]\n",
    "#         self.input_spec = keras.layers.InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "#         self.clusters = self.add_weight((self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "#         if self.initial_weights is not None:\n",
    "#             self.set_weights(self.initial_weights)\n",
    "#             del self.initial_weights\n",
    "#         self.built = True\n",
    "\n",
    "#     def call(self, inputs, **kwargs):\n",
    "#         \"\"\" student t-distribution, as same as used in t-SNE algorithm.        \n",
    "#                  q_ij = 1/(1+dist(x_i, Âµ_j)^2), then normalize it.\n",
    "#                  q_ij can be interpreted as the probability of assigning sample i to cluster j.\n",
    "#                  (i.e., a soft assignment)\n",
    "#         Arguments:\n",
    "#             inputs: the variable containing data, shape=(n_samples, n_features)\n",
    "#         Return:\n",
    "#             q: student's t-distribution, or soft labels for each sample. shape=(n_samples, n_clusters)\n",
    "#         \"\"\"\n",
    "#         q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "#         q **= (self.alpha + 1.0) / 2.0\n",
    "#         q = K.transpose(K.transpose(q) / K.sum(q, axis=1)) # Make sure each sample's 10 values add up to 1.\n",
    "#         return q\n",
    "\n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         assert input_shape and len(input_shape) == 2\n",
    "#         return input_shape[0], self.n_clusters\n",
    "\n",
    "#     def get_config(self):\n",
    "#         config = {'n_clusters': self.n_clusters}\n",
    "#         base_config = super(ClusteringLayer, self).get_config()\n",
    "#         return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, filters=[32, 16, 8, 2]):\n",
    "#     if input_shape[0] % 8 == 0:\n",
    "#         pad3 = 'same'\n",
    "#     else:\n",
    "#         pad3 = 'valid'\n",
    "    \n",
    "    #============================================================================\n",
    "    # CNN for MRI images processing\n",
    "    #============================================================================\n",
    "    inputs_mri = keras.layers.Input(shape=INPUT_SHAPE_mri, name='inpupt_mri')\n",
    "\n",
    "    # convolution block #1\n",
    "    x = keras.layers.Conv3D(filters[0], kernel_size=(3, 3, 3), strides=(1,1,1), padding='same',\n",
    "                                  kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                                  bias_initializer=keras.initializers.Constant(0.01))(inputs_mri)\n",
    "    x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = keras.layers.Conv3D(filters[0], kernel_size=(3, 3, 3), strides=(1,1,1), padding='same',\n",
    "                                  kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                                  bias_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = keras.layers.MaxPooling3D(pool_size=(2, 2, 2), strides=(2,2,2))(x)\n",
    "#     x, p1_idx = tf.nn.max_pool_with_argmax(x, ksize=[2], strides=[2], padding='SAME', name=\"p1\")\n",
    "    x = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                              beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                              moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                              beta_constraint=None, gamma_constraint=None)(x)\n",
    "\n",
    "    # convolution block #2\n",
    "    x = keras.layers.Conv3D(filters[1], kernel_size=(3, 3, 3), strides=(1,1,1), padding='same',\n",
    "                                  kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                                  bias_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = keras.layers.Conv3D(filters[1], kernel_size=(3, 3, 3), strides=(1,1,1), padding='same',\n",
    "                                  kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                                  bias_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = keras.layers.MaxPooling3D(pool_size=(2, 2, 2), strides=(2,2,2))(x)\n",
    "    x = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                              beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                              moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                              beta_constraint=None, gamma_constraint=None)(x)\n",
    "\n",
    "    # convolution block #3\n",
    "    x = keras.layers.Conv3D(filters[2], kernel_size=(3, 3, 3), strides=(1,1,1), padding='same',\n",
    "                                  kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                                  bias_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = keras.layers.Conv3D(filters[2], kernel_size=(3, 3, 3), strides=(1,1,1), padding='same',\n",
    "                                  kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                                  bias_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = keras.layers.MaxPooling3D(pool_size=(2, 2, 2), strides=(2,2,2))(x)\n",
    "    x = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                              beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                              moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                              beta_constraint=None, gamma_constraint=None)(x)\n",
    "\n",
    "    # convolution block #4\n",
    "#     x = keras.layers.Conv3D(filters[3], kernel_size=(3, 3, 3), strides=(1,1,1), padding='same',\n",
    "#                                   kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "#                                   bias_initializer=keras.initializers.Constant(0.01))(x)\n",
    "#     x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "#     x = keras.layers.Conv3D(filters[3], kernel_size=(3, 3, 3), strides=(1,1,1), padding='same',\n",
    "#                                   kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "#                                   bias_initializer=keras.initializers.Constant(0.01))(x)\n",
    "#     x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "#     x = keras.layers.MaxPooling3D(pool_size=(2, 2, 2), strides=(2,2,2))(x)\n",
    "#     x = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                               beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                               moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                               beta_constraint=None, gamma_constraint=None)(x)\n",
    "    \n",
    "#     shape_before_flattening = K.int_shape(x)\n",
    "\n",
    "    flatten = keras.layers.Flatten(data_format='channels_last')(x)\n",
    "\n",
    "    encoded = keras.layers.Dense(2,\n",
    "                               kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                               bias_initializer=keras.initializers.Constant(5.))(flatten)\n",
    "    encoded = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(encoded)\n",
    "    \n",
    "\n",
    "#     filters=[64, 32, 16, 8, 2]\n",
    "#     INPUT_SHAPE_mri = (52, 66, 56, 53)\n",
    "    \n",
    "    # Decoder\n",
    "    x = keras.layers.Dense(filters[2]*int(input_shape[0]/8)*int(input_shape[1]/8)*int(input_shape[2]/8),\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(encoded)\n",
    "    \n",
    "    x = keras.layers.Reshape((int(input_shape[0]/8), int(input_shape[1]/8), int(input_shape[2]/8), filters[2]))(x)\n",
    "    \n",
    "    # convolution block #4\n",
    "#     x = tf.keras.layers.UpSampling3D(size=(2, 2, 2))(x)\n",
    "#     x = tf.keras.layers.Conv3DTranspose(filters[2], kernel_size=(1, 1, 2), strides=(1,1,1), padding='valid',\n",
    "#                                         kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "#                                         bias_initializer=keras.initializers.Constant(0.01))(x)\n",
    "#     x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    \n",
    "    # convolution block #3\n",
    "    x = tf.keras.layers.UpSampling3D(size=(2, 2, 2))(x)\n",
    "    x = tf.keras.layers.Conv3DTranspose(filters[2], kernel_size=(2, 1, 1), strides=(1,1,1), padding='valid',\n",
    "                                        kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                                        bias_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.Conv3DTranspose(filters[2], kernel_size=(2, 1, 1), strides=(1,1,1), padding='same',\n",
    "                                        kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                                        bias_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    \n",
    "    # convolution block #2\n",
    "    x = tf.keras.layers.UpSampling3D(size=(2, 2, 2))(x)\n",
    "    x = tf.keras.layers.Conv3DTranspose(filters[1], kernel_size=(1, 2, 1), strides=(1,1,1), padding='valid',\n",
    "                                        kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                                        bias_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.Conv3DTranspose(filters[1], kernel_size=(1, 2, 1), strides=(1,1,1), padding='same',\n",
    "                                        kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                                        bias_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    \n",
    "    # convolution block #1\n",
    "    x = tf.keras.layers.UpSampling3D(size=(2, 2, 2))(x)\n",
    "    x = tf.keras.layers.Conv3DTranspose(filters[0], kernel_size=(1, 1, 1), strides=(1,1,1), padding='valid',\n",
    "                                        kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                                        bias_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.Conv3DTranspose(filters[0], kernel_size=(1, 1, 1), strides=(1,1,1), padding='same',\n",
    "                                        kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                                        bias_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.Conv3DTranspose(input_shape[3], kernel_size=(1, 1, 1), strides=(1,1,1), padding='valid',\n",
    "                                        kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                                        bias_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.01))(x)\n",
    "    \n",
    "    # Output\n",
    "#     decoded = keras.layers.Conv3D(53, kernel_size=(3, 3, 3), activation='sigmoid', padding='same')(x)\n",
    "    decoded = x\n",
    "\n",
    "    autoencoder = keras.Model(inputs=inputs_mri, outputs=decoded, name='autoencoder')\n",
    "    encoder = keras.Model(inputs=inputs_mri, outputs=encoded, name='encoder')\n",
    "\n",
    "    optim = tf.keras.optimizers.Adadelta(learning_rate=0.001, rho=0.95)\n",
    "\n",
    "    METRICS = [keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    "\n",
    "    autoencoder.compile(loss='mse', metrics=METRICS, optimizer=optim)\n",
    "#     encoder.compile(loss='mse', metrics=METRICS, optimizer=optim)\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters=[64, 32, 16, 8, 2]\n",
    "# input_shape = (52, 66, 56, 53)\n",
    "# # filters[3]*int(input_shape[0]/8)*int(input_shape[0]/8)\n",
    "# (int(input_shape[0]/8), int(input_shape[1]/8), int(input_shape[2]/8), filters[2])\n",
    "# filters[2]*int(input_shape[0]/8)*int(input_shape[0]/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encoder = create_model(INPUT_SHAPE_mri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inpupt_mri (InputLayer)      [(None, 52, 66, 56, 53)]  0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 52, 66, 56, 32)    45824     \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, 52, 66, 56, 32)    6150144   \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 52, 66, 56, 32)    27680     \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 52, 66, 56, 32)    6150144   \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 26, 33, 28, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 33, 28, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 26, 33, 28, 16)    13840     \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 26, 33, 28, 16)    384384    \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 26, 33, 28, 16)    6928      \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, 26, 33, 28, 16)    384384    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 13, 16, 14, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 13, 16, 14, 16)    64        \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 13, 16, 14, 8)     3464      \n",
      "_________________________________________________________________\n",
      "p_re_lu_4 (PReLU)            (None, 13, 16, 14, 8)     23296     \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 13, 16, 14, 8)     1736      \n",
      "_________________________________________________________________\n",
      "p_re_lu_5 (PReLU)            (None, 13, 16, 14, 8)     23296     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 6, 8, 7, 8)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 6, 8, 7, 8)        32        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 5378      \n",
      "_________________________________________________________________\n",
      "p_re_lu_6 (PReLU)            (None, 2)                 2         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2688)              8064      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 6, 8, 7, 8)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling3d (UpSampling3D) (None, 12, 16, 14, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose (Conv3DTran (None, 13, 16, 14, 8)     136       \n",
      "_________________________________________________________________\n",
      "p_re_lu_7 (PReLU)            (None, 13, 16, 14, 8)     23296     \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_1 (Conv3DTr (None, 13, 16, 14, 8)     136       \n",
      "_________________________________________________________________\n",
      "p_re_lu_8 (PReLU)            (None, 13, 16, 14, 8)     23296     \n",
      "_________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3 (None, 26, 32, 28, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_2 (Conv3DTr (None, 26, 33, 28, 16)    272       \n",
      "_________________________________________________________________\n",
      "p_re_lu_9 (PReLU)            (None, 26, 33, 28, 16)    384384    \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_3 (Conv3DTr (None, 26, 33, 28, 16)    528       \n",
      "_________________________________________________________________\n",
      "p_re_lu_10 (PReLU)           (None, 26, 33, 28, 16)    384384    \n",
      "_________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3 (None, 52, 66, 56, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_4 (Conv3DTr (None, 52, 66, 56, 32)    544       \n",
      "_________________________________________________________________\n",
      "p_re_lu_11 (PReLU)           (None, 52, 66, 56, 32)    6150144   \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_5 (Conv3DTr (None, 52, 66, 56, 32)    1056      \n",
      "_________________________________________________________________\n",
      "p_re_lu_12 (PReLU)           (None, 52, 66, 56, 32)    6150144   \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_6 (Conv3DTr (None, 52, 66, 56, 53)    1749      \n",
      "_________________________________________________________________\n",
      "p_re_lu_13 (PReLU)           (None, 52, 66, 56, 53)    10186176  \n",
      "=================================================================\n",
      "Total params: 36,535,033\n",
      "Trainable params: 36,534,921\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### checkpoint_dir = './99_Training_checkpoints/mri-fnc-loading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "#                                               min_delta=0.001, \n",
    "#                                               patience=10, \n",
    "#                                               verbose=1, \n",
    "#                                               mode='min',\n",
    "#                                               baseline=None, \n",
    "#                                               restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefix = os.path.join('./99_Training_checkpoints/mri_clustering', \"ckpt_{epoch}\")\n",
    "\n",
    "callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/mri_clustering'),\n",
    "             tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                                save_weights_only=True),\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              min_delta=0.001, \n",
    "                                              patience=5, \n",
    "                                              verbose=1, \n",
    "                                              mode='min',\n",
    "                                              baseline=None, \n",
    "                                              restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1470/1470 [==============================] - 8630s 6s/step - loss: 1.2870 - rmse: 1.1345 - val_loss: 0.7527 - val_rmse: 0.8676\n",
      "Epoch 2/400\n",
      "1470/1470 [==============================] - 8586s 6s/step - loss: 0.6158 - rmse: 0.7847 - val_loss: 0.5071 - val_rmse: 0.7121\n",
      "Epoch 3/400\n",
      "1470/1470 [==============================] - 8569s 6s/step - loss: 0.4421 - rmse: 0.6649 - val_loss: 0.3925 - val_rmse: 0.6265\n",
      "Epoch 4/400\n",
      "1470/1470 [==============================] - 8578s 6s/step - loss: 0.3654 - rmse: 0.6045 - val_loss: 0.3449 - val_rmse: 0.5872\n",
      "Epoch 5/400\n",
      "1470/1470 [==============================] - 8574s 6s/step - loss: 0.3325 - rmse: 0.5766 - val_loss: 0.3227 - val_rmse: 0.5681\n",
      "Epoch 6/400\n",
      "1470/1470 [==============================] - 8629s 6s/step - loss: 0.3165 - rmse: 0.5626 - val_loss: 0.3116 - val_rmse: 0.5582\n",
      "Epoch 7/400\n",
      "1470/1470 [==============================] - 8830s 6s/step - loss: 0.3085 - rmse: 0.5554 - val_loss: 0.3060 - val_rmse: 0.5532\n",
      "Epoch 8/400\n",
      "1470/1470 [==============================] - 8700s 6s/step - loss: 0.3045 - rmse: 0.5518 - val_loss: 0.3032 - val_rmse: 0.5507\n",
      "Epoch 9/400\n",
      "1470/1470 [==============================] - 8703s 6s/step - loss: 0.3024 - rmse: 0.5499 - val_loss: 0.3018 - val_rmse: 0.5493\n",
      "Epoch 10/400\n",
      "1470/1470 [==============================] - 8673s 6s/step - loss: 0.3013 - rmse: 0.5489 - val_loss: 0.3010 - val_rmse: 0.5486\n",
      "Epoch 11/400\n",
      "1470/1470 [==============================] - 8659s 6s/step - loss: 0.3007 - rmse: 0.5483 - val_loss: 0.3004 - val_rmse: 0.5481\n",
      "Epoch 12/400\n",
      "1470/1470 [==============================] - 8618s 6s/step - loss: 0.3002 - rmse: 0.5479 - val_loss: 0.3001 - val_rmse: 0.5478\n",
      "Epoch 13/400\n",
      "1470/1470 [==============================] - 8625s 6s/step - loss: 0.2999 - rmse: 0.5477 - val_loss: 0.2998 - val_rmse: 0.5475\n",
      "Epoch 14/400\n",
      "1470/1470 [==============================] - 8628s 6s/step - loss: 0.2997 - rmse: 0.5474 - val_loss: 0.2996 - val_rmse: 0.5473\n",
      "Epoch 15/400\n",
      "1470/1470 [==============================] - 8620s 6s/step - loss: 0.2995 - rmse: 0.5473 - val_loss: 0.2994 - val_rmse: 0.5472\n",
      "Epoch 16/400\n",
      "1470/1470 [==============================] - 8551s 6s/step - loss: 0.2993 - rmse: 0.5471 - val_loss: 0.2993 - val_rmse: 0.5471\n",
      "Epoch 17/400\n",
      "1470/1470 [==============================] - 8675s 6s/step - loss: 0.2992 - rmse: 0.5470 - val_loss: 0.2992 - val_rmse: 0.5470\n",
      "Epoch 18/400\n",
      "1470/1470 [==============================] - 8658s 6s/step - loss: 0.2991 - rmse: 0.5469 - val_loss: 0.2990 - val_rmse: 0.5469\n",
      "Epoch 19/400\n",
      "1470/1470 [==============================] - 8661s 6s/step - loss: 0.2990 - rmse: 0.5468 - val_loss: 0.2990 - val_rmse: 0.5468\n",
      "Epoch 20/400\n",
      "1470/1470 [==============================] - ETA: 0s - loss: 0.2989 - rmse: 0.5467Restoring model weights from the end of the best epoch.\n",
      "1470/1470 [==============================] - 8682s 6s/step - loss: 0.2989 - rmse: 0.5467 - val_loss: 0.2989 - val_rmse: 0.5467\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "# with tf.device('/CPU:0'):\n",
    "    hist = autoencoder.fit(ds_train,\n",
    "                     validation_data=ds_train,\n",
    "                     callbacks=callbacks,\n",
    "                     epochs=400,\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights('./99_Training_checkpoints/mri_clustering/model_weights_02.h5')\n",
    "# tf.keras.models.save_model(autoencoder, \n",
    "#                            filepath='./99_Training_checkpoints/mri_clustering/model_02.h5', overwrite=True, include_optimizer=True, save_format=None,\n",
    "#     signatures=None, options=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights('./99_Training_checkpoints/mri_clustering/model_weights_02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(16,8)\n",
    "\n",
    "#     ax=fig.add_subplot(3,2,1)\n",
    "#     ax.plot(hist.history['rmse'])\n",
    "#     ax.plot(hist.history['mse'])\n",
    "#     ax.legend(['Metric', 'Loss'])\n",
    "#     ax.set_title('Train')\n",
    "\n",
    "#     ax=fig.add_subplot(3,2,2)\n",
    "#     ax.plot(hist.history['val_rmse'])\n",
    "#     ax.plot(hist.history['val_mse'])\n",
    "#     ax.legend(['Metric', 'Loss'])\n",
    "#     ax.set_title('Test')\n",
    "\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.plot(hist.history['loss'])\n",
    "    ax.plot(hist.history['val_loss'])\n",
    "    ax.legend(['Train', 'Test'])\n",
    "    ax.set_title('Loss')\n",
    "\n",
    "#     ax=fig.add_subplot(3,2,4)\n",
    "#     ax.plot(hist.history['mse'])\n",
    "#     ax.plot(hist.history['val_mse'])\n",
    "#     ax.legend(['Train', 'Test'])\n",
    "#     ax.set_title('Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_subm(idx):\n",
    "    # FNC inputs\n",
    "    df_fnc = pd.read_csv('00_Data/fnc_csv/{0}.csv'.format(idx), index_col=0)\n",
    "    X_fnc = np.array(df_fnc.values).reshape(-1)\n",
    "    \n",
    "    # Loading inputs\n",
    "    df_loading = pd.read_csv('00_Data/loading_csv/{0}.csv'.format(idx), index_col=0)\n",
    "    X_loading = np.array(df_loading.values).reshape(-1)\n",
    "    \n",
    "    #MRI inputs\n",
    "    patient_SM = h5py.File('00_Data/fMRI_test/{0}.mat'.format(idx), mode='r')\n",
    "    patient_SM = np.array(patient_SM.get('SM_feature'))\n",
    "#     patient_SM = mat.transpose([1,2,3,0])\n",
    "\n",
    "#     print('patient: {idx}')\n",
    "    \n",
    "    k = 1\n",
    "    ki_padding = 3\n",
    "    \n",
    "    arr_regions = []\n",
    "    for i in range(patient_SM.shape[0]):\n",
    "        sample_map = patient_SM[i,:,:,:]\n",
    "#         print(len(arr_regions))\n",
    "        # padding MRI map\n",
    "        if k > 1:\n",
    "            map_shape = sample_map.shape\n",
    "            shape_pad = ((map_shape[0]//k + 1)*k - map_shape[0],\n",
    "                         (map_shape[1]//k + 1)*k - map_shape[1],\n",
    "                         (map_shape[2]//k + 1)*k - map_shape[2])\n",
    "\n",
    "            npad = ((shape_pad[0]//2, (shape_pad[0]//2 if shape_pad[0]%2==0 else shape_pad[0]//2+1)),    \n",
    "                    (shape_pad[1]//2, (shape_pad[1]//2 if shape_pad[1]%2==0 else shape_pad[1]//2+1)),    \n",
    "                    (shape_pad[2]//2, (shape_pad[2]//2 if shape_pad[2]%2==0 else shape_pad[2]//2+1)))\n",
    "\n",
    "            sample_map_padded = np.pad(sample_map, pad_width=npad, mode='constant', constant_values=0)\n",
    "\n",
    "            sx = sample_map_padded.shape[0] / k\n",
    "            sy = sample_map_padded.shape[1] / k\n",
    "            sz = sample_map_padded.shape[2] / k\n",
    "            for kz in range(k):\n",
    "                for ky in range(k):\n",
    "                    for kx in range(k):\n",
    "                        ki_region = sample_map_padded[int(kx*sx): int(kx*sx + sx - 1), \n",
    "                                                     int(ky*sy): int(ky*sy + sy - 1), \n",
    "                                                     int(kz*sz): int(kz*sz + sz - 1)]\n",
    "                        #padding i-th region by 3 pixels\n",
    "                        ki_region_padded = np.pad(ki_region, pad_width=ki_padding, mode='constant', constant_values=0)\n",
    "                        arr_regions.append(ki_region_padded)\n",
    "        else:\n",
    "            map_padded = np.pad(sample_map, pad_width=ki_padding, mode='constant', constant_values=0)\n",
    "            arr_regions.append(map_padded)\n",
    "#             print(map_padded.shape)\n",
    "    X_mri = np.stack(arr_regions, axis=3)\n",
    "    \n",
    "#     X = (X_mri, X_fnc, X_loading)\n",
    "    return X_mri, X_fnc, X_loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "for i in TEST_IDS:\n",
    "    X_mri, X_fnc, X_loading = get_inputs_subm(i)\n",
    "    X_mri = X_mri.reshape(1,58, 69, 59, 53)\n",
    "    X_fnc = X_fnc.reshape(1,1378)\n",
    "    X_loading = X_loading.reshape(1,26)\n",
    "    preds = model.predict([X_mri, X_fnc, X_loading], batch_size=1)\n",
    "    y_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5877"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.array(y_preds).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = []\n",
    "i = 0\n",
    "for idx in TEST_IDS:\n",
    "    df_submission.append(['{0}_age'.format(idx), y_preds[i]])\n",
    "    df_submission.append(['{0}_domain1_var1'.format(idx), y_preds[i+1]])\n",
    "    df_submission.append(['{0}_domain1_var2'.format(idx), y_preds[i+2]])\n",
    "    df_submission.append(['{0}_domain2_var1'.format(idx), y_preds[i+3]])\n",
    "    df_submission.append(['{0}_domain2_var2'.format(idx), y_preds[i+4]])\n",
    "    i += 5\n",
    "\n",
    "df_submission = pd.DataFrame(df_submission, columns=['Id', 'Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('submission_mri-fnc-load_mae_08.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
