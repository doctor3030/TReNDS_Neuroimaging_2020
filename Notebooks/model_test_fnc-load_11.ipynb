{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "from IPython.display import IFrame\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "\n",
    "import scipy.stats as sts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing as prep\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn import discriminant_analysis as disan\n",
    "from sklearn import calibration as calib\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn import svm\n",
    "from sklearn import gaussian_process as gaup\n",
    "from sklearn import mixture as mix\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble as ens\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# from keras import models as kermdls\n",
    "# from keras import layers as kerlrs\n",
    "# from keras import metrics as kmetrics\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "import pickle\n",
    "\n",
    "import nilearn as nl\n",
    "from nilearn import plotting, image\n",
    "from nilearn import datasets\n",
    "import nibabel as nb\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5945836021926194012\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12249910470899978829\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6589725830\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15500259890345464202\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12265047953424415564\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnc_10 = pd.read_csv('00_Data/fnc.csv')\n",
    "# fnc_10 = fnc_10.head(5)\n",
    "# for row in fnc_10.iterrows():\n",
    "#     idx = int(row[1][0])\n",
    "#     row = row[1][1:]\n",
    "#     print(row)\n",
    "#     row.to_csv('00_Data/fnc_csv_norm/{0}.csv'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IDS = [map_id.split('.')[0] for map_id in sorted(os.listdir('00_Data/fMRI_test'))]\n",
    "TRAIN_IDS = [map_id.split('.')[0] for map_id in sorted(os.listdir('00_Data/fMRI_train'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.108977</td>\n",
       "      <td>69.993075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>21746</td>\n",
       "      <td>14.257265</td>\n",
       "      <td>21.358872</td>\n",
       "      <td>61.165998</td>\n",
       "      <td>51.778483</td>\n",
       "      <td>54.640179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>21747</td>\n",
       "      <td>55.456978</td>\n",
       "      <td>68.169675</td>\n",
       "      <td>29.907995</td>\n",
       "      <td>55.349257</td>\n",
       "      <td>54.019517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>21750</td>\n",
       "      <td>48.948756</td>\n",
       "      <td>55.114811</td>\n",
       "      <td>60.878271</td>\n",
       "      <td>38.617246</td>\n",
       "      <td>50.679885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>21752</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>59.844808</td>\n",
       "      <td>72.303110</td>\n",
       "      <td>55.458281</td>\n",
       "      <td>46.870235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>21754</td>\n",
       "      <td>68.820928</td>\n",
       "      <td>56.594193</td>\n",
       "      <td>34.605868</td>\n",
       "      <td>49.922535</td>\n",
       "      <td>50.383078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2\n",
       "0     10001  57.436077     30.571975     62.553736     53.325130     51.427998\n",
       "1     10002  59.580851     50.969456     67.470628     60.651856     58.311361\n",
       "2     10004  71.413018     53.152498     58.012103     52.418389     62.536641\n",
       "3     10005  66.532630           NaN           NaN     52.108977     69.993075\n",
       "4     10007  38.617381     49.197021     65.674285     40.151376     34.096421\n",
       "...     ...        ...           ...           ...           ...           ...\n",
       "5872  21746  14.257265     21.358872     61.165998     51.778483     54.640179\n",
       "5873  21747  55.456978     68.169675     29.907995     55.349257     54.019517\n",
       "5874  21750  48.948756     55.114811     60.878271     38.617246     50.679885\n",
       "5875  21752  66.532630     59.844808     72.303110     55.458281     46.870235\n",
       "5876  21754  68.820928     56.594193     34.605868     49.922535     50.383078\n",
       "\n",
       "[5877 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('00_Data/train_scores.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                0\n",
       "age               0\n",
       "domain1_var1    438\n",
       "domain1_var2    438\n",
       "domain2_var1     39\n",
       "domain2_var2     39\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls = data.isnull().sum()\n",
    "# l = len(data.index)\n",
    "\n",
    "# nulls['domain1_var1'] / l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length:  5434\n"
     ]
    }
   ],
   "source": [
    "print('Dataset length: ', len(data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_inputs_fnc(idx, labels):\n",
    "#     df = pd.read_csv('00_Data/fnc_csv/{0}.csv'.format(idx), index_col=0)\n",
    "#     X = np.array(df.values).reshape(-1)\n",
    "#     return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_inputs_loading(idx, labels):\n",
    "#     df = pd.read_csv('00_Data/loading_csv/{0}.csv'.format(idx), index_col=0)\n",
    "#     X = np.array(df.values).reshape(-1)\n",
    "#     return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(idx, labels):\n",
    "    df_fnc = pd.read_csv('00_Data/fnc_csv/{0}.csv'.format(idx), index_col=0)\n",
    "    X_fnc = np.array(df_fnc.values).reshape(-1)\n",
    "    \n",
    "    df_loading = pd.read_csv('00_Data/loading_csv/{0}.csv'.format(idx), index_col=0)\n",
    "    X_loading = np.array(df_loading.values).reshape(-1)\n",
    "#     print(X_fnc[0])\n",
    "#     print(X_loading[0])\n",
    "#     print(labels[0])\n",
    "#     print(X_fnc.shape)\n",
    "#     print(X_loading.shape)\n",
    "#     print(labels.shape)\n",
    "\n",
    "#     X_fnc = tf.convert_to_tensor(X_fnc, dtype=tf.float64)\n",
    "#     X_loading = tf.convert_to_tensor(X_loading, dtype=tf.float64)\n",
    "#     labels = tf.convert_to_tensor(labels, dtype=tf.float64)\n",
    "#     X = tf.tuple([X_fnc, X_loading])\n",
    "\n",
    "#     X = dict()\n",
    "#     X['input_1'] = X_fnc\n",
    "#     X['input_2'] = X_loading\n",
    "    X = (X_fnc, X_loading)\n",
    "    return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_decorator(func):\n",
    "    def wrapper(idx, labels):\n",
    "        # Use a tf.py_function to prevent auto-graph from compiling the method\n",
    "        return tf.py_function(func,\n",
    "                              inp=(idx, labels),\n",
    "                              Tout=tf.float64)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_py_function(func, inp, Tout, name=None):\n",
    "    \n",
    "    def wrapped_func(*flat_inp):\n",
    "        reconstructed_inp = tf.nest.pack_sequence_as(inp, flat_inp,\n",
    "                                                     expand_composites=True)\n",
    "        out = func(*reconstructed_inp)\n",
    "        return tf.nest.flatten(out, expand_composites=True)\n",
    "    \n",
    "    flat_Tout = tf.nest.flatten(Tout, expand_composites=True)\n",
    "    flat_out = tf.py_function(func=wrapped_func, \n",
    "                              inp=tf.nest.flatten(inp, expand_composites=True),\n",
    "                              Tout=[_tensor_spec_to_dtype(v) for v in flat_Tout],\n",
    "                              name=name)\n",
    "    spec_out = tf.nest.map_structure(_dtype_to_tensor_spec, Tout, expand_composites=True)\n",
    "    out = tf.nest.pack_sequence_as(spec_out, flat_out, expand_composites=True)\n",
    "    return out\n",
    "\n",
    "def _dtype_to_tensor_spec(v):\n",
    "    return tf.TensorSpec(None, v) if isinstance(v, tf.dtypes.DType) else v\n",
    "\n",
    "def _tensor_spec_to_dtype(v):\n",
    "    return v.dtype if isinstance(v, tf.TensorSpec) else v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dataset(data, batch_size):\n",
    "#     data = tf.data.Dataset.from_tensor_slices((data['Id'].values, \n",
    "#                                                data[['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']].values))\n",
    "#     data = data.shuffle(buffer_size=5500, seed=30, reshuffle_each_iteration=True)\n",
    "    \n",
    "#     data_fnc = data.map(map_decorator(get_inputs_fnc), \n",
    "#                      num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "#                      deterministic=True)\n",
    "#     data_loading = data.map(map_decorator(get_inputs_loading), \n",
    "#                      num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "#                      deterministic=True)\n",
    "\n",
    "#     data_fnc = data_fnc.batch(batch_size, drop_remainder=True)\n",
    "#     data_fnc = data_fnc.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "#     data_loading = data_loading.batch(batch_size, drop_remainder=True)\n",
    "#     data_loading = data_loading.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#     return (data_fnc, data_loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data, batch_size):\n",
    "    data = tf.data.Dataset.from_tensor_slices((data['Id'].values, \n",
    "                                               data[['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']].values))\n",
    "    data = data.shuffle(buffer_size=5500, seed=30, reshuffle_each_iteration=True)\n",
    "    \n",
    "    data = data.map(lambda idx, lbl:new_py_function(get_inputs, inp=(idx, lbl), Tout=((tf.float64, tf.float64), tf.float64), name=None), \n",
    "                     num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "                     deterministic=True)\n",
    "    data = data.batch(batch_size, drop_remainder=True)\n",
    "    data = data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = model_selection.train_test_split(data, test_size=0.2, shuffle=True, random_state=30)\n",
    "train, val = model_selection.train_test_split(train, test_size=0.2, shuffle=True, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 64\n",
    "\n",
    "# ds_train_fnc, ds_train_loading = get_dataset(train, batch_size)\n",
    "# ds_val_fnc, ds_val_loading = get_dataset(val, batch_size)\n",
    "# ds_test_fnc, ds_test_loading = get_dataset(test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "ds_train = get_dataset(train, batch_size)\n",
    "ds_val = get_dataset(val, batch_size)\n",
    "ds_test = get_dataset(test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.perf_counter()\n",
    "# for f in ds_train.take(1):\n",
    "#     pass\n",
    "# tf.print(\"Execution time:\", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE_fnc = (1378,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE_loading = (26,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_fnc = keras.layers.Input(shape=INPUT_SHAPE_fnc, name='inp_fnc')\n",
    "\n",
    "# x = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(inputs_fnc)\n",
    "x = keras.layers.Dense(2048,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(inputs_fnc)\n",
    "x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x)\n",
    "# x = keras.layers.Dropout(rate=0.2, seed=30)(x)\n",
    "\n",
    "x1 = keras.layers.Dense(512,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x1)\n",
    "# x1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(x1)\n",
    "\n",
    "x11 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x1)\n",
    "x11 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x11)\n",
    "x11 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x11)\n",
    "\n",
    "\n",
    "x12 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x1)\n",
    "x12 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x12)\n",
    "x12 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x12)\n",
    "\n",
    "x1 = keras.layers.concatenate([x11, x12])\n",
    "\n",
    "x1 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x1)\n",
    "x1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x1)\n",
    "x1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x1)\n",
    "\n",
    "x2 = keras.layers.Dense(512,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x2)\n",
    "# x2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(x2)\n",
    "\n",
    "x21 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x2)\n",
    "x21 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x21)\n",
    "x21 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x21)\n",
    "\n",
    "x22 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x2)\n",
    "x22 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x22)\n",
    "x22 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x22)\n",
    "\n",
    "x2 = keras.layers.concatenate([x21, x22])\n",
    "\n",
    "x2 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x2)\n",
    "x2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x2)\n",
    "x2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x2)\n",
    "\n",
    "x = keras.layers.concatenate([x1, x2])\n",
    "\n",
    "# x = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(x)\n",
    "\n",
    "x = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x)\n",
    "\n",
    "# output\n",
    "x = keras.Model(inputs=inputs_fnc, outputs=x, name='model_fnc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_loading = keras.layers.Input(shape=INPUT_SHAPE_loading, name='inp_load')\n",
    "\n",
    "# y = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(inputs_loading)\n",
    "\n",
    "y = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(inputs_loading)\n",
    "y = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y)\n",
    "# y = keras.layers.Dropout(rate=0.2, seed=30)(y)\n",
    "\n",
    "y1 = keras.layers.Dense(128,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y1)\n",
    "# y1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(y1)\n",
    "\n",
    "y11 = keras.layers.Dense(64,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y1)\n",
    "y11 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y11)\n",
    "y11 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y11)\n",
    "\n",
    "\n",
    "y12 = keras.layers.Dense(64,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y1)\n",
    "y12 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y12)\n",
    "y12 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y12)\n",
    "\n",
    "y1 = keras.layers.concatenate([y11, y12])\n",
    "\n",
    "y1 = keras.layers.Dense(128,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y1)\n",
    "y1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y1)\n",
    "y1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y1)\n",
    "\n",
    "y2 = keras.layers.Dense(128,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y2)\n",
    "# y2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(y2)\n",
    "\n",
    "y21 = keras.layers.Dense(64,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y2)\n",
    "y21 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y21)\n",
    "y21 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y21)\n",
    "\n",
    "y22 = keras.layers.Dense(64,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y2)\n",
    "y22 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y22)\n",
    "y22 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y22)\n",
    "\n",
    "y2 = keras.layers.concatenate([y21, y22])\n",
    "\n",
    "y2 = keras.layers.Dense(128,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y2)\n",
    "y2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y2)\n",
    "y2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y2)\n",
    "\n",
    "y = keras.layers.concatenate([y1, y2])\n",
    "\n",
    "# y = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(y)\n",
    "\n",
    "y = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y)\n",
    "# x = keras.layers.Dropout(rate=0.2, seed=30)(x)\n",
    "\n",
    "# output\n",
    "y = keras.Model(inputs=inputs_loading, outputs=y, name='model_loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = keras.layers.concatenate([x.output, y.output])\n",
    "\n",
    "z1 = keras.layers.Dense(512, \n",
    "                       kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                       bias_initializer=keras.initializers.Constant(5.))(concat)\n",
    "z1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(z1)\n",
    "z1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(z1)\n",
    "\n",
    "z2 = keras.layers.Dense(512, \n",
    "                       kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                       bias_initializer=keras.initializers.Constant(5.))(concat)\n",
    "z2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(z2)\n",
    "z2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(z2)\n",
    "\n",
    "z = keras.layers.concatenate([z1, z2])\n",
    "\n",
    "z = keras.layers.Dense(512, \n",
    "                       kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                       bias_initializer=keras.initializers.Constant(5.))(z)\n",
    "z = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(z)\n",
    "\n",
    "outputs = keras.layers.Dense(5, activation='linear')(z)\n",
    "\n",
    "model = keras.Model(inputs=[x.input, y.input], outputs=outputs, name='model_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_combined\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inp_fnc (InputLayer)            [(None, 1378)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inp_load (InputLayer)           [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         2824192     inp_fnc[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          6912        inp_load[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu (PReLU)                 (None, 2048)         2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_10 (PReLU)              (None, 256)          256         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     p_re_lu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          1049088     p_re_lu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 128)          32896       p_re_lu_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 128)          32896       p_re_lu_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 512)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_5 (PReLU)               (None, 512)          512         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_11 (PReLU)              (None, 128)          128         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_15 (PReLU)              (None, 128)          128         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          131328      p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          131328      p_re_lu_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          131328      p_re_lu_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           8256        p_re_lu_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           8256        p_re_lu_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 64)           8256        p_re_lu_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 64)           8256        p_re_lu_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 256)          256         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_3 (PReLU)               (None, 256)          256         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_6 (PReLU)               (None, 256)          256         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_7 (PReLU)               (None, 256)          256         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_12 (PReLU)              (None, 64)           64          dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_13 (PReLU)              (None, 64)           64          dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_16 (PReLU)              (None, 64)           64          dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_17 (PReLU)              (None, 64)           64          dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256)          1024        p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        p_re_lu_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        p_re_lu_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256)          1024        p_re_lu_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64)           256         p_re_lu_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64)           256         p_re_lu_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64)           256         p_re_lu_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64)           256         p_re_lu_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128)          0           batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128)          0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          131328      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          131328      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 128)          16512       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 128)          16512       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_4 (PReLU)               (None, 256)          256         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_8 (PReLU)               (None, 256)          256         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_14 (PReLU)              (None, 128)          128         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_18 (PReLU)              (None, 128)          128         dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256)          1024        p_re_lu_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128)          512         p_re_lu_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128)          512         p_re_lu_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 256)          0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          131328      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 256)          65792       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_9 (PReLU)               (None, 256)          256         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_19 (PReLU)              (None, 256)          256         dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 512)          0           p_re_lu_9[0][0]                  \n",
      "                                                                 p_re_lu_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 512)          262656      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 512)          262656      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_20 (PReLU)              (None, 512)          512         dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_21 (PReLU)              (None, 512)          512         dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 512)          2048        p_re_lu_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 512)          2048        p_re_lu_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1024)         0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 512)          524800      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_22 (PReLU)              (None, 512)          512         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 5)            2565        p_re_lu_22[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 7,118,853\n",
      "Trainable params: 7,112,709\n",
      "Non-trainable params: 6,144\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim = keras.optimizers.Adam(lr=0.000001,\n",
    "#                                  beta_1=0.99,\n",
    "#                                  beta_2=0.999,\n",
    "#                                  amsgrad=False)\n",
    "\n",
    "optim = tf.keras.optimizers.Adadelta(learning_rate=0.001, rho=0.95)\n",
    "        \n",
    "METRICS = [keras.metrics.RootMeanSquaredError(name='rmse'),\n",
    "           keras.metrics.MeanSquaredError(name='mse'),\n",
    "           keras.metrics.MeanAbsoluteError(name='mae')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mae(y_true, y_pred):\n",
    "    W = tf.constant([[0.3, 0.175, 0.175, 0.175, 0.175]])\n",
    "    return tf.math.reduce_mean(tf.linalg.matmul(tf.math.abs(y_pred - y_true), tf.transpose(W / tf.math.reduce_mean(y_true, axis=0))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=weighted_mae, metrics=METRICS, optimizer=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint directory to store the checkpoints\n",
    "# Name of the checkpoint files\n",
    "# checkpoint_prefix = os.path.join('./99_Training_checkpoints/fnc-loading', \"ckpt_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/fnc-loading'),\n",
    "#              tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "#                                                 save_weights_only=False),\n",
    "#              tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "#                                                   factor=0.7, \n",
    "#                                                   patience=2, \n",
    "#                                                   verbose=1, \n",
    "#                                                   mode='min',\n",
    "#                                                   min_delta=0.01, \n",
    "#                                                   cooldown=5, \n",
    "#                                                   min_lr=0.00000001),\n",
    "#              tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "#                                               min_delta=0.001, \n",
    "#                                               patience=10, \n",
    "#                                               verbose=1, \n",
    "#                                               mode='min',\n",
    "#                                               baseline=None, \n",
    "#                                               restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/fnc-loading'),\n",
    "#              tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "#                                                   factor=0.7, \n",
    "#                                                   patience=2, \n",
    "#                                                   verbose=1, \n",
    "#                                                   mode='min',\n",
    "#                                                   min_delta=0.01, \n",
    "#                                                   cooldown=5, \n",
    "#                                                   min_lr=0.00000001),\n",
    "#              tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "#                                               min_delta=0.001, \n",
    "#                                               patience=10, \n",
    "#                                               verbose=1, \n",
    "#                                               mode='min',\n",
    "#                                               baseline=None, \n",
    "#                                               restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/fnc-loading'),\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              min_delta=0.001, \n",
    "                                              patience=10, \n",
    "                                              verbose=1, \n",
    "                                              mode='min',\n",
    "                                              baseline=None, \n",
    "                                              restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "54/54 [==============================] - 15s 281ms/step - loss: 0.9358 - rmse: 53.4864 - mse: 2860.7922 - mae: 50.8586 - val_loss: 0.8657 - val_rmse: 50.6493 - val_mse: 2565.3560 - val_mae: 46.2054\n",
      "Epoch 2/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 0.9314 - rmse: 53.2767 - mse: 2838.4126 - mae: 50.6372 - val_loss: 0.8970 - val_rmse: 51.0633 - val_mse: 2607.4597 - val_mae: 47.3797\n",
      "Epoch 3/400\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 0.9270 - rmse: 53.0629 - mse: 2815.6697 - mae: 50.4143 - val_loss: 0.8994 - val_rmse: 50.6042 - val_mse: 2560.7825 - val_mae: 47.3336\n",
      "Epoch 4/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 0.9223 - rmse: 52.8243 - mse: 2790.4094 - mae: 50.1637 - val_loss: 0.8910 - val_rmse: 49.9539 - val_mse: 2495.3950 - val_mae: 46.8997\n",
      "Epoch 5/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 0.9174 - rmse: 52.5871 - mse: 2765.4077 - mae: 49.9146 - val_loss: 0.8810 - val_rmse: 49.2263 - val_mse: 2423.2244 - val_mae: 46.3494\n",
      "Epoch 6/400\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 0.9124 - rmse: 52.3343 - mse: 2738.8750 - mae: 49.6493 - val_loss: 0.8731 - val_rmse: 48.7342 - val_mse: 2375.0247 - val_mae: 45.9869\n",
      "Epoch 7/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 0.9071 - rmse: 52.0831 - mse: 2712.6516 - mae: 49.3841 - val_loss: 0.8668 - val_rmse: 48.4975 - val_mse: 2352.0115 - val_mae: 45.7579\n",
      "Epoch 8/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 0.9017 - rmse: 51.8174 - mse: 2685.0386 - mae: 49.1028 - val_loss: 0.8670 - val_rmse: 48.5896 - val_mse: 2360.9534 - val_mae: 45.9249\n",
      "Epoch 9/400\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 0.8961 - rmse: 51.5467 - mse: 2657.0576 - mae: 48.8215 - val_loss: 0.8670 - val_rmse: 48.7390 - val_mse: 2375.4905 - val_mae: 46.1053: 0.8997\n",
      "Epoch 10/400\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 0.8902 - rmse: 51.2574 - mse: 2627.3198 - mae: 48.5109 - val_loss: 0.8648 - val_rmse: 48.8547 - val_mse: 2386.7817 - val_mae: 46.1942\n",
      "Epoch 11/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 0.8844 - rmse: 50.9767 - mse: 2598.6208 - mae: 48.2182 - val_loss: 0.8646 - val_rmse: 49.0437 - val_mse: 2405.2834 - val_mae: 46.3637\n",
      "Epoch 12/400\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 0.8782 - rmse: 50.6806 - mse: 2568.5237 - mae: 47.9049 - val_loss: 0.8640 - val_rmse: 49.2239 - val_mse: 2422.9958 - val_mae: 46.5137\n",
      "Epoch 13/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 0.8721 - rmse: 50.3714 - mse: 2537.2771 - mae: 47.5798 - val_loss: 0.8615 - val_rmse: 49.3424 - val_mse: 2434.6755 - val_mae: 46.5891\n",
      "Epoch 14/400\n",
      "54/54 [==============================] - 15s 273ms/step - loss: 0.8657 - rmse: 50.0581 - mse: 2505.8103 - mae: 47.2524 - val_loss: 0.8584 - val_rmse: 49.2054 - val_mse: 2421.1709 - val_mae: 46.4296\n",
      "Epoch 15/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.8592 - rmse: 49.7400 - mse: 2474.0686 - mae: 46.9165 - val_loss: 0.8540 - val_rmse: 49.1574 - val_mse: 2416.4529 - val_mae: 46.3570\n",
      "Epoch 16/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.8526 - rmse: 49.4199 - mse: 2442.3264 - mae: 46.5798 - val_loss: 0.8493 - val_rmse: 48.9883 - val_mse: 2399.8528 - val_mae: 46.1657\n",
      "Epoch 17/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 0.8458 - rmse: 49.0943 - mse: 2410.2517 - mae: 46.2356 - val_loss: 0.8429 - val_rmse: 48.6970 - val_mse: 2371.3958 - val_mae: 45.8327\n",
      "Epoch 18/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.8389 - rmse: 48.7414 - mse: 2375.7288 - mae: 45.8658 - val_loss: 0.8363 - val_rmse: 48.3386 - val_mse: 2336.6240 - val_mae: 45.4468\n",
      "Epoch 19/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.8319 - rmse: 48.4109 - mse: 2343.6135 - mae: 45.5177 - val_loss: 0.8300 - val_rmse: 48.0759 - val_mse: 2311.2932 - val_mae: 45.1673\n",
      "Epoch 20/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.8246 - rmse: 48.0477 - mse: 2308.5837 - mae: 45.1300 - val_loss: 0.8236 - val_rmse: 47.7803 - val_mse: 2282.9592 - val_mae: 44.8544\n",
      "Epoch 21/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.8173 - rmse: 47.7085 - mse: 2276.0972 - mae: 44.7718 - val_loss: 0.8160 - val_rmse: 47.4202 - val_mse: 2248.6799 - val_mae: 44.4709\n",
      "Epoch 22/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.8101 - rmse: 47.3424 - mse: 2241.3013 - mae: 44.3852 - val_loss: 0.8094 - val_rmse: 47.1110 - val_mse: 2219.4458 - val_mae: 44.1553\n",
      "Epoch 23/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.8026 - rmse: 46.9774 - mse: 2206.8760 - mae: 43.9979 - val_loss: 0.8013 - val_rmse: 46.6795 - val_mse: 2178.9729 - val_mae: 43.6906\n",
      "Epoch 24/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.7948 - rmse: 46.5911 - mse: 2170.7322 - mae: 43.5889 - val_loss: 0.7934 - val_rmse: 46.2221 - val_mse: 2136.4839 - val_mae: 43.2169\n",
      "Epoch 25/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.7872 - rmse: 46.2246 - mse: 2136.7146 - mae: 43.2017 - val_loss: 0.7862 - val_rmse: 45.9560 - val_mse: 2111.9509 - val_mae: 42.9255\n",
      "Epoch 26/400\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 0.7794 - rmse: 45.8420 - mse: 2101.4915 - mae: 42.7925 - val_loss: 0.7786 - val_rmse: 45.5315 - val_mse: 2073.1189 - val_mae: 42.4976\n",
      "Epoch 27/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.7715 - rmse: 45.4655 - mse: 2067.1079 - mae: 42.3983 - val_loss: 0.7710 - val_rmse: 45.1370 - val_mse: 2037.3503 - val_mae: 42.0740\n",
      "Epoch 28/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.7636 - rmse: 45.0677 - mse: 2031.1007 - mae: 41.9808 - val_loss: 0.7630 - val_rmse: 44.8058 - val_mse: 2007.5580 - val_mae: 41.7261\n",
      "Epoch 29/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.7555 - rmse: 44.6730 - mse: 1995.6764 - mae: 41.5651 - val_loss: 0.7549 - val_rmse: 44.3833 - val_mse: 1969.8735 - val_mae: 41.2843\n",
      "Epoch 30/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.7472 - rmse: 44.2807 - mse: 1960.7805 - mae: 41.1401 - val_loss: 0.7465 - val_rmse: 43.9917 - val_mse: 1935.2687 - val_mae: 40.8493\n",
      "Epoch 31/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.7390 - rmse: 43.8701 - mse: 1924.5857 - mae: 40.7089 - val_loss: 0.7386 - val_rmse: 43.5691 - val_mse: 1898.2703 - val_mae: 40.4304\n",
      "Epoch 32/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 0.7307 - rmse: 43.4649 - mse: 1889.1954 - mae: 40.2795 - val_loss: 0.7308 - val_rmse: 43.1740 - val_mse: 1863.9949 - val_mae: 40.0079\n",
      "Epoch 33/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 0.7222 - rmse: 43.0313 - mse: 1851.6947 - mae: 39.8206 - val_loss: 0.7228 - val_rmse: 42.8331 - val_mse: 1834.6731 - val_mae: 39.65230 - rmse: 43.1349 \n",
      "Epoch 34/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.7138 - rmse: 42.6268 - mse: 1817.0435 - mae: 39.3936 - val_loss: 0.7150 - val_rmse: 42.3462 - val_mse: 1793.1970 - val_mae: 39.1652\n",
      "Epoch 35/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.7054 - rmse: 42.2022 - mse: 1781.0229 - mae: 38.9539 - val_loss: 0.7072 - val_rmse: 41.9672 - val_mse: 1761.2469 - val_mae: 38.7668\n",
      "Epoch 36/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 0.6967 - rmse: 41.7709 - mse: 1744.8119 - mae: 38.4890 - val_loss: 0.6980 - val_rmse: 41.4856 - val_mse: 1721.0585 - val_mae: 38.2348\n",
      "Epoch 37/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.6880 - rmse: 41.3466 - mse: 1709.5415 - mae: 38.0416 - val_loss: 0.6919 - val_rmse: 41.2173 - val_mse: 1698.8696 - val_mae: 38.0114\n",
      "Epoch 38/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.6795 - rmse: 40.9164 - mse: 1674.1537 - mae: 37.5900 - val_loss: 0.6818 - val_rmse: 40.6797 - val_mse: 1654.8342 - val_mae: 37.4137\n",
      "Epoch 39/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.6706 - rmse: 40.4769 - mse: 1638.3796 - mae: 37.1217 - val_loss: 0.6739 - val_rmse: 40.2957 - val_mse: 1623.7416 - val_mae: 37.0121\n",
      "Epoch 40/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.6618 - rmse: 40.0466 - mse: 1603.7275 - mae: 36.6685 - val_loss: 0.6658 - val_rmse: 39.8598 - val_mse: 1588.8071 - val_mae: 36.5850\n",
      "Epoch 41/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.6528 - rmse: 39.5873 - mse: 1567.1560 - mae: 36.1854 - val_loss: 0.6570 - val_rmse: 39.4348 - val_mse: 1555.1038 - val_mae: 36.1117\n",
      "Epoch 42/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.6442 - rmse: 39.1591 - mse: 1533.4315 - mae: 35.7360 - val_loss: 0.6484 - val_rmse: 38.9293 - val_mse: 1515.4939 - val_mae: 35.6121\n",
      "Epoch 43/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.6354 - rmse: 38.7095 - mse: 1498.4290 - mae: 35.2674 - val_loss: 0.6389 - val_rmse: 38.4634 - val_mse: 1479.4368 - val_mae: 35.1015\n",
      "Epoch 44/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.6264 - rmse: 38.2633 - mse: 1464.0819 - mae: 34.7955 - val_loss: 0.6299 - val_rmse: 38.0531 - val_mse: 1448.0352 - val_mae: 34.6583\n",
      "Epoch 45/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.6173 - rmse: 37.8042 - mse: 1429.1570 - mae: 34.3108 - val_loss: 0.6221 - val_rmse: 37.6120 - val_mse: 1414.6655 - val_mae: 34.2118\n",
      "Epoch 46/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 0.6085 - rmse: 37.3504 - mse: 1395.0505 - mae: 33.8374 - val_loss: 0.6135 - val_rmse: 37.1805 - val_mse: 1382.3911 - val_mae: 33.7696\n",
      "Epoch 47/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.5992 - rmse: 36.8884 - mse: 1360.7518 - mae: 33.3465 - val_loss: 0.6050 - val_rmse: 36.6844 - val_mse: 1345.7444 - val_mae: 33.2623\n",
      "Epoch 48/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.5904 - rmse: 36.4277 - mse: 1326.9758 - mae: 32.8743 - val_loss: 0.5964 - val_rmse: 36.2523 - val_mse: 1314.2323 - val_mae: 32.8279\n",
      "Epoch 49/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.5816 - rmse: 35.9872 - mse: 1295.0813 - mae: 32.4106 - val_loss: 0.5880 - val_rmse: 35.8334 - val_mse: 1284.0343 - val_mae: 32.3859\n",
      "Epoch 50/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.5725 - rmse: 35.5130 - mse: 1261.1702 - mae: 31.9174 - val_loss: 0.5791 - val_rmse: 35.3686 - val_mse: 1250.9375 - val_mae: 31.8869\n",
      "Epoch 51/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.5635 - rmse: 35.0523 - mse: 1228.6611 - mae: 31.4349 - val_loss: 0.5710 - val_rmse: 34.9496 - val_mse: 1221.4722 - val_mae: 31.4712\n",
      "Epoch 52/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.5546 - rmse: 34.5777 - mse: 1195.6146 - mae: 30.9442 - val_loss: 0.5624 - val_rmse: 34.4528 - val_mse: 1186.9922 - val_mae: 30.9669\n",
      "Epoch 53/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.5458 - rmse: 34.1153 - mse: 1163.8511 - mae: 30.4642 - val_loss: 0.5540 - val_rmse: 34.0139 - val_mse: 1156.9462 - val_mae: 30.5212\n",
      "Epoch 54/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.5368 - rmse: 33.6486 - mse: 1132.2252 - mae: 29.9853 - val_loss: 0.5455 - val_rmse: 33.5609 - val_mse: 1126.3358 - val_mae: 30.03383.7685 - mse:  - ETA: 0s - loss: 0.5372 - rmse: 33.6889 - mse: 1134.9447 - mae: 30.0\n",
      "Epoch 55/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 0.5279 - rmse: 33.1791 - mse: 1100.8551 - mae: 29.4963 - val_loss: 0.5362 - val_rmse: 33.0546 - val_mse: 1092.6040 - val_mae: 29.5101\n",
      "Epoch 56/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.5188 - rmse: 32.7012 - mse: 1069.3673 - mae: 29.0007 - val_loss: 0.5290 - val_rmse: 32.7221 - val_mse: 1070.7336 - val_mae: 29.1769\n",
      "Epoch 57/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.5101 - rmse: 32.2336 - mse: 1039.0020 - mae: 28.5279 - val_loss: 0.5189 - val_rmse: 32.1491 - val_mse: 1033.5667 - val_mae: 28.5659\n",
      "Epoch 58/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.5014 - rmse: 31.7678 - mse: 1009.1962 - mae: 28.0430 - val_loss: 0.5103 - val_rmse: 31.6826 - val_mse: 1003.7883 - val_mae: 28.1083\n",
      "Epoch 59/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 0.4925 - rmse: 31.2851 - mse: 978.7547 - mae: 27.5532 - val_loss: 0.5023 - val_rmse: 31.2763 - val_mse: 978.2045 - val_mae: 27.6884\n",
      "Epoch 60/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.4840 - rmse: 30.8214 - mse: 949.9561 - mae: 27.0877 - val_loss: 0.4936 - val_rmse: 30.7890 - val_mse: 947.9656 - val_mae: 27.1899\n",
      "Epoch 61/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.4754 - rmse: 30.3577 - mse: 921.5925 - mae: 26.6118 - val_loss: 0.4860 - val_rmse: 30.3245 - val_mse: 919.5775 - val_mae: 26.7613\n",
      "Epoch 62/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.4667 - rmse: 29.8732 - mse: 892.4078 - mae: 26.1227 - val_loss: 0.4771 - val_rmse: 29.8553 - val_mse: 891.3403 - val_mae: 26.2643\n",
      "Epoch 63/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.4582 - rmse: 29.4096 - mse: 864.9266 - mae: 25.6537 - val_loss: 0.4693 - val_rmse: 29.4288 - val_mse: 866.0544 - val_mae: 25.8278\n",
      "Epoch 64/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.4499 - rmse: 28.9501 - mse: 838.1065 - mae: 25.1917 - val_loss: 0.4601 - val_rmse: 28.9363 - val_mse: 837.3077 - val_mae: 25.3187\n",
      "Epoch 65/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.4413 - rmse: 28.4707 - mse: 810.5788 - mae: 24.7095 - val_loss: 0.4527 - val_rmse: 28.4700 - val_mse: 810.5397 - val_mae: 24.8706\n",
      "Epoch 66/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.4332 - rmse: 28.0137 - mse: 784.7655 - mae: 24.2532 - val_loss: 0.4448 - val_rmse: 28.0757 - val_mse: 788.2443 - val_mae: 24.4543\n",
      "Epoch 67/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.4252 - rmse: 27.5611 - mse: 759.6117 - mae: 23.8064 - val_loss: 0.4361 - val_rmse: 27.5821 - val_mse: 760.7725 - val_mae: 23.9648\n",
      "Epoch 68/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.4170 - rmse: 27.0782 - mse: 733.2263 - mae: 23.3314 - val_loss: 0.4283 - val_rmse: 27.1567 - val_mse: 737.4871 - val_mae: 23.5330\n",
      "Epoch 69/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.4088 - rmse: 26.6069 - mse: 707.9263 - mae: 22.8578 - val_loss: 0.4206 - val_rmse: 26.7122 - val_mse: 713.5401 - val_mae: 23.0795\n",
      "Epoch 70/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.4008 - rmse: 26.1490 - mse: 683.7715 - mae: 22.4082 - val_loss: 0.4129 - val_rmse: 26.3389 - val_mse: 693.7383 - val_mae: 22.7026\n",
      "Epoch 71/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.3930 - rmse: 25.7007 - mse: 660.5277 - mae: 21.9662 - val_loss: 0.4052 - val_rmse: 25.8319 - val_mse: 667.2896 - val_mae: 22.2196\n",
      "Epoch 72/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.3853 - rmse: 25.2474 - mse: 637.4318 - mae: 21.5245 - val_loss: 0.3985 - val_rmse: 25.4325 - val_mse: 646.8138 - val_mae: 21.8448\n",
      "Epoch 73/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.3777 - rmse: 24.8012 - mse: 615.1000 - mae: 21.0936 - val_loss: 0.3924 - val_rmse: 25.0916 - val_mse: 629.5908 - val_mae: 21.4986\n",
      "Epoch 74/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.3701 - rmse: 24.3478 - mse: 592.8166 - mae: 20.6476 - val_loss: 0.3814 - val_rmse: 24.4456 - val_mse: 597.5876 - val_mae: 20.8695\n",
      "Epoch 75/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.3627 - rmse: 23.9165 - mse: 572.0009 - mae: 20.2302 - val_loss: 0.3737 - val_rmse: 24.0345 - val_mse: 577.6588 - val_mae: 20.4435\n",
      "Epoch 76/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.3551 - rmse: 23.4649 - mse: 550.6036 - mae: 19.7932 - val_loss: 0.3675 - val_rmse: 23.6928 - val_mse: 561.3508 - val_mae: 20.1127\n",
      "Epoch 77/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.3481 - rmse: 23.0311 - mse: 530.4324 - mae: 19.3795 - val_loss: 0.3619 - val_rmse: 23.3554 - val_mse: 545.4747 - val_mae: 19.7679\n",
      "Epoch 78/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 0.3411 - rmse: 22.5995 - mse: 510.7383 - mae: 18.9698 - val_loss: 0.3525 - val_rmse: 22.8072 - val_mse: 520.1678 - val_mae: 19.2333\n",
      "Epoch 79/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.3343 - rmse: 22.1838 - mse: 492.1221 - mae: 18.5782 - val_loss: 0.3450 - val_rmse: 22.3515 - val_mse: 499.5897 - val_mae: 18.8155\n",
      "Epoch 80/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.3276 - rmse: 21.7591 - mse: 473.4563 - mae: 18.1793 - val_loss: 0.3367 - val_rmse: 21.8444 - val_mse: 477.1785 - val_mae: 18.3399\n",
      "Epoch 81/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.3209 - rmse: 21.3447 - mse: 455.5980 - mae: 17.7947 - val_loss: 0.3307 - val_rmse: 21.5028 - val_mse: 462.3686 - val_mae: 17.9960\n",
      "Epoch 82/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 0.3145 - rmse: 20.9349 - mse: 438.2705 - mae: 17.4105 - val_loss: 0.3263 - val_rmse: 21.1915 - val_mse: 449.0784 - val_mae: 17.7103\n",
      "Epoch 83/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.3082 - rmse: 20.5400 - mse: 421.8916 - mae: 17.0451 - val_loss: 0.3178 - val_rmse: 20.6291 - val_mse: 425.5584 - val_mae: 17.2017\n",
      "Epoch 84/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.3022 - rmse: 20.1421 - mse: 405.7036 - mae: 16.6818 - val_loss: 0.3131 - val_rmse: 20.4033 - val_mse: 416.2926 - val_mae: 16.9796\n",
      "Epoch 85/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.2962 - rmse: 19.7547 - mse: 390.2473 - mae: 16.3250 - val_loss: 0.3067 - val_rmse: 19.9622 - val_mse: 398.4914 - val_mae: 16.5944\n",
      "Epoch 86/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.2905 - rmse: 19.3791 - mse: 375.5481 - mae: 15.9839 - val_loss: 0.3006 - val_rmse: 19.6011 - val_mse: 384.2041 - val_mae: 16.2426\n",
      "Epoch 87/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.2847 - rmse: 18.9970 - mse: 360.8857 - mae: 15.6385 - val_loss: 0.2954 - val_rmse: 19.2284 - val_mse: 369.7327 - val_mae: 15.9118\n",
      "Epoch 88/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.2793 - rmse: 18.6433 - mse: 347.5711 - mae: 15.3237 - val_loss: 0.2894 - val_rmse: 18.8559 - val_mse: 355.5441 - val_mae: 15.5945\n",
      "Epoch 89/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.2739 - rmse: 18.2839 - mse: 334.3018 - mae: 14.9986 - val_loss: 0.2837 - val_rmse: 18.5133 - val_mse: 342.7438 - val_mae: 15.2706\n",
      "Epoch 90/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.2687 - rmse: 17.9329 - mse: 321.5887 - mae: 14.6875 - val_loss: 0.2785 - val_rmse: 18.1939 - val_mse: 331.0189 - val_mae: 14.9497\n",
      "Epoch 91/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.2636 - rmse: 17.5889 - mse: 309.3702 - mae: 14.3811 - val_loss: 0.2734 - val_rmse: 17.8367 - val_mse: 318.1470 - val_mae: 14.6493\n",
      "Epoch 92/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.2589 - rmse: 17.2625 - mse: 297.9952 - mae: 14.0904 - val_loss: 0.2691 - val_rmse: 17.5802 - val_mse: 309.0626 - val_mae: 14.4318\n",
      "Epoch 93/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.2542 - rmse: 16.9398 - mse: 286.9576 - mae: 13.8099 - val_loss: 0.2635 - val_rmse: 17.2079 - val_mse: 296.1120 - val_mae: 14.0955\n",
      "Epoch 94/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.2495 - rmse: 16.6134 - mse: 276.0061 - mae: 13.5302 - val_loss: 0.2595 - val_rmse: 16.9043 - val_mse: 285.7566 - val_mae: 13.8333\n",
      "Epoch 95/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.2454 - rmse: 16.3243 - mse: 266.4838 - mae: 13.2724 - val_loss: 0.2541 - val_rmse: 16.5375 - val_mse: 273.4898 - val_mae: 13.5140\n",
      "Epoch 96/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.2411 - rmse: 16.0200 - mse: 256.6394 - mae: 13.0126 - val_loss: 0.2514 - val_rmse: 16.3353 - val_mse: 266.8419 - val_mae: 13.3430\n",
      "Epoch 97/400\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 0.2369 - rmse: 15.7324 - mse: 247.5094 - mae: 12.7644 - val_loss: 0.2471 - val_rmse: 16.0165 - val_mse: 256.5289 - val_mae: 13.0860\n",
      "Epoch 98/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.2332 - rmse: 15.4673 - mse: 239.2379 - mae: 12.5399 - val_loss: 0.2436 - val_rmse: 15.8075 - val_mse: 249.8757 - val_mae: 12.8883\n",
      "Epoch 99/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.2297 - rmse: 15.2063 - mse: 231.2305 - mae: 12.3200 - val_loss: 0.2399 - val_rmse: 15.5299 - val_mse: 241.1792 - val_mae: 12.6625\n",
      "Epoch 100/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.2260 - rmse: 14.9482 - mse: 223.4480 - mae: 12.0971 - val_loss: 0.2354 - val_rmse: 15.2294 - val_mse: 231.9353 - val_mae: 12.3998\n",
      "Epoch 101/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 0.2228 - rmse: 14.7134 - mse: 216.4853 - mae: 11.9026 - val_loss: 0.2321 - val_rmse: 14.9947 - val_mse: 224.8419 - val_mae: 12.1898\n",
      "Epoch 102/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.2197 - rmse: 14.4805 - mse: 209.6851 - mae: 11.7042 - val_loss: 0.2295 - val_rmse: 14.7877 - val_mse: 218.6772 - val_mae: 12.0370\n",
      "Epoch 103/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.2170 - rmse: 14.2769 - mse: 203.8308 - mae: 11.5379 - val_loss: 0.2265 - val_rmse: 14.5603 - val_mse: 212.0032 - val_mae: 11.8436\n",
      "Epoch 104/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.2141 - rmse: 14.0617 - mse: 197.7312 - mae: 11.3567 - val_loss: 0.2238 - val_rmse: 14.3658 - val_mse: 206.3755 - val_mae: 11.6839\n",
      "Epoch 105/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 0.2112 - rmse: 13.8533 - mse: 191.9138 - mae: 11.1807 - val_loss: 0.2213 - val_rmse: 14.1998 - val_mse: 201.6347 - val_mae: 11.5558\n",
      "Epoch 106/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.2086 - rmse: 13.6690 - mse: 186.8427 - mae: 11.0220 - val_loss: 0.2180 - val_rmse: 13.9601 - val_mse: 194.8853 - val_mae: 11.3324\n",
      "Epoch 107/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.2062 - rmse: 13.4830 - mse: 181.7912 - mae: 10.8679 - val_loss: 0.2159 - val_rmse: 13.8023 - val_mse: 190.5034 - val_mae: 11.2115\n",
      "Epoch 108/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.2040 - rmse: 13.3092 - mse: 177.1355 - mae: 10.7310 - val_loss: 0.2137 - val_rmse: 13.6048 - val_mse: 185.0909 - val_mae: 11.0485\n",
      "Epoch 109/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.2019 - rmse: 13.1632 - mse: 173.2706 - mae: 10.6031 - val_loss: 0.2115 - val_rmse: 13.5087 - val_mse: 182.4848 - val_mae: 10.9427\n",
      "Epoch 110/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1995 - rmse: 13.0019 - mse: 169.0502 - mae: 10.4654 - val_loss: 0.2097 - val_rmse: 13.4044 - val_mse: 179.6773 - val_mae: 10.8751\n",
      "Epoch 111/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.1977 - rmse: 12.8648 - mse: 165.5027 - mae: 10.3461 - val_loss: 0.2080 - val_rmse: 13.2613 - val_mse: 175.8615 - val_mae: 10.7512\n",
      "Epoch 112/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1959 - rmse: 12.7256 - mse: 161.9404 - mae: 10.2342 - val_loss: 0.2048 - val_rmse: 13.0261 - val_mse: 169.6803 - val_mae: 10.5345\n",
      "Epoch 113/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1943 - rmse: 12.6101 - mse: 159.0141 - mae: 10.1369 - val_loss: 0.2040 - val_rmse: 12.9442 - val_mse: 167.5530 - val_mae: 10.4843\n",
      "Epoch 114/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 0.1927 - rmse: 12.4955 - mse: 156.1369 - mae: 10.0344 - val_loss: 0.2018 - val_rmse: 12.8477 - val_mse: 165.0633 - val_mae: 10.3803\n",
      "Epoch 115/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.1911 - rmse: 12.3864 - mse: 153.4233 - mae: 9.9402 - val_loss: 0.2002 - val_rmse: 12.7205 - val_mse: 161.8107 - val_mae: 10.2804\n",
      "Epoch 116/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.1898 - rmse: 12.2868 - mse: 150.9659 - mae: 9.8560 - val_loss: 0.1990 - val_rmse: 12.6439 - val_mse: 159.8690 - val_mae: 10.1979\n",
      "Epoch 117/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1886 - rmse: 12.1942 - mse: 148.6978 - mae: 9.7758 - val_loss: 0.1977 - val_rmse: 12.5593 - val_mse: 157.7354 - val_mae: 10.1304\n",
      "Epoch 118/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.1874 - rmse: 12.1184 - mse: 146.8549 - mae: 9.7084 - val_loss: 0.1971 - val_rmse: 12.5012 - val_mse: 156.2801 - val_mae: 10.0665\n",
      "Epoch 119/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.1864 - rmse: 12.0380 - mse: 144.9144 - mae: 9.6416 - val_loss: 0.1958 - val_rmse: 12.4196 - val_mse: 154.2458 - val_mae: 9.9870\n",
      "Epoch 120/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.1852 - rmse: 11.9602 - mse: 143.0475 - mae: 9.5718 - val_loss: 0.1932 - val_rmse: 12.2574 - val_mse: 150.2445 - val_mae: 9.8569\n",
      "Epoch 121/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.1843 - rmse: 11.8976 - mse: 141.5518 - mae: 9.5167 - val_loss: 0.1934 - val_rmse: 12.2550 - val_mse: 150.1840 - val_mae: 9.8496\n",
      "Epoch 122/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 0.1835 - rmse: 11.8316 - mse: 139.9875 - mae: 9.4626 - val_loss: 0.1919 - val_rmse: 12.1540 - val_mse: 147.7188 - val_mae: 9.7623\n",
      "Epoch 123/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1826 - rmse: 11.7906 - mse: 139.0175 - mae: 9.4197 - val_loss: 0.1905 - val_rmse: 12.0984 - val_mse: 146.3709 - val_mae: 9.6948\n",
      "Epoch 124/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 0.1819 - rmse: 11.7353 - mse: 137.7172 - mae: 9.3714 - val_loss: 0.1902 - val_rmse: 12.0506 - val_mse: 145.2176 - val_mae: 9.6654\n",
      "Epoch 125/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.1813 - rmse: 11.6889 - mse: 136.6310 - mae: 9.3323 - val_loss: 0.1887 - val_rmse: 11.9860 - val_mse: 143.6648 - val_mae: 9.6032\n",
      "Epoch 126/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1806 - rmse: 11.6446 - mse: 135.5975 - mae: 9.2919 - val_loss: 0.1880 - val_rmse: 11.9171 - val_mse: 142.0184 - val_mae: 9.5447\n",
      "Epoch 127/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1798 - rmse: 11.6010 - mse: 134.5829 - mae: 9.2548 - val_loss: 0.1884 - val_rmse: 11.9360 - val_mse: 142.4690 - val_mae: 9.5706\n",
      "Epoch 128/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 0.1794 - rmse: 11.5729 - mse: 133.9310 - mae: 9.2241 - val_loss: 0.1870 - val_rmse: 11.8734 - val_mse: 140.9772 - val_mae: 9.5027\n",
      "Epoch 129/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.1791 - rmse: 11.5542 - mse: 133.4990 - mae: 9.2041 - val_loss: 0.1868 - val_rmse: 11.8459 - val_mse: 140.3255 - val_mae: 9.4620\n",
      "Epoch 130/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1783 - rmse: 11.5116 - mse: 132.5163 - mae: 9.1669 - val_loss: 0.1866 - val_rmse: 11.8464 - val_mse: 140.3383 - val_mae: 9.4541\n",
      "Epoch 131/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.1782 - rmse: 11.4956 - mse: 132.1478 - mae: 9.1494 - val_loss: 0.1863 - val_rmse: 11.8204 - val_mse: 139.7213 - val_mae: 9.4341\n",
      "Epoch 132/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 0.1774 - rmse: 11.4548 - mse: 131.2124 - mae: 9.1140 - val_loss: 0.1847 - val_rmse: 11.7376 - val_mse: 137.7721 - val_mae: 9.3613\n",
      "Epoch 133/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1772 - rmse: 11.4406 - mse: 130.8874 - mae: 9.0989 - val_loss: 0.1848 - val_rmse: 11.7388 - val_mse: 137.7989 - val_mae: 9.3603\n",
      "Epoch 134/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.1773 - rmse: 11.4339 - mse: 130.7349 - mae: 9.0961 - val_loss: 0.1843 - val_rmse: 11.7312 - val_mse: 137.6218 - val_mae: 9.3432\n",
      "Epoch 135/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.1766 - rmse: 11.4063 - mse: 130.1047 - mae: 9.0665 - val_loss: 0.1846 - val_rmse: 11.7386 - val_mse: 137.7959 - val_mae: 9.3507\n",
      "Epoch 136/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1767 - rmse: 11.3984 - mse: 129.9230 - mae: 9.0609 - val_loss: 0.1834 - val_rmse: 11.6652 - val_mse: 136.0769 - val_mae: 9.2877\n",
      "Epoch 137/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.1760 - rmse: 11.3759 - mse: 129.4100 - mae: 9.0321 - val_loss: 0.1836 - val_rmse: 11.6900 - val_mse: 136.6556 - val_mae: 9.3031\n",
      "Epoch 138/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1758 - rmse: 11.3675 - mse: 129.2203 - mae: 9.0258 - val_loss: 0.1840 - val_rmse: 11.6824 - val_mse: 136.4785 - val_mae: 9.3015\n",
      "Epoch 139/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1754 - rmse: 11.3472 - mse: 128.7586 - mae: 9.0029 - val_loss: 0.1849 - val_rmse: 11.7073 - val_mse: 137.0607 - val_mae: 9.3092\n",
      "Epoch 140/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1751 - rmse: 11.3308 - mse: 128.3862 - mae: 8.9888 - val_loss: 0.1825 - val_rmse: 11.6224 - val_mse: 135.0811 - val_mae: 9.2441\n",
      "Epoch 141/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 0.1752 - rmse: 11.3279 - mse: 128.3205 - mae: 8.9879 - val_loss: 0.1814 - val_rmse: 11.5791 - val_mse: 134.0753 - val_mae: 9.2199\n",
      "Epoch 142/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.1749 - rmse: 11.3179 - mse: 128.0939 - mae: 8.9728 - val_loss: 0.1822 - val_rmse: 11.6004 - val_mse: 134.5703 - val_mae: 9.2235\n",
      "Epoch 143/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1747 - rmse: 11.3045 - mse: 127.7926 - mae: 8.9646 - val_loss: 0.1817 - val_rmse: 11.5557 - val_mse: 133.5352 - val_mae: 9.1967\n",
      "Epoch 144/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.1743 - rmse: 11.2878 - mse: 127.4138 - mae: 8.9477 - val_loss: 0.1808 - val_rmse: 11.5574 - val_mse: 133.5727 - val_mae: 9.1792\n",
      "Epoch 145/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.1745 - rmse: 11.2980 - mse: 127.6440 - mae: 8.9531 - val_loss: 0.1803 - val_rmse: 11.5139 - val_mse: 132.5698 - val_mae: 9.1421\n",
      "Epoch 146/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.1741 - rmse: 11.2840 - mse: 127.3281 - mae: 8.9373 - val_loss: 0.1809 - val_rmse: 11.5383 - val_mse: 133.1325 - val_mae: 9.1630\n",
      "Epoch 147/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.1739 - rmse: 11.2719 - mse: 127.0549 - mae: 8.9282 - val_loss: 0.1813 - val_rmse: 11.5567 - val_mse: 133.5578 - val_mae: 9.1742\n",
      "Epoch 148/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.1735 - rmse: 11.2528 - mse: 126.6264 - mae: 8.9111 - val_loss: 0.1811 - val_rmse: 11.5426 - val_mse: 133.2319 - val_mae: 9.1708\n",
      "Epoch 149/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1736 - rmse: 11.2609 - mse: 126.8086 - mae: 8.9142 - val_loss: 0.1817 - val_rmse: 11.5738 - val_mse: 133.9523 - val_mae: 9.1900\n",
      "Epoch 150/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.1734 - rmse: 11.2465 - mse: 126.4837 - mae: 8.9016 - val_loss: 0.1815 - val_rmse: 11.5698 - val_mse: 133.8596 - val_mae: 9.2011\n",
      "Epoch 151/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.1732 - rmse: 11.2346 - mse: 126.2168 - mae: 8.8936 - val_loss: 0.1802 - val_rmse: 11.5012 - val_mse: 132.2778 - val_mae: 9.1205\n",
      "Epoch 152/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.1731 - rmse: 11.2334 - mse: 126.1892 - mae: 8.8889 - val_loss: 0.1807 - val_rmse: 11.5053 - val_mse: 132.3713 - val_mae: 9.1425\n",
      "Epoch 153/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 0.1731 - rmse: 11.2358 - mse: 126.2429 - mae: 8.8923 - val_loss: 0.1795 - val_rmse: 11.4718 - val_mse: 131.6031 - val_mae: 9.1141\n",
      "Epoch 154/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 0.1726 - rmse: 11.2111 - mse: 125.6879 - mae: 8.8665 - val_loss: 0.1805 - val_rmse: 11.5242 - val_mse: 132.8069 - val_mae: 9.1497\n",
      "Epoch 155/400\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1726 - rmse: 11.2227 - mse: 125.9479 - mae: 8.8734Restoring model weights from the end of the best epoch.\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 0.1726 - rmse: 11.2227 - mse: 125.9479 - mae: 8.8734 - val_loss: 0.1816 - val_rmse: 11.5487 - val_mse: 133.3730 - val_mae: 9.1737\n",
      "Epoch 00155: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    hist = model.fit(ds_train,\n",
    "                     validation_data=ds_val,\n",
    "                     callbacks=callbacks,\n",
    "                     epochs=400,\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 198ms/step - loss: 0.1796 - rmse: 11.4453 - mse: 130.9947 - mae: 9.0982\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    results = model.evaluate(ds_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Metric')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(16,16)\n",
    "\n",
    "    ax=fig.add_subplot(3,2,1)\n",
    "    ax.plot(hist.history['rmse'])\n",
    "    ax.plot(hist.history['mse'])\n",
    "    ax.legend(['Metric', 'Loss'])\n",
    "    ax.set_title('Train')\n",
    "\n",
    "    ax=fig.add_subplot(3,2,2)\n",
    "    ax.plot(hist.history['val_rmse'])\n",
    "    ax.plot(hist.history['val_mse'])\n",
    "    ax.legend(['Metric', 'Loss'])\n",
    "    ax.set_title('Test')\n",
    "\n",
    "    ax=fig.add_subplot(3,2,3)\n",
    "    ax.plot(hist.history['loss'])\n",
    "    ax.plot(hist.history['val_loss'])\n",
    "    ax.legend(['Train', 'Test'])\n",
    "    ax.set_title('Loss')\n",
    "\n",
    "    ax=fig.add_subplot(3,2,4)\n",
    "    ax.plot(hist.history['mse'])\n",
    "    ax.plot(hist.history['val_mse'])\n",
    "    ax.legend(['Train', 'Test'])\n",
    "    ax.set_title('Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = pd.read_csv('00_Data/fnc.csv')\n",
    "X1_test = X1_test[X1_test['Id'].isin(TEST_IDS)]\n",
    "X1_test = X1_test.to_numpy()\n",
    "X1_test = X1_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_test = pd.read_csv('00_Data/loading.csv')\n",
    "X2_test = X2_test[X2_test['Id'].isin(TEST_IDS)]\n",
    "X2_test = X2_test.to_numpy()\n",
    "X2_test = X2_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict([X1_test, X2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = y_preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = []\n",
    "i = 0\n",
    "for idx in TEST_IDS:\n",
    "    df_submission.append(['{0}_age'.format(idx), y_preds[i]])\n",
    "    df_submission.append(['{0}_domain1_var1'.format(idx), y_preds[i+1]])\n",
    "    df_submission.append(['{0}_domain1_var2'.format(idx), y_preds[i+2]])\n",
    "    df_submission.append(['{0}_domain2_var1'.format(idx), y_preds[i+3]])\n",
    "    df_submission.append(['{0}_domain2_var2'.format(idx), y_preds[i+4]])\n",
    "    i += 5\n",
    "\n",
    "df_submission = pd.DataFrame(df_submission, columns=['Id', 'Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('submission_fnc-load_mae_07.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.108977</td>\n",
       "      <td>69.993075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>21746</td>\n",
       "      <td>14.257265</td>\n",
       "      <td>21.358872</td>\n",
       "      <td>61.165998</td>\n",
       "      <td>51.778483</td>\n",
       "      <td>54.640179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>21747</td>\n",
       "      <td>55.456978</td>\n",
       "      <td>68.169675</td>\n",
       "      <td>29.907995</td>\n",
       "      <td>55.349257</td>\n",
       "      <td>54.019517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>21750</td>\n",
       "      <td>48.948756</td>\n",
       "      <td>55.114811</td>\n",
       "      <td>60.878271</td>\n",
       "      <td>38.617246</td>\n",
       "      <td>50.679885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>21752</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>59.844808</td>\n",
       "      <td>72.303110</td>\n",
       "      <td>55.458281</td>\n",
       "      <td>46.870235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>21754</td>\n",
       "      <td>68.820928</td>\n",
       "      <td>56.594193</td>\n",
       "      <td>34.605868</td>\n",
       "      <td>49.922535</td>\n",
       "      <td>50.383078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2\n",
       "0     10001  57.436077     30.571975     62.553736     53.325130     51.427998\n",
       "1     10002  59.580851     50.969456     67.470628     60.651856     58.311361\n",
       "2     10004  71.413018     53.152498     58.012103     52.418389     62.536641\n",
       "3     10005  66.532630           NaN           NaN     52.108977     69.993075\n",
       "4     10007  38.617381     49.197021     65.674285     40.151376     34.096421\n",
       "...     ...        ...           ...           ...           ...           ...\n",
       "5872  21746  14.257265     21.358872     61.165998     51.778483     54.640179\n",
       "5873  21747  55.456978     68.169675     29.907995     55.349257     54.019517\n",
       "5874  21750  48.948756     55.114811     60.878271     38.617246     50.679885\n",
       "5875  21752  66.532630     59.844808     72.303110     55.458281     46.870235\n",
       "5876  21754  68.820928     56.594193     34.605868     49.922535     50.383078\n",
       "\n",
       "[5877 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('00_Data/train_scores.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nulls = data[data.isnull().any(axis=1)]\n",
    "NULL_IDS = list(data_nulls['Id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
