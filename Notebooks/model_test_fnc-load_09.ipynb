{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "from IPython.display import IFrame\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "\n",
    "import scipy.stats as sts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing as prep\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn import discriminant_analysis as disan\n",
    "from sklearn import calibration as calib\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn import svm\n",
    "from sklearn import gaussian_process as gaup\n",
    "from sklearn import mixture as mix\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble as ens\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# from keras import models as kermdls\n",
    "# from keras import layers as kerlrs\n",
    "# from keras import metrics as kmetrics\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "import pickle\n",
    "\n",
    "import nilearn as nl\n",
    "from nilearn import plotting, image\n",
    "from nilearn import datasets\n",
    "import nibabel as nb\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10956898353285573279\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8113992409944468048\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6589725830\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9260765866342505891\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13594915500766043469\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnc_10 = pd.read_csv('00_Data/fnc.csv')\n",
    "# fnc_10 = fnc_10.head(5)\n",
    "# for row in fnc_10.iterrows():\n",
    "#     idx = int(row[1][0])\n",
    "#     row = row[1][1:]\n",
    "#     print(row)\n",
    "#     row.to_csv('00_Data/fnc_csv_norm/{0}.csv'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IDS = [map_id.split('.')[0] for map_id in sorted(os.listdir('00_Data/fMRI_test'))]\n",
    "TRAIN_IDS = [map_id.split('.')[0] for map_id in sorted(os.listdir('00_Data/fMRI_train'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.108977</td>\n",
       "      <td>69.993075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>21746</td>\n",
       "      <td>14.257265</td>\n",
       "      <td>21.358872</td>\n",
       "      <td>61.165998</td>\n",
       "      <td>51.778483</td>\n",
       "      <td>54.640179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>21747</td>\n",
       "      <td>55.456978</td>\n",
       "      <td>68.169675</td>\n",
       "      <td>29.907995</td>\n",
       "      <td>55.349257</td>\n",
       "      <td>54.019517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>21750</td>\n",
       "      <td>48.948756</td>\n",
       "      <td>55.114811</td>\n",
       "      <td>60.878271</td>\n",
       "      <td>38.617246</td>\n",
       "      <td>50.679885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>21752</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>59.844808</td>\n",
       "      <td>72.303110</td>\n",
       "      <td>55.458281</td>\n",
       "      <td>46.870235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>21754</td>\n",
       "      <td>68.820928</td>\n",
       "      <td>56.594193</td>\n",
       "      <td>34.605868</td>\n",
       "      <td>49.922535</td>\n",
       "      <td>50.383078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2\n",
       "0     10001  57.436077     30.571975     62.553736     53.325130     51.427998\n",
       "1     10002  59.580851     50.969456     67.470628     60.651856     58.311361\n",
       "2     10004  71.413018     53.152498     58.012103     52.418389     62.536641\n",
       "3     10005  66.532630           NaN           NaN     52.108977     69.993075\n",
       "4     10007  38.617381     49.197021     65.674285     40.151376     34.096421\n",
       "...     ...        ...           ...           ...           ...           ...\n",
       "5872  21746  14.257265     21.358872     61.165998     51.778483     54.640179\n",
       "5873  21747  55.456978     68.169675     29.907995     55.349257     54.019517\n",
       "5874  21750  48.948756     55.114811     60.878271     38.617246     50.679885\n",
       "5875  21752  66.532630     59.844808     72.303110     55.458281     46.870235\n",
       "5876  21754  68.820928     56.594193     34.605868     49.922535     50.383078\n",
       "\n",
       "[5877 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('00_Data/train_scores.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                0\n",
       "age               0\n",
       "domain1_var1    438\n",
       "domain1_var2    438\n",
       "domain2_var1     39\n",
       "domain2_var2     39\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls = data.isnull().sum()\n",
    "# l = len(data.index)\n",
    "\n",
    "# nulls['domain1_var1'] / l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length:  5434\n"
     ]
    }
   ],
   "source": [
    "print('Dataset length: ', len(data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_inputs_fnc(idx, labels):\n",
    "#     df = pd.read_csv('00_Data/fnc_csv/{0}.csv'.format(idx), index_col=0)\n",
    "#     X = np.array(df.values).reshape(-1)\n",
    "#     return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_inputs_loading(idx, labels):\n",
    "#     df = pd.read_csv('00_Data/loading_csv/{0}.csv'.format(idx), index_col=0)\n",
    "#     X = np.array(df.values).reshape(-1)\n",
    "#     return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(idx, labels):\n",
    "    df_fnc = pd.read_csv('00_Data/fnc_csv/{0}.csv'.format(idx), index_col=0)\n",
    "    X_fnc = np.array(df_fnc.values).reshape(-1)\n",
    "    \n",
    "    df_loading = pd.read_csv('00_Data/loading_csv/{0}.csv'.format(idx), index_col=0)\n",
    "    X_loading = np.array(df_loading.values).reshape(-1)\n",
    "#     print(X_fnc[0])\n",
    "#     print(X_loading[0])\n",
    "#     print(labels[0])\n",
    "#     print(X_fnc.shape)\n",
    "#     print(X_loading.shape)\n",
    "#     print(labels.shape)\n",
    "\n",
    "#     X_fnc = tf.convert_to_tensor(X_fnc, dtype=tf.float64)\n",
    "#     X_loading = tf.convert_to_tensor(X_loading, dtype=tf.float64)\n",
    "#     labels = tf.convert_to_tensor(labels, dtype=tf.float64)\n",
    "#     X = tf.tuple([X_fnc, X_loading])\n",
    "\n",
    "#     X = dict()\n",
    "#     X['input_1'] = X_fnc\n",
    "#     X['input_2'] = X_loading\n",
    "    X = (X_fnc, X_loading)\n",
    "    return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_decorator(func):\n",
    "    def wrapper(idx, labels):\n",
    "        # Use a tf.py_function to prevent auto-graph from compiling the method\n",
    "        return tf.py_function(func,\n",
    "                              inp=(idx, labels),\n",
    "                              Tout=tf.float64)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_py_function(func, inp, Tout, name=None):\n",
    "    \n",
    "    def wrapped_func(*flat_inp):\n",
    "        reconstructed_inp = tf.nest.pack_sequence_as(inp, flat_inp,\n",
    "                                                     expand_composites=True)\n",
    "        out = func(*reconstructed_inp)\n",
    "        return tf.nest.flatten(out, expand_composites=True)\n",
    "    \n",
    "    flat_Tout = tf.nest.flatten(Tout, expand_composites=True)\n",
    "    flat_out = tf.py_function(func=wrapped_func, \n",
    "                              inp=tf.nest.flatten(inp, expand_composites=True),\n",
    "                              Tout=[_tensor_spec_to_dtype(v) for v in flat_Tout],\n",
    "                              name=name)\n",
    "    spec_out = tf.nest.map_structure(_dtype_to_tensor_spec, Tout, expand_composites=True)\n",
    "    out = tf.nest.pack_sequence_as(spec_out, flat_out, expand_composites=True)\n",
    "    return out\n",
    "\n",
    "def _dtype_to_tensor_spec(v):\n",
    "    return tf.TensorSpec(None, v) if isinstance(v, tf.dtypes.DType) else v\n",
    "\n",
    "def _tensor_spec_to_dtype(v):\n",
    "    return v.dtype if isinstance(v, tf.TensorSpec) else v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dataset(data, batch_size):\n",
    "#     data = tf.data.Dataset.from_tensor_slices((data['Id'].values, \n",
    "#                                                data[['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']].values))\n",
    "#     data = data.shuffle(buffer_size=5500, seed=30, reshuffle_each_iteration=True)\n",
    "    \n",
    "#     data_fnc = data.map(map_decorator(get_inputs_fnc), \n",
    "#                      num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "#                      deterministic=True)\n",
    "#     data_loading = data.map(map_decorator(get_inputs_loading), \n",
    "#                      num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "#                      deterministic=True)\n",
    "\n",
    "#     data_fnc = data_fnc.batch(batch_size, drop_remainder=True)\n",
    "#     data_fnc = data_fnc.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "#     data_loading = data_loading.batch(batch_size, drop_remainder=True)\n",
    "#     data_loading = data_loading.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#     return (data_fnc, data_loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data, batch_size):\n",
    "    data = tf.data.Dataset.from_tensor_slices((data['Id'].values, \n",
    "                                               data[['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']].values))\n",
    "    data = data.shuffle(buffer_size=5500, seed=30, reshuffle_each_iteration=True)\n",
    "    \n",
    "    data = data.map(lambda idx, lbl:new_py_function(get_inputs, inp=(idx, lbl), Tout=((tf.float64, tf.float64), tf.float64), name=None), \n",
    "                     num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
    "                     deterministic=True)\n",
    "    data = data.batch(batch_size, drop_remainder=True)\n",
    "    data = data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = model_selection.train_test_split(data, test_size=0.2, shuffle=True, random_state=30)\n",
    "train, val = model_selection.train_test_split(train, test_size=0.2, shuffle=True, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 64\n",
    "\n",
    "# ds_train_fnc, ds_train_loading = get_dataset(train, batch_size)\n",
    "# ds_val_fnc, ds_val_loading = get_dataset(val, batch_size)\n",
    "# ds_test_fnc, ds_test_loading = get_dataset(test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "ds_train = get_dataset(train, batch_size)\n",
    "ds_val = get_dataset(val, batch_size)\n",
    "ds_test = get_dataset(test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.perf_counter()\n",
    "# for f in ds_train.take(1):\n",
    "#     pass\n",
    "# tf.print(\"Execution time:\", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE_fnc = (1378,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE_loading = (26,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_fnc = keras.layers.Input(shape=INPUT_SHAPE_fnc, name='inp_fnc')\n",
    "\n",
    "x = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(inputs_fnc)\n",
    "x = keras.layers.Dense(2048,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x)\n",
    "# x = keras.layers.Dropout(rate=0.2, seed=30)(x)\n",
    "\n",
    "x1 = keras.layers.Dense(512,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x1)\n",
    "# x1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(x1)\n",
    "\n",
    "x11 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x1)\n",
    "x11 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x11)\n",
    "x11 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x11)\n",
    "\n",
    "\n",
    "x12 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x1)\n",
    "x12 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x12)\n",
    "x12 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x12)\n",
    "\n",
    "x1 = keras.layers.concatenate([x11, x12])\n",
    "\n",
    "x1 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x1)\n",
    "x1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x1)\n",
    "x1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x1)\n",
    "\n",
    "x2 = keras.layers.Dense(512,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x2)\n",
    "# x2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(x2)\n",
    "\n",
    "x21 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x2)\n",
    "x21 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x21)\n",
    "x21 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x21)\n",
    "\n",
    "x22 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x2)\n",
    "x22 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x22)\n",
    "x22 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x22)\n",
    "\n",
    "x2 = keras.layers.concatenate([x21, x22])\n",
    "\n",
    "x2 = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x2)\n",
    "x2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x2)\n",
    "x2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(x2)\n",
    "\n",
    "x = keras.layers.concatenate([x1, x2])\n",
    "\n",
    "# x = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(x)\n",
    "\n",
    "x = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(x)\n",
    "x = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(x)\n",
    "\n",
    "# output\n",
    "x = keras.Model(inputs=inputs_fnc, outputs=x, name='model_fnc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_loading = keras.layers.Input(shape=INPUT_SHAPE_loading, name='inp_load')\n",
    "\n",
    "y = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(inputs_loading)\n",
    "\n",
    "y = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y)\n",
    "# y = keras.layers.Dropout(rate=0.2, seed=30)(y)\n",
    "\n",
    "y1 = keras.layers.Dense(128,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y1)\n",
    "y1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y1)\n",
    "\n",
    "y2 = keras.layers.Dense(128,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y2)\n",
    "y2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(y2)\n",
    "\n",
    "y = keras.layers.concatenate([y1, y2])\n",
    "\n",
    "# y = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "#                                           beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "#                                           moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "#                                           beta_constraint=None, gamma_constraint=None)(y)\n",
    "\n",
    "y = keras.layers.Dense(256,\n",
    "                           kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                           bias_initializer=keras.initializers.Constant(5.))(y)\n",
    "y = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(y)\n",
    "# x = keras.layers.Dropout(rate=0.2, seed=30)(x)\n",
    "\n",
    "# output\n",
    "y = keras.Model(inputs=inputs_loading, outputs=y, name='model_loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = keras.layers.concatenate([x.output, y.output])\n",
    "\n",
    "z1 = keras.layers.Dense(512, \n",
    "                       kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                       bias_initializer=keras.initializers.Constant(5.))(concat)\n",
    "z1 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(z1)\n",
    "z1 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(z1)\n",
    "\n",
    "z2 = keras.layers.Dense(512, \n",
    "                       kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                       bias_initializer=keras.initializers.Constant(5.))(concat)\n",
    "z2 = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(z2)\n",
    "z2 = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros',\n",
    "                                          moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, \n",
    "                                          beta_constraint=None, gamma_constraint=None)(z2)\n",
    "\n",
    "z = keras.layers.concatenate([z1, z2])\n",
    "\n",
    "z = keras.layers.Dense(512, \n",
    "                       kernel_initializer=keras.initializers.he_normal(seed=30),\n",
    "                       bias_initializer=keras.initializers.Constant(5.))(z)\n",
    "z = tf.keras.layers.PReLU(alpha_initializer=keras.initializers.Constant(0.5))(z)\n",
    "\n",
    "outputs = keras.layers.Dense(5, activation='linear')(z)\n",
    "\n",
    "model = keras.Model(inputs=[x.input, y.input], outputs=outputs, name='model_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_combined\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inp_fnc (InputLayer)            [(None, 1378)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1378)         5512        inp_fnc[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         2824192     batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu (PReLU)                 (None, 2048)         2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     p_re_lu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          1049088     p_re_lu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 512)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_5 (PReLU)               (None, 512)          512         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          131328      p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          131328      p_re_lu_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          131328      p_re_lu_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inp_load (InputLayer)           [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 256)          256         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_3 (PReLU)               (None, 256)          256         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_6 (PReLU)               (None, 256)          256         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_7 (PReLU)               (None, 256)          256         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 26)           104         inp_load[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        p_re_lu_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256)          1024        p_re_lu_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256)          1024        p_re_lu_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          6912        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_10 (PReLU)              (None, 256)          256         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          131328      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          131328      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 128)          32896       p_re_lu_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128)          32896       p_re_lu_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_4 (PReLU)               (None, 256)          256         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_8 (PReLU)               (None, 256)          256         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_11 (PReLU)              (None, 128)          128         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_12 (PReLU)              (None, 128)          128         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256)          1024        p_re_lu_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128)          512         p_re_lu_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 128)          512         p_re_lu_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256)          0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          131328      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          65792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_9 (PReLU)               (None, 256)          256         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_13 (PReLU)              (None, 256)          256         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 512)          0           p_re_lu_9[0][0]                  \n",
      "                                                                 p_re_lu_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 512)          262656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 512)          262656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_14 (PReLU)              (None, 512)          512         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_15 (PReLU)              (None, 512)          512         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 512)          2048        p_re_lu_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 512)          2048        p_re_lu_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1024)         0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 512)          524800      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_16 (PReLU)              (None, 512)          512         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 5)            2565        p_re_lu_16[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 7,056,885\n",
      "Trainable params: 7,048,445\n",
      "Non-trainable params: 8,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim = keras.optimizers.Adam(lr=0.000001,\n",
    "#                                  beta_1=0.99,\n",
    "#                                  beta_2=0.999,\n",
    "#                                  amsgrad=False)\n",
    "\n",
    "optim = tf.keras.optimizers.Adadelta(learning_rate=0.001, rho=0.95)\n",
    "        \n",
    "METRICS = [keras.metrics.RootMeanSquaredError(name='rmse'),\n",
    "           keras.metrics.MeanSquaredError(name='mse'),\n",
    "           keras.metrics.MeanAbsoluteError(name='mae')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def weighted_mae(y_true, y_pred):\n",
    "# #     tf.print(y_true)\n",
    "#     W = tf.constant([[0.2, 0.2, 0.2, 0.2, 0.2]])\n",
    "# #     tf.print(W / tf.math.reduce_mean(y_true, axis=0))\n",
    "#     return tf.math.reduce_mean(tf.linalg.matmul(tf.math.abs(y_pred - y_true), tf.transpose(W / tf.math.reduce_mean(y_true, axis=0))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mae', metrics=METRICS, optimizer=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint directory to store the checkpoints\n",
    "# Name of the checkpoint files\n",
    "# checkpoint_prefix = os.path.join('./99_Training_checkpoints/fnc-loading', \"ckpt_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/fnc-loading'),\n",
    "#              tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "#                                                 save_weights_only=False),\n",
    "#              tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "#                                                   factor=0.7, \n",
    "#                                                   patience=2, \n",
    "#                                                   verbose=1, \n",
    "#                                                   mode='min',\n",
    "#                                                   min_delta=0.01, \n",
    "#                                                   cooldown=5, \n",
    "#                                                   min_lr=0.00000001),\n",
    "#              tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "#                                               min_delta=0.001, \n",
    "#                                               patience=10, \n",
    "#                                               verbose=1, \n",
    "#                                               mode='min',\n",
    "#                                               baseline=None, \n",
    "#                                               restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/fnc-loading'),\n",
    "#              tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "#                                                   factor=0.7, \n",
    "#                                                   patience=2, \n",
    "#                                                   verbose=1, \n",
    "#                                                   mode='min',\n",
    "#                                                   min_delta=0.01, \n",
    "#                                                   cooldown=5, \n",
    "#                                                   min_lr=0.00000001),\n",
    "#              tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "#                                               min_delta=0.001, \n",
    "#                                               patience=10, \n",
    "#                                               verbose=1, \n",
    "#                                               mode='min',\n",
    "#                                               baseline=None, \n",
    "#                                               restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./99_Logs/fnc-loading'),\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                              min_delta=0.001, \n",
    "                                              patience=10, \n",
    "                                              verbose=1, \n",
    "                                              mode='min',\n",
    "                                              baseline=None, \n",
    "                                              restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decay(epoch):\n",
    "#     if epoch < 2:\n",
    "#         return 0.01\n",
    "#     elif epoch >= 2 and epoch < 10:\n",
    "#         return 0.005\n",
    "#     else:\n",
    "#         return 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.LearningRateScheduler(decay)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "54/54 [==============================] - 15s 279ms/step - loss: 56.7213 - rmse: 58.6116 - mse: 3435.3198 - mae: 56.7213 - val_loss: 58.4808 - val_rmse: 60.7992 - val_mse: 3696.5386 - val_mae: 58.4808\n",
      "Epoch 2/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 56.4966 - rmse: 58.3944 - mse: 3409.9067 - mae: 56.4966 - val_loss: 57.2289 - val_rmse: 59.1667 - val_mse: 3500.7007 - val_mae: 57.2289\n",
      "Epoch 3/400\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 56.2706 - rmse: 58.1750 - mse: 3384.3291 - mae: 56.2706 - val_loss: 56.4340 - val_rmse: 58.3027 - val_mse: 3399.2100 - val_mae: 56.4340\n",
      "Epoch 4/400\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 56.0155 - rmse: 57.9293 - mse: 3355.8081 - mae: 56.0155 - val_loss: 56.0044 - val_rmse: 57.8825 - val_mse: 3350.3804 - val_mae: 56.0044\n",
      "Epoch 5/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 55.7619 - rmse: 57.6836 - mse: 3327.3958 - mae: 55.7619 - val_loss: 55.5579 - val_rmse: 57.4632 - val_mse: 3302.0178 - val_mae: 55.5579\n",
      "Epoch 6/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 55.4922 - rmse: 57.4247 - mse: 3297.5940 - mae: 55.4922 - val_loss: 55.2161 - val_rmse: 57.1496 - val_mse: 3266.0745 - val_mae: 55.2161\n",
      "Epoch 7/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 55.2222 - rmse: 57.1646 - mse: 3267.7905 - mae: 55.2222 - val_loss: 54.8393 - val_rmse: 56.8036 - val_mse: 3226.6526 - val_mae: 54.8393\n",
      "Epoch 8/400\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 54.9352 - rmse: 56.8855 - mse: 3235.9600 - mae: 54.9352 - val_loss: 54.6146 - val_rmse: 56.5956 - val_mse: 3203.0583 - val_mae: 54.6146\n",
      "Epoch 9/400\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 54.6481 - rmse: 56.6061 - mse: 3204.2468 - mae: 54.6481 - val_loss: 54.3142 - val_rmse: 56.2899 - val_mse: 3168.5564 - val_mae: 54.3142\n",
      "Epoch 10/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 54.3313 - rmse: 56.3035 - mse: 3170.0859 - mae: 54.3313 - val_loss: 54.0138 - val_rmse: 56.0177 - val_mse: 3137.9780 - val_mae: 54.0138\n",
      "Epoch 11/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 54.0315 - rmse: 56.0132 - mse: 3137.4785 - mae: 54.0315 - val_loss: 53.6942 - val_rmse: 55.7221 - val_mse: 3104.9565 - val_mae: 53.6942\n",
      "Epoch 12/400\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 53.7105 - rmse: 55.7042 - mse: 3102.9612 - mae: 53.7105 - val_loss: 53.3861 - val_rmse: 55.4333 - val_mse: 3072.8481 - val_mae: 53.3861\n",
      "Epoch 13/400\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 53.3780 - rmse: 55.3846 - mse: 3067.4565 - mae: 53.3780 - val_loss: 53.0900 - val_rmse: 55.1485 - val_mse: 3041.3611 - val_mae: 53.0900\n",
      "Epoch 14/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 53.0418 - rmse: 55.0589 - mse: 3031.4802 - mae: 53.0418 - val_loss: 52.6566 - val_rmse: 54.7223 - val_mse: 2994.5264 - val_mae: 52.6566\n",
      "Epoch 15/400\n",
      "54/54 [==============================] - 15s 282ms/step - loss: 52.6969 - rmse: 54.7261 - mse: 2994.9441 - mae: 52.6969 - val_loss: 52.4001 - val_rmse: 54.4743 - val_mse: 2967.4543 - val_mae: 52.4001\n",
      "Epoch 16/400\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 52.3520 - rmse: 54.3935 - mse: 2958.6550 - mae: 52.3520 - val_loss: 52.0641 - val_rmse: 54.1656 - val_mse: 2933.9119 - val_mae: 52.0641\n",
      "Epoch 17/400\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 51.9978 - rmse: 54.0539 - mse: 2921.8208 - mae: 51.9978 - val_loss: 51.6410 - val_rmse: 53.7487 - val_mse: 2888.9192 - val_mae: 51.6410\n",
      "Epoch 18/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 51.6177 - rmse: 53.6882 - mse: 2882.4229 - mae: 51.6177 - val_loss: 51.1962 - val_rmse: 53.3226 - val_mse: 2843.3037 - val_mae: 51.1962\n",
      "Epoch 19/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 51.2588 - rmse: 53.3414 - mse: 2845.3096 - mae: 51.2588 - val_loss: 50.8755 - val_rmse: 53.0302 - val_mse: 2812.1992 - val_mae: 50.8755\n",
      "Epoch 20/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 50.8593 - rmse: 52.9594 - mse: 2804.6990 - mae: 50.8593 - val_loss: 50.4967 - val_rmse: 52.6667 - val_mse: 2773.7842 - val_mae: 50.4967\n",
      "Epoch 21/400\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 50.4888 - rmse: 52.6023 - mse: 2767.0015 - mae: 50.4888 - val_loss: 50.1272 - val_rmse: 52.3117 - val_mse: 2736.5186 - val_mae: 50.1272\n",
      "Epoch 22/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 50.0879 - rmse: 52.2179 - mse: 2726.7053 - mae: 50.0879 - val_loss: 49.7715 - val_rmse: 51.9706 - val_mse: 2700.9426 - val_mae: 49.7715\n",
      "Epoch 23/400\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 49.6872 - rmse: 51.8334 - mse: 2686.6990 - mae: 49.6872 - val_loss: 49.2805 - val_rmse: 51.4941 - val_mse: 2651.6406 - val_mae: 49.2805\n",
      "Epoch 24/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 49.2627 - rmse: 51.4279 - mse: 2644.8330 - mae: 49.2627 - val_loss: 48.8146 - val_rmse: 51.0456 - val_mse: 2605.6494 - val_mae: 48.8146\n",
      "Epoch 25/400\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 48.8607 - rmse: 51.0394 - mse: 2605.0186 - mae: 48.8607 - val_loss: 48.4839 - val_rmse: 50.7415 - val_mse: 2574.6968 - val_mae: 48.4839\n",
      "Epoch 26/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 48.4347 - rmse: 50.6372 - mse: 2564.1287 - mae: 48.4347 - val_loss: 48.0281 - val_rmse: 50.2869 - val_mse: 2528.7761 - val_mae: 48.0281\n",
      "Epoch 27/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 48.0234 - rmse: 50.2384 - mse: 2523.9016 - mae: 48.0234 - val_loss: 47.5738 - val_rmse: 49.8661 - val_mse: 2486.6267 - val_mae: 47.5738\n",
      "Epoch 28/400\n",
      "54/54 [==============================] - 15s 273ms/step - loss: 47.5854 - rmse: 49.8223 - mse: 2482.2659 - mae: 47.5854 - val_loss: 47.2152 - val_rmse: 49.5267 - val_mse: 2452.8899 - val_mae: 47.2152\n",
      "Epoch 29/400\n",
      "54/54 [==============================] - 15s 273ms/step - loss: 47.1524 - rmse: 49.4071 - mse: 2441.0603 - mae: 47.1524 - val_loss: 46.7391 - val_rmse: 49.0623 - val_mse: 2407.1072 - val_mae: 46.7391\n",
      "Epoch 30/400\n",
      "54/54 [==============================] - 15s 276ms/step - loss: 46.7052 - rmse: 48.9838 - mse: 2399.4084 - mae: 46.7052 - val_loss: 46.2762 - val_rmse: 48.6353 - val_mse: 2365.3916 - val_mae: 46.2762\n",
      "Epoch 31/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 46.2526 - rmse: 48.5485 - mse: 2356.9595 - mae: 46.2526 - val_loss: 45.8345 - val_rmse: 48.1990 - val_mse: 2323.1409 - val_mae: 45.8345\n",
      "Epoch 32/400\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 45.7979 - rmse: 48.1154 - mse: 2315.0876 - mae: 45.7979 - val_loss: 45.3544 - val_rmse: 47.7532 - val_mse: 2280.3706 - val_mae: 45.3544\n",
      "Epoch 33/400\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 45.3152 - rmse: 47.6560 - mse: 2271.0928 - mae: 45.3152 - val_loss: 44.9933 - val_rmse: 47.4059 - val_mse: 2247.3225 - val_mae: 44.9933\n",
      "Epoch 34/400\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 44.8577 - rmse: 47.2245 - mse: 2230.1494 - mae: 44.8577 - val_loss: 44.4541 - val_rmse: 46.8918 - val_mse: 2198.8389 - val_mae: 44.4541\n",
      "Epoch 35/400\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 44.3908 - rmse: 46.7727 - mse: 2187.6814 - mae: 44.3908 - val_loss: 43.9944 - val_rmse: 46.4502 - val_mse: 2157.6194 - val_mae: 43.9944\n",
      "Epoch 36/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 43.8925 - rmse: 46.3068 - mse: 2144.3206 - mae: 43.8925 - val_loss: 43.4251 - val_rmse: 45.9310 - val_mse: 2109.6567 - val_mae: 43.4251\n",
      "Epoch 37/400\n",
      "54/54 [==============================] - 15s 279ms/step - loss: 43.4123 - rmse: 45.8507 - mse: 2102.2830 - mae: 43.4123 - val_loss: 43.1343 - val_rmse: 45.6259 - val_mse: 2081.7251 - val_mae: 43.1343\n",
      "Epoch 38/400\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 42.9256 - rmse: 45.3878 - mse: 2060.0525 - mae: 42.9256 - val_loss: 42.5145 - val_rmse: 45.0548 - val_mse: 2029.9335 - val_mae: 42.5145\n",
      "Epoch 39/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 42.4190 - rmse: 44.9092 - mse: 2016.8331 - mae: 42.4190 - val_loss: 42.0586 - val_rmse: 44.6320 - val_mse: 1992.0154 - val_mae: 42.0586\n",
      "Epoch 40/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 41.9281 - rmse: 44.4454 - mse: 1975.3917 - mae: 41.9281 - val_loss: 41.5742 - val_rmse: 44.1531 - val_mse: 1949.4937 - val_mae: 41.5742\n",
      "Epoch 41/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 41.4052 - rmse: 43.9483 - mse: 1931.4553 - mae: 41.4052 - val_loss: 41.0236 - val_rmse: 43.6628 - val_mse: 1906.4374 - val_mae: 41.0236\n",
      "Epoch 42/400\n",
      "54/54 [==============================] - 15s 282ms/step - loss: 40.9140 - rmse: 43.4856 - mse: 1890.9984 - mae: 40.9140 - val_loss: 40.4913 - val_rmse: 43.1450 - val_mse: 1861.4895 - val_mae: 40.4913\n",
      "Epoch 43/400\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 40.4005 - rmse: 42.9966 - mse: 1848.7092 - mae: 40.4005 - val_loss: 39.9363 - val_rmse: 42.6246 - val_mse: 1816.8585 - val_mae: 39.9363\n",
      "Epoch 44/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 39.8776 - rmse: 42.5064 - mse: 1806.7947 - mae: 39.8776 - val_loss: 39.4360 - val_rmse: 42.1616 - val_mse: 1777.6011 - val_mae: 39.4360\n",
      "Epoch 45/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 39.3438 - rmse: 42.0031 - mse: 1764.2640 - mae: 39.3438 - val_loss: 38.8916 - val_rmse: 41.6377 - val_mse: 1733.6987 - val_mae: 38.8916\n",
      "Epoch 46/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 38.8181 - rmse: 41.5044 - mse: 1722.6169 - mae: 38.8181 - val_loss: 38.4322 - val_rmse: 41.2139 - val_mse: 1698.5853 - val_mae: 38.4322\n",
      "Epoch 47/400\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 38.2693 - rmse: 40.9940 - mse: 1680.5067 - mae: 38.2693 - val_loss: 37.8126 - val_rmse: 40.6182 - val_mse: 1649.8392 - val_mae: 37.8126\n",
      "Epoch 48/400\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 37.7378 - rmse: 40.4871 - mse: 1639.2030 - mae: 37.7378 - val_loss: 37.3120 - val_rmse: 40.1342 - val_mse: 1610.7546 - val_mae: 37.3120\n",
      "Epoch 49/400\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 37.2106 - rmse: 39.9915 - mse: 1599.3163 - mae: 37.2106 - val_loss: 36.7809 - val_rmse: 39.6335 - val_mse: 1570.8171 - val_mae: 36.7809\n",
      "Epoch 50/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 36.6559 - rmse: 39.4721 - mse: 1558.0454 - mae: 36.6559 - val_loss: 36.2268 - val_rmse: 39.1419 - val_mse: 1532.0918 - val_mae: 36.2268\n",
      "Epoch 51/400\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 36.1063 - rmse: 38.9547 - mse: 1517.4680 - mae: 36.1063 - val_loss: 35.7297 - val_rmse: 38.6508 - val_mse: 1493.8872 - val_mae: 35.7297\n",
      "Epoch 52/400\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 35.5458 - rmse: 38.4212 - mse: 1476.1914 - mae: 35.5458 - val_loss: 35.1398 - val_rmse: 38.0839 - val_mse: 1450.3866 - val_mae: 35.1398\n",
      "Epoch 53/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 34.9918 - rmse: 37.9014 - mse: 1436.5159 - mae: 34.9918 - val_loss: 34.6205 - val_rmse: 37.5974 - val_mse: 1413.5634 - val_mae: 34.6205\n",
      "Epoch 54/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 34.4335 - rmse: 37.3740 - mse: 1396.8188 - mae: 34.4335 - val_loss: 34.0041 - val_rmse: 37.0487 - val_mse: 1372.6053 - val_mae: 34.0041\n",
      "Epoch 55/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 33.8670 - rmse: 36.8442 - mse: 1357.4978 - mae: 33.8670 - val_loss: 33.3930 - val_rmse: 36.4505 - val_mse: 1328.6378 - val_mae: 33.3930\n",
      "Epoch 56/400\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 33.2930 - rmse: 36.3007 - mse: 1317.7408 - mae: 33.2930 - val_loss: 32.9740 - val_rmse: 36.0613 - val_mse: 1300.4148 - val_mae: 32.9740\n",
      "Epoch 57/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 32.7377 - rmse: 35.7726 - mse: 1279.6765 - mae: 32.7377 - val_loss: 32.2878 - val_rmse: 35.4329 - val_mse: 1255.4884 - val_mae: 32.2878\n",
      "Epoch 58/400\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 32.1565 - rmse: 35.2292 - mse: 1241.0956 - mae: 32.1565 - val_loss: 31.7413 - val_rmse: 34.8928 - val_mse: 1217.5109 - val_mae: 31.7413\n",
      "Epoch 59/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 31.5759 - rmse: 34.6809 - mse: 1202.7654 - mae: 31.5759 - val_loss: 31.2295 - val_rmse: 34.4067 - val_mse: 1183.8236 - val_mae: 31.2295\n",
      "Epoch 60/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 31.0157 - rmse: 34.1497 - mse: 1166.1997 - mae: 31.0157 - val_loss: 30.6027 - val_rmse: 33.8099 - val_mse: 1143.1063 - val_mae: 30.6027\n",
      "Epoch 61/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 30.4407 - rmse: 33.6108 - mse: 1129.6833 - mae: 30.4407 - val_loss: 30.0840 - val_rmse: 33.2919 - val_mse: 1108.3518 - val_mae: 30.0840\n",
      "Epoch 62/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 29.8466 - rmse: 33.0482 - mse: 1092.1849 - mae: 29.8466 - val_loss: 29.5021 - val_rmse: 32.7619 - val_mse: 1073.3431 - val_mae: 29.5021\n",
      "Epoch 63/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 29.2788 - rmse: 32.5100 - mse: 1056.8976 - mae: 29.2788 - val_loss: 28.9146 - val_rmse: 32.2122 - val_mse: 1037.6282 - val_mae: 28.9146\n",
      "Epoch 64/400\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 28.7116 - rmse: 31.9690 - mse: 1022.0151 - mae: 28.7116 - val_loss: 28.3397 - val_rmse: 31.6526 - val_mse: 1001.8851 - val_mae: 28.3397\n",
      "Epoch 65/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 28.1189 - rmse: 31.4082 - mse: 986.4729 - mae: 28.1189 - val_loss: 27.7327 - val_rmse: 31.0603 - val_mse: 964.7395 - val_mae: 27.7327\n",
      "Epoch 66/400\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 27.5495 - rmse: 30.8654 - mse: 952.6757 - mae: 27.5495 - val_loss: 27.1898 - val_rmse: 30.5635 - val_mse: 934.1277 - val_mae: 27.1898\n",
      "Epoch 67/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 26.9857 - rmse: 30.3310 - mse: 919.9702 - mae: 26.9857 - val_loss: 26.6252 - val_rmse: 30.0007 - val_mse: 900.0427 - val_mae: 26.6252\n",
      "Epoch 68/400\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 26.3894 - rmse: 29.7615 - mse: 885.7458 - mae: 26.3894 - val_loss: 26.0708 - val_rmse: 29.4840 - val_mse: 869.3047 - val_mae: 26.0708\n",
      "Epoch 69/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 25.7947 - rmse: 29.1954 - mse: 852.3742 - mae: 25.7947 - val_loss: 25.5043 - val_rmse: 28.9273 - val_mse: 836.7866 - val_mae: 25.5043\n",
      "Epoch 70/400\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 25.2275 - rmse: 28.6521 - mse: 820.9414 - mae: 25.2275 - val_loss: 24.9921 - val_rmse: 28.4442 - val_mse: 809.0712 - val_mae: 24.9921\n",
      "Epoch 71/400\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 24.6607 - rmse: 28.1109 - mse: 790.2239 - mae: 24.6607 - val_loss: 24.4101 - val_rmse: 27.8653 - val_mse: 776.4733 - val_mae: 24.4101\n",
      "Epoch 72/400\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 24.0955 - rmse: 27.5624 - mse: 759.6876 - mae: 24.0955 - val_loss: 23.9127 - val_rmse: 27.3716 - val_mse: 749.2040 - val_mae: 23.9127\n",
      "Epoch 73/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 23.5379 - rmse: 27.0264 - mse: 730.4259 - mae: 23.5379 - val_loss: 23.3941 - val_rmse: 26.8699 - val_mse: 721.9919 - val_mae: 23.3941\n",
      "Epoch 74/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 22.9578 - rmse: 26.4676 - mse: 700.5367 - mae: 22.9578 - val_loss: 22.7385 - val_rmse: 26.2067 - val_mse: 686.7930 - val_mae: 22.7385\n",
      "Epoch 75/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 22.4173 - rmse: 25.9401 - mse: 672.8876 - mae: 22.4173 - val_loss: 22.1862 - val_rmse: 25.6798 - val_mse: 659.4500 - val_mae: 22.1862\n",
      "Epoch 76/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 21.8542 - rmse: 25.3924 - mse: 644.7726 - mae: 21.8542 - val_loss: 21.7162 - val_rmse: 25.2082 - val_mse: 635.4547 - val_mae: 21.7162\n",
      "Epoch 77/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 21.3141 - rmse: 24.8627 - mse: 618.1540 - mae: 21.3141 - val_loss: 21.2082 - val_rmse: 24.7096 - val_mse: 610.5650 - val_mae: 21.2082\n",
      "Epoch 78/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 20.7711 - rmse: 24.3254 - mse: 591.7230 - mae: 20.7711 - val_loss: 20.5979 - val_rmse: 24.1028 - val_mse: 580.9459 - val_mae: 20.5979\n",
      "Epoch 79/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 20.2509 - rmse: 23.8149 - mse: 567.1495 - mae: 20.2509 - val_loss: 20.1150 - val_rmse: 23.6149 - val_mse: 557.6625 - val_mae: 20.1150\n",
      "Epoch 80/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 19.7224 - rmse: 23.2798 - mse: 541.9506 - mae: 19.7224 - val_loss: 19.5783 - val_rmse: 23.0440 - val_mse: 531.0253 - val_mae: 19.5783\n",
      "Epoch 81/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 19.2045 - rmse: 22.7629 - mse: 518.1501 - mae: 19.2045 - val_loss: 19.1237 - val_rmse: 22.5837 - val_mse: 510.0257 - val_mae: 19.1237\n",
      "Epoch 82/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 18.6991 - rmse: 22.2539 - mse: 495.2375 - mae: 18.6991 - val_loss: 18.6781 - val_rmse: 22.1127 - val_mse: 488.9700 - val_mae: 18.6781\n",
      "Epoch 83/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 18.2211 - rmse: 21.7625 - mse: 473.6068 - mae: 18.2211 - val_loss: 18.0756 - val_rmse: 21.5121 - val_mse: 462.7712 - val_mae: 18.0756\n",
      "Epoch 84/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 17.7187 - rmse: 21.2543 - mse: 451.7459 - mae: 17.7187 - val_loss: 17.7452 - val_rmse: 21.1473 - val_mse: 447.2068 - val_mae: 17.7452\n",
      "Epoch 85/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 17.2455 - rmse: 20.7686 - mse: 431.3354 - mae: 17.2455 - val_loss: 17.2160 - val_rmse: 20.5931 - val_mse: 424.0765 - val_mae: 17.2160\n",
      "Epoch 86/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 16.7897 - rmse: 20.2976 - mse: 411.9939 - mae: 16.7897 - val_loss: 16.7770 - val_rmse: 20.1433 - val_mse: 405.7526 - val_mae: 16.7770\n",
      "Epoch 87/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 16.3368 - rmse: 19.8143 - mse: 392.6067 - mae: 16.3368 - val_loss: 16.3449 - val_rmse: 19.6678 - val_mse: 386.8228 - val_mae: 16.3449\n",
      "Epoch 88/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 15.9194 - rmse: 19.3737 - mse: 375.3397 - mae: 15.9194 - val_loss: 15.9761 - val_rmse: 19.2564 - val_mse: 370.8098 - val_mae: 15.9761\n",
      "Epoch 89/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 15.4839 - rmse: 18.9114 - mse: 357.6405 - mae: 15.4839 - val_loss: 15.5327 - val_rmse: 18.8182 - val_mse: 354.1242 - val_mae: 15.5327\n",
      "Epoch 90/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 15.0711 - rmse: 18.4696 - mse: 341.1277 - mae: 15.0711 - val_loss: 15.1285 - val_rmse: 18.3889 - val_mse: 338.1520 - val_mae: 15.1285\n",
      "Epoch 91/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 14.6698 - rmse: 18.0318 - mse: 325.1453 - mae: 14.6698 - val_loss: 14.7872 - val_rmse: 17.9959 - val_mse: 323.8530 - val_mae: 14.7872\n",
      "Epoch 92/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 14.2971 - rmse: 17.6224 - mse: 310.5485 - mae: 14.2971 - val_loss: 14.4079 - val_rmse: 17.5927 - val_mse: 309.5018 - val_mae: 14.4079\n",
      "Epoch 93/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 13.9298 - rmse: 17.2144 - mse: 296.3355 - mae: 13.9298 - val_loss: 14.0315 - val_rmse: 17.1667 - val_mse: 294.6971 - val_mae: 14.0315\n",
      "Epoch 94/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 13.5785 - rmse: 16.8161 - mse: 282.7821 - mae: 13.5785 - val_loss: 13.6813 - val_rmse: 16.7737 - val_mse: 281.3579 - val_mae: 13.6813\n",
      "Epoch 95/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 13.2362 - rmse: 16.4334 - mse: 270.0561 - mae: 13.2362 - val_loss: 13.3514 - val_rmse: 16.4154 - val_mse: 269.4651 - val_mae: 13.3514\n",
      "Epoch 96/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 12.9024 - rmse: 16.0563 - mse: 257.8054 - mae: 12.9024 - val_loss: 13.0471 - val_rmse: 16.0649 - val_mse: 258.0814 - val_mae: 13.0471\n",
      "Epoch 97/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 12.5837 - rmse: 15.6872 - mse: 246.0871 - mae: 12.5837 - val_loss: 12.7405 - val_rmse: 15.7009 - val_mse: 246.5195 - val_mae: 12.7405\n",
      "Epoch 98/400\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 12.2994 - rmse: 15.3540 - mse: 235.7464 - mae: 12.2994 - val_loss: 12.4520 - val_rmse: 15.3955 - val_mse: 237.0207 - val_mae: 12.4520\n",
      "Epoch 99/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 12.0273 - rmse: 15.0317 - mse: 225.9534 - mae: 12.0273 - val_loss: 12.1347 - val_rmse: 15.0242 - val_mse: 225.7256 - val_mae: 12.1347\n",
      "Epoch 100/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 11.7504 - rmse: 14.7111 - mse: 216.4179 - mae: 11.7504 - val_loss: 11.8259 - val_rmse: 14.6845 - val_mse: 215.6339 - val_mae: 11.8259\n",
      "Epoch 101/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 11.4956 - rmse: 14.4025 - mse: 207.4315 - mae: 11.4956 - val_loss: 11.5712 - val_rmse: 14.3956 - val_mse: 207.2323 - val_mae: 11.57125074 - mse: 210\n",
      "Epoch 102/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 11.2474 - rmse: 14.1092 - mse: 199.0683 - mae: 11.2474 - val_loss: 11.3713 - val_rmse: 14.1632 - val_mse: 200.5954 - val_mae: 11.3713\n",
      "Epoch 103/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 11.0324 - rmse: 13.8468 - mse: 191.7338 - mae: 11.0324 - val_loss: 11.1105 - val_rmse: 13.8496 - val_mse: 191.8104 - val_mae: 11.1105\n",
      "Epoch 104/400\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 10.8248 - rmse: 13.5914 - mse: 184.7269 - mae: 10.8248 - val_loss: 10.9685 - val_rmse: 13.6582 - val_mse: 186.5456 - val_mae: 10.9685\n",
      "Epoch 105/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 10.6055 - rmse: 13.3300 - mse: 177.6876 - mae: 10.6055 - val_loss: 10.7896 - val_rmse: 13.4302 - val_mse: 180.3691 - val_mae: 10.7896\n",
      "Epoch 106/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 10.4113 - rmse: 13.0981 - mse: 171.5610 - mae: 10.4113 - val_loss: 10.5525 - val_rmse: 13.1800 - val_mse: 173.7113 - val_mae: 10.5525\n",
      "Epoch 107/400\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 10.2318 - rmse: 12.8693 - mse: 165.6200 - mae: 10.2318 - val_loss: 10.3695 - val_rmse: 12.9473 - val_mse: 167.6321 - val_mae: 10.3695\n",
      "Epoch 108/400\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 10.0585 - rmse: 12.6508 - mse: 160.0416 - mae: 10.0585 - val_loss: 10.1917 - val_rmse: 12.7396 - val_mse: 162.2972 - val_mae: 10.1917\n",
      "Epoch 109/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 9.9022 - rmse: 12.4612 - mse: 155.2807 - mae: 9.9022 - val_loss: 10.0731 - val_rmse: 12.6039 - val_mse: 158.8590 - val_mae: 10.0731\n",
      "Epoch 110/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 9.7442 - rmse: 12.2697 - mse: 150.5457 - mae: 9.7442 - val_loss: 9.9974 - val_rmse: 12.4783 - val_mse: 155.7091 - val_mae: 9.9974\n",
      "Epoch 111/400\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 9.5939 - rmse: 12.0897 - mse: 146.1606 - mae: 9.5939 - val_loss: 9.8635 - val_rmse: 12.3202 - val_mse: 151.7871 - val_mae: 9.8635\n",
      "Epoch 112/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 9.4728 - rmse: 11.9384 - mse: 142.5251 - mae: 9.4728 - val_loss: 9.6750 - val_rmse: 12.1196 - val_mse: 146.8838 - val_mae: 9.6750\n",
      "Epoch 113/400\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 9.3531 - rmse: 11.7949 - mse: 139.1194 - mae: 9.3531 - val_loss: 9.5952 - val_rmse: 12.0025 - val_mse: 144.0598 - val_mae: 9.5952\n",
      "Epoch 114/400\n",
      "54/54 [==============================] - 15s 276ms/step - loss: 9.2399 - rmse: 11.6505 - mse: 135.7342 - mae: 9.2399 - val_loss: 9.4893 - val_rmse: 11.8827 - val_mse: 141.1992 - val_mae: 9.4893\n",
      "Epoch 115/400\n",
      "54/54 [==============================] - 15s 278ms/step - loss: 9.1334 - rmse: 11.5218 - mse: 132.7510 - mae: 9.1334 - val_loss: 9.4071 - val_rmse: 11.7870 - val_mse: 138.9344 - val_mae: 9.4071\n",
      "Epoch 116/400\n",
      "54/54 [==============================] - 15s 276ms/step - loss: 9.0263 - rmse: 11.3942 - mse: 129.8285 - mae: 9.0263 - val_loss: 9.3135 - val_rmse: 11.6838 - val_mse: 136.5122 - val_mae: 9.3135\n",
      "Epoch 117/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 8.9684 - rmse: 11.3121 - mse: 127.9640 - mae: 8.9684 - val_loss: 9.2406 - val_rmse: 11.5817 - val_mse: 134.1361 - val_mae: 9.2406\n",
      "Epoch 118/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 8.8633 - rmse: 11.2048 - mse: 125.5479 - mae: 8.8633 - val_loss: 9.1690 - val_rmse: 11.5114 - val_mse: 132.5124 - val_mae: 9.1690\n",
      "Epoch 119/400\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 8.7883 - rmse: 11.1111 - mse: 123.4574 - mae: 8.7883 - val_loss: 9.0942 - val_rmse: 11.4398 - val_mse: 130.8692 - val_mae: 9.0942\n",
      "Epoch 120/400\n",
      "54/54 [==============================] - 15s 273ms/step - loss: 8.7159 - rmse: 11.0231 - mse: 121.5083 - mae: 8.7159 - val_loss: 8.9994 - val_rmse: 11.3076 - val_mse: 127.8616 - val_mae: 8.9994\n",
      "Epoch 121/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 8.6593 - rmse: 10.9554 - mse: 120.0216 - mae: 8.6593 - val_loss: 8.9703 - val_rmse: 11.2897 - val_mse: 127.4579 - val_mae: 8.9703\n",
      "Epoch 122/400\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 8.5931 - rmse: 10.8731 - mse: 118.2233 - mae: 8.5931 - val_loss: 8.9031 - val_rmse: 11.1980 - val_mse: 125.3941 - val_mae: 8.9031\n",
      "Epoch 123/400\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 8.5684 - rmse: 10.8421 - mse: 117.5512 - mae: 8.5684 - val_loss: 8.8552 - val_rmse: 11.1633 - val_mse: 124.6198 - val_mae: 8.8552\n",
      "Epoch 124/400\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 8.5044 - rmse: 10.7718 - mse: 116.0320 - mae: 8.5044 - val_loss: 8.7966 - val_rmse: 11.0897 - val_mse: 122.9813 - val_mae: 8.7966\n",
      "Epoch 125/400\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 8.4568 - rmse: 10.7189 - mse: 114.8944 - mae: 8.4568 - val_loss: 8.8227 - val_rmse: 11.1178 - val_mse: 123.6065 - val_mae: 8.8227\n",
      "Epoch 126/400\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 8.4228 - rmse: 10.6825 - mse: 114.1155 - mae: 8.4228 - val_loss: 8.7452 - val_rmse: 11.0375 - val_mse: 121.8267 - val_mae: 8.7452\n",
      "Epoch 127/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 8.3796 - rmse: 10.6278 - mse: 112.9491 - mae: 8.3796 - val_loss: 8.7692 - val_rmse: 11.0497 - val_mse: 122.0964 - val_mae: 8.7692\n",
      "Epoch 128/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 8.3475 - rmse: 10.6005 - mse: 112.3698 - mae: 8.3475 - val_loss: 8.7099 - val_rmse: 11.0017 - val_mse: 121.0375 - val_mae: 8.7099\n",
      "Epoch 129/400\n",
      "54/54 [==============================] - 15s 283ms/step - loss: 8.3248 - rmse: 10.5743 - mse: 111.8164 - mae: 8.3248 - val_loss: 8.6553 - val_rmse: 10.9427 - val_mse: 119.7433 - val_mae: 8.6553\n",
      "Epoch 130/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 8.2853 - rmse: 10.5302 - mse: 110.8853 - mae: 8.2853 - val_loss: 8.6908 - val_rmse: 10.9735 - val_mse: 120.4168 - val_mae: 8.6908\n",
      "Epoch 131/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 8.2717 - rmse: 10.5244 - mse: 110.7633 - mae: 8.2717 - val_loss: 8.6642 - val_rmse: 10.9496 - val_mse: 119.8930 - val_mae: 8.6642\n",
      "Epoch 132/400\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 8.2255 - rmse: 10.4764 - mse: 109.7550 - mae: 8.2255 - val_loss: 8.6200 - val_rmse: 10.8920 - val_mse: 118.6358 - val_mae: 8.6200\n",
      "Epoch 133/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 8.2165 - rmse: 10.4650 - mse: 109.5169 - mae: 8.2165 - val_loss: 8.5906 - val_rmse: 10.8578 - val_mse: 117.8908 - val_mae: 8.5906\n",
      "Epoch 134/400\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 8.2302 - rmse: 10.4706 - mse: 109.6325 - mae: 8.2302 - val_loss: 8.6003 - val_rmse: 10.8854 - val_mse: 118.4912 - val_mae: 8.6003\n",
      "Epoch 135/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 8.1828 - rmse: 10.4304 - mse: 108.7937 - mae: 8.1828 - val_loss: 8.5846 - val_rmse: 10.8638 - val_mse: 118.0214 - val_mae: 8.5846\n",
      "Epoch 136/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 8.1848 - rmse: 10.4307 - mse: 108.8005 - mae: 8.1848 - val_loss: 8.5563 - val_rmse: 10.8371 - val_mse: 117.4431 - val_mae: 8.5563\n",
      "Epoch 137/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 8.1592 - rmse: 10.4094 - mse: 108.3552 - mae: 8.1592 - val_loss: 8.5934 - val_rmse: 10.8873 - val_mse: 118.5341 - val_mae: 8.5934\n",
      "Epoch 138/400\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 8.1307 - rmse: 10.3840 - mse: 107.8267 - mae: 8.1307 - val_loss: 8.5552 - val_rmse: 10.8387 - val_mse: 117.4772 - val_mae: 8.5552\n",
      "Epoch 139/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 8.1258 - rmse: 10.3777 - mse: 107.6965 - mae: 8.1258 - val_loss: 8.5263 - val_rmse: 10.8133 - val_mse: 116.9278 - val_mae: 8.5263\n",
      "Epoch 140/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 8.1160 - rmse: 10.3688 - mse: 107.5122 - mae: 8.1160 - val_loss: 8.5753 - val_rmse: 10.8804 - val_mse: 118.3838 - val_mae: 8.5753\n",
      "Epoch 141/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 8.1204 - rmse: 10.3729 - mse: 107.5968 - mae: 8.1204 - val_loss: 8.5663 - val_rmse: 10.8597 - val_mse: 117.9333 - val_mae: 8.5663\n",
      "Epoch 142/400\n",
      "54/54 [==============================] - 14s 264ms/step - loss: 8.0963 - rmse: 10.3495 - mse: 107.1115 - mae: 8.0963 - val_loss: 8.5821 - val_rmse: 10.8792 - val_mse: 118.3577 - val_mae: 8.5821\n",
      "Epoch 143/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 8.0766 - rmse: 10.3310 - mse: 106.7298 - mae: 8.0766 - val_loss: 8.5450 - val_rmse: 10.8214 - val_mse: 117.1021 - val_mae: 8.5450\n",
      "Epoch 144/400\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 8.0843 - rmse: 10.3408 - mse: 106.9331 - mae: 8.0843 - val_loss: 8.5434 - val_rmse: 10.8381 - val_mse: 117.4640 - val_mae: 8.5434\n",
      "Epoch 145/400\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 8.0716 - rmse: 10.3370 - mse: 106.8541 - mae: 8.0716 - val_loss: 8.4945 - val_rmse: 10.7881 - val_mse: 116.3821 - val_mae: 8.4945\n",
      "Epoch 146/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 8.0615 - rmse: 10.3384 - mse: 106.8826 - mae: 8.0615 - val_loss: 8.5365 - val_rmse: 10.8318 - val_mse: 117.3279 - val_mae: 8.5365\n",
      "Epoch 147/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 8.0346 - rmse: 10.2979 - mse: 106.0462 - mae: 8.0346 - val_loss: 8.5492 - val_rmse: 10.8509 - val_mse: 117.7424 - val_mae: 8.5492\n",
      "Epoch 148/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 8.0350 - rmse: 10.2943 - mse: 105.9717 - mae: 8.0350 - val_loss: 8.4982 - val_rmse: 10.7985 - val_mse: 116.6077 - val_mae: 8.4982\n",
      "Epoch 149/400\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 8.0384 - rmse: 10.3087 - mse: 106.2684 - mae: 8.0384 - val_loss: 8.5354 - val_rmse: 10.8229 - val_mse: 117.1355 - val_mae: 8.5354\n",
      "Epoch 150/400\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 8.0224 - rmse: 10.2943 - mse: 105.9732 - mae: 8.0224 - val_loss: 8.5357 - val_rmse: 10.8321 - val_mse: 117.3337 - val_mae: 8.5357\n",
      "Epoch 151/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 8.0009 - rmse: 10.2697 - mse: 105.4672 - mae: 8.0009 - val_loss: 8.5011 - val_rmse: 10.7937 - val_mse: 116.5032 - val_mae: 8.5011\n",
      "Epoch 152/400\n",
      "54/54 [==============================] - 14s 258ms/step - loss: 8.0101 - rmse: 10.2865 - mse: 105.8119 - mae: 8.0101 - val_loss: 8.5228 - val_rmse: 10.8124 - val_mse: 116.9081 - val_mae: 8.5228\n",
      "Epoch 153/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 8.0126 - rmse: 10.2935 - mse: 105.9563 - mae: 8.0126 - val_loss: 8.4780 - val_rmse: 10.7603 - val_mse: 115.7850 - val_mae: 8.4780\n",
      "Epoch 154/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 7.9813 - rmse: 10.2635 - mse: 105.3397 - mae: 7.9813 - val_loss: 8.5208 - val_rmse: 10.8187 - val_mse: 117.0436 - val_mae: 8.5208\n",
      "Epoch 155/400\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 7.9866 - rmse: 10.2750 - mse: 105.5748 - mae: 7.9866 - val_loss: 8.5204 - val_rmse: 10.8144 - val_mse: 116.9504 - val_mae: 8.5204\n",
      "Epoch 156/400\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 7.9663 - rmse: 10.2532 - mse: 105.1278 - mae: 7.9663 - val_loss: 8.4881 - val_rmse: 10.7731 - val_mse: 116.0601 - val_mae: 8.4881\n",
      "Epoch 157/400\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 7.9606 - rmse: 10.2486 - mse: 105.0345 - mae: 7.9606 - val_loss: 8.5042 - val_rmse: 10.8078 - val_mse: 116.8088 - val_mae: 8.5042\n",
      "Epoch 158/400\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 7.9692 - rmse: 10.2530 - mse: 105.1238 - mae: 7.9692 - val_loss: 8.4605 - val_rmse: 10.7748 - val_mse: 116.0967 - val_mae: 8.4605\n",
      "Epoch 159/400\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 7.9659 - rmse: 10.2558 - mse: 105.1807 - mae: 7.9659 - val_loss: 8.5035 - val_rmse: 10.7995 - val_mse: 116.6300 - val_mae: 8.5035\n",
      "Epoch 160/400\n",
      "54/54 [==============================] - 15s 273ms/step - loss: 7.9371 - rmse: 10.2344 - mse: 104.7429 - mae: 7.9371 - val_loss: 8.4518 - val_rmse: 10.7411 - val_mse: 115.3712 - val_mae: 8.4518\n",
      "Epoch 161/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 7.9395 - rmse: 10.2377 - mse: 104.8096 - mae: 7.9395 - val_loss: 8.4846 - val_rmse: 10.7895 - val_mse: 116.4135 - val_mae: 8.4846\n",
      "Epoch 162/400\n",
      "54/54 [==============================] - 14s 261ms/step - loss: 7.9381 - rmse: 10.2301 - mse: 104.6542 - mae: 7.9381 - val_loss: 8.5056 - val_rmse: 10.8090 - val_mse: 116.8350 - val_mae: 8.5056\n",
      "Epoch 163/400\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 7.9455 - rmse: 10.2418 - mse: 104.8945 - mae: 7.9455 - val_loss: 8.4940 - val_rmse: 10.7806 - val_mse: 116.2220 - val_mae: 8.4940\n",
      "Epoch 164/400\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 7.9262 - rmse: 10.2264 - mse: 104.5787 - mae: 7.9262 - val_loss: 8.4646 - val_rmse: 10.7363 - val_mse: 115.2688 - val_mae: 8.4646\n",
      "Epoch 165/400\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 7.9312 - rmse: 10.2353 - mse: 104.7612 - mae: 7.9312 - val_loss: 8.5029 - val_rmse: 10.7992 - val_mse: 116.6219 - val_mae: 8.5029\n",
      "Epoch 166/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 7.9239 - rmse: 10.2298 - mse: 104.6479 - mae: 7.9239 - val_loss: 8.4828 - val_rmse: 10.7600 - val_mse: 115.7772 - val_mae: 8.4828\n",
      "Epoch 167/400\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 7.9138 - rmse: 10.2247 - mse: 104.5452 - mae: 7.9138 - val_loss: 8.5270 - val_rmse: 10.8030 - val_mse: 116.7049 - val_mae: 8.5270\n",
      "Epoch 168/400\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 7.9009 - rmse: 10.2111 - mse: 104.2674 - mae: 7.9009 - val_loss: 8.5419 - val_rmse: 10.8537 - val_mse: 117.8035 - val_mae: 8.5419\n",
      "Epoch 169/400\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 7.9028 - rmse: 10.2063 - mse: 104.1675 - mae: 7.9028 - val_loss: 8.4985 - val_rmse: 10.8074 - val_mse: 116.8004 - val_mae: 8.4985\n",
      "Epoch 170/400\n",
      "54/54 [==============================] - ETA: 0s - loss: 7.8893 - rmse: 10.1945 - mse: 103.9276 - mae: 7.8893Restoring model weights from the end of the best epoch.\n",
      "54/54 [==============================] - 15s 276ms/step - loss: 7.8893 - rmse: 10.1945 - mse: 103.9276 - mae: 7.8893 - val_loss: 8.5009 - val_rmse: 10.8122 - val_mse: 116.9033 - val_mae: 8.5009\n",
      "Epoch 00170: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    hist = model.fit(ds_train,\n",
    "                     validation_data=ds_val,\n",
    "                     callbacks=callbacks,\n",
    "                     epochs=400,\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 200ms/step - loss: 8.4272 - rmse: 10.7324 - mse: 115.1843 - mae: 8.4272\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    results = model.evaluate(ds_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Metric')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(16,16)\n",
    "\n",
    "    ax=fig.add_subplot(3,2,1)\n",
    "    ax.plot(hist.history['rmse'])\n",
    "    ax.plot(hist.history['mse'])\n",
    "    ax.legend(['Metric', 'Loss'])\n",
    "    ax.set_title('Train')\n",
    "\n",
    "    ax=fig.add_subplot(3,2,2)\n",
    "    ax.plot(hist.history['val_rmse'])\n",
    "    ax.plot(hist.history['val_mse'])\n",
    "    ax.legend(['Metric', 'Loss'])\n",
    "    ax.set_title('Test')\n",
    "\n",
    "    ax=fig.add_subplot(3,2,3)\n",
    "    ax.plot(hist.history['loss'])\n",
    "    ax.plot(hist.history['val_loss'])\n",
    "    ax.legend(['Train', 'Test'])\n",
    "    ax.set_title('Loss')\n",
    "\n",
    "    ax=fig.add_subplot(3,2,4)\n",
    "    ax.plot(hist.history['mse'])\n",
    "    ax.plot(hist.history['val_mse'])\n",
    "    ax.legend(['Train', 'Test'])\n",
    "    ax.set_title('Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = pd.read_csv('00_Data/fnc.csv')\n",
    "X1_test = X1_test[X1_test['Id'].isin(TEST_IDS)]\n",
    "X1_test = X1_test.to_numpy()\n",
    "X1_test = X1_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_test = pd.read_csv('00_Data/loading.csv')\n",
    "X2_test = X2_test[X2_test['Id'].isin(TEST_IDS)]\n",
    "X2_test = X2_test.to_numpy()\n",
    "X2_test = X2_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict([X1_test, X2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = y_preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = []\n",
    "i = 0\n",
    "for idx in TEST_IDS:\n",
    "    df_submission.append(['{0}_age'.format(idx), y_preds[i]])\n",
    "    df_submission.append(['{0}_domain1_var1'.format(idx), y_preds[i+1]])\n",
    "    df_submission.append(['{0}_domain1_var2'.format(idx), y_preds[i+2]])\n",
    "    df_submission.append(['{0}_domain2_var1'.format(idx), y_preds[i+3]])\n",
    "    df_submission.append(['{0}_domain2_var2'.format(idx), y_preds[i+4]])\n",
    "    i += 5\n",
    "\n",
    "df_submission = pd.DataFrame(df_submission, columns=['Id', 'Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('submission_fnc-load_mae_09.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.108977</td>\n",
       "      <td>69.993075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>21746</td>\n",
       "      <td>14.257265</td>\n",
       "      <td>21.358872</td>\n",
       "      <td>61.165998</td>\n",
       "      <td>51.778483</td>\n",
       "      <td>54.640179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>21747</td>\n",
       "      <td>55.456978</td>\n",
       "      <td>68.169675</td>\n",
       "      <td>29.907995</td>\n",
       "      <td>55.349257</td>\n",
       "      <td>54.019517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>21750</td>\n",
       "      <td>48.948756</td>\n",
       "      <td>55.114811</td>\n",
       "      <td>60.878271</td>\n",
       "      <td>38.617246</td>\n",
       "      <td>50.679885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>21752</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>59.844808</td>\n",
       "      <td>72.303110</td>\n",
       "      <td>55.458281</td>\n",
       "      <td>46.870235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>21754</td>\n",
       "      <td>68.820928</td>\n",
       "      <td>56.594193</td>\n",
       "      <td>34.605868</td>\n",
       "      <td>49.922535</td>\n",
       "      <td>50.383078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2\n",
       "0     10001  57.436077     30.571975     62.553736     53.325130     51.427998\n",
       "1     10002  59.580851     50.969456     67.470628     60.651856     58.311361\n",
       "2     10004  71.413018     53.152498     58.012103     52.418389     62.536641\n",
       "3     10005  66.532630           NaN           NaN     52.108977     69.993075\n",
       "4     10007  38.617381     49.197021     65.674285     40.151376     34.096421\n",
       "...     ...        ...           ...           ...           ...           ...\n",
       "5872  21746  14.257265     21.358872     61.165998     51.778483     54.640179\n",
       "5873  21747  55.456978     68.169675     29.907995     55.349257     54.019517\n",
       "5874  21750  48.948756     55.114811     60.878271     38.617246     50.679885\n",
       "5875  21752  66.532630     59.844808     72.303110     55.458281     46.870235\n",
       "5876  21754  68.820928     56.594193     34.605868     49.922535     50.383078\n",
       "\n",
       "[5877 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('00_Data/train_scores.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nulls = data[data.isnull().any(axis=1)]\n",
    "NULL_IDS = list(data_nulls['Id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
